<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Quartz Best Practices]]></title>
      <url>%2F2018%2F06%2F20%2FQuartz%20Best%20Practices%2F</url>
      <content type="text"><![CDATA[最佳实践 Production System Tips JobDataMap Tips Trigger Tips JDBC JobStore Daylight Savings Time Jobs Listeners (TriggerListener, JobListener, SchedulerListener Exposing Scheduler Functionality Through Applications 生产环境中的建议跳过检查更新通过配置 “org.quartz.scheduler.skipUpdateCheck: true” 属性，你能够取消检查更新。 JobDataMap 建议Only Store Primitive Data Types (including Strings) In the JobDataMap，避免序列化问题 Use the Merged JobDataMap在任务执行的时候，JobExecutionContext中的JobDataMap作为一个convenience。它是通过在JobDetail中的JobDataMap和Trigger中的JobDataMap合并而来，后者中的值会覆盖前面一个中同名变量的值。 当你有一个任务在scheduler中，而且这个任务又会被多个Triggers重复使用，那么你最好把值存在Trigger的JobDataMap中，这样对于每次独立的任务触发时，你就可以为Job提供不同的数据输入啦。 根据以上所述，我们提出了如下的最佳实践：在调用Job.execute(…)方法时，一般来说应该从JobExecutionContext中的JobDataMap中解析变量的值，而不是直接从JobDetail的JobDataMap中解析。 Trigger 建议Use TriggerUtils 提供了一个简单的方法来创建triggers（schedules） 有很多不同的方法通过schedules来创建triggers以满足特定的描述，这个要比直接实例化特定类型的triggers（SimpleTrigger，CronTrigger等）然后调用不同的setter方法来配置它们方便许多 提供了一个简单的方法来创建日期（比如start/end日期） 提供了分析triggers的助手（e.g. calculating future fire times） JDBC JobStore永远都不要直接往Quartz的表中写数据Writing scheduling data directly to the database (via SQL) rather than using scheduling API:永远不要在同一个Database将一个Non-Clustered Scheduler 指向另一个相同名字的Scheduler NameIf you point more than one scheduler instance at the same set of database tables, and one or more of those instances is not configured for clustering, any of the following may occur: 会造成数据腐化（被删除的数据，混乱的数据） 会造成任务在到达执行点的时候像没有执行就消失了 会造成当触发时间到来时，而任务还未执行 可能会造成死锁 Ensure Adequate Datasource Connection Size建议将你的数据源连接数配置为配置为线程池中工作线程数加3。如果你的应用还要经常调用scheduler的API，那么你还需要增加额外的connections。If you are using JobStoreCMT, the “non managed” datasource should have a max connection size of at least four. Daylight Savings TimeAvoid Scheduling Jobs Near the Transition Hours of Daylight Savings Time注意：本地的时钟向前或者向后转移时和总的时间的细节可以在如下链接中找到：https://en.wikipedia.org/wiki/Daylight_saving_time_by_country. SimpleTriggers不受夏令时的影响，这是因为它们总是在毫秒时刻被精确地触发，并且在进过了精确的毫秒数之后会再次被触发。 由于CronTriggers会在给定的时/分/秒被触发，当夏令时转移时到来的时候，它们会受到这些怪事的影响。 举一个可能发生的例子，在夏令时的美国时区/位置进行调度的时候，如果使用CronTrigger并且调度的触发时间是在1:00 AM和2:00 AM之间时会发生下列的问题： 1:05 AM may occur twice! - duplicate firings on CronTrigger possible 2:05 AM may never occur! - missed firings on CronTrigger possible Again, specifics of time and amount of adjustment varies by locale. 其他的触发器类型是根据日历的移动而不是根据确切的时间量来进行的，例如CalenderIntervalTrigger，将会同样地受影响，但不是错过触发或者触发两次，而是将它的触发时间偏移一个小时。 Jobs等待条件来到长时间运行的任务会阻止其他任务的运行（如果在线程池中所有的线程都繁忙）。 如果你认为需要调用 Thread.sleep() 这个方法来停止工作线程执行任务，这是一个典型的信号，任务不会完成其余的任务，因它必须等待某些条件的到来（比如某些数据可读）。 一个更好的方法是释放线程 (exit the job) 并且允许其他任务在这个线程执行。任务可以重新调度自己，或者在它退出之前其他任务。 抛出异常一个任务的执行方法应该包含在try-catch块中，以此处理可能发生的异常。 如果一个任务抛出一个异常，Quartz一般会马上再执行它（可能会抛出相同的异常）。最好是任务捕获所有它可能遇到的异常并处理它们，然后重新调度自己或其他的任务。 可恢复性和幂等性In-progress Jobs marked “recoverable” are automatically re-executed after a scheduler fails. This means some of the job’s “work” will be executed twice. This means the job should be coded in such a way that its work is idempotent. 监听器（TriggerListener, JobListener, SchedulerListener）Keep Code In Listeners Concise And EfficientKeep Code In Listeners Concise And EfficientPerforming large amounts of work is discouraged, as the thread that would be executing the job (or completing the trigger and moving on to firing another job, etc.) will be tied up within the listener. 处理异常每个监听器的方法都应该在try-catch块中处理所有可能的异常。 如果一个监听器抛出了一个异常，可能会造成其他的监听器无法被通知到或阻止其他任务的执行等。 通过应用来暴露调度器的功能Be Careful of Security!有的用户通过应用程序接口来暴露Quartz的调度功能。这会非常有用，虽它可能会造成极度的危险。 确保你没有错误地允许用户定义他们想要的任何参数和任何类型的任务。例如，Quartz会带有一个预定的任务org.quartz.jobs.NativeJob，这个任务将会在它们定义的任意的本地系统上执行命令。恶意的用户可能会使用这个来控制或者摧毁你的系统。 同样的像 SendEmailJob 之类的任务，并且事实上任何其他的任务都可以被当作恶意用途。 如果允许用户定义任意他们想要的任务将会是你的系统遭受各种可能的危害，等同于 OWASP 和 MITRE 定义的命令注入攻击等。 参考在此：Quartz Best Practices(http://www.quartz-scheduler.org/documentation/best-practices.html)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[网线接口转换器 苹果Mac集线器HUB接硬盘]]></title>
      <url>%2F2018%2F06%2F05%2FMac%20%E7%BD%91%E7%BA%BF%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2%E5%99%A8%E7%9A%84%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
      <content type="text"><![CDATA[Mac 连接网线以我在京东上购买的 毕亚兹(biaze) USB分线器3.0 千兆有线网卡 USB转RJ45网线接口转换器 苹果Mac集线器HUB接硬盘 ZH17-金属银 为例： ~ csrutil status System Integrity Protection status: enabled (Custom Configuration). Configuration: Apple Internal: disabled Kext Signing: enabled Filesystem Protections: enabled Debugging Restrictions: disabled DTrace Restrictions: enabled NVRAM Protections: enabled BaseSystem Verification: enabled This is an unsupported configuration, likely to break in the future and leave your machine in an unknown state. ~ 首先，SIP status 必须是 disabled 状态才行，可以通过以下步骤设置：1、重启电脑2、按住command+r进入恢复模式3、点击顶部菜单栏实用工具中的终端，（可以输入csrutil status检查状态）4、然后输入csrutil disable 其次，下载驱动,选择 MAC OS 10.6 to 10.13 版本，下载安装。 最后，重启电脑。此时，关闭Wi-Fi 网络，试试网络吧。公司网络应该是用网线连接上了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[亿级流量网站架构核心技术]]></title>
      <url>%2F2018%2F05%2F14%2F%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%2F</url>
      <content type="text"><![CDATA[跟开涛学搭建高可用高并发系统本书将介绍缓存、异步并发、连接池、线程池、如何扩容、消息队列、分布式任务等高并发原则来提升系统吞吐量。 通过负载均衡和反向代理实现分流，通过限流 保护服务免受雪崩之灾，通过降级实现部分可用、有损服务，通过隔离实现故障隔离，通过设置合理的超时与重试机制避免请求堆积造成雪崩，通过回滚机制快速修复错误版本；使得系统高可用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[那些年我看过的书]]></title>
      <url>%2F2018%2F03%2F14%2Frecommend-books%2F</url>
      <content type="text"><![CDATA[开头2012年底正式参加工作，先后经历了三家单位（软通、必联（北京）电子商务、北京四合天地科技），有短有长（补充：2018-06入职互金行业了）。有的得到了经验，有的在那里得到了成长。不付青春吧。期间也认识了不少志同道合的好同事，有些也成为了好朋友。技术道路上还需披荆斩棘，更进一步。回首往事，才能更好的展望未来。 技术书籍推荐（90%都是购买的书籍，偏爱）有些是在京东上购买的书籍，有些是在异步社区上购买的，还有些就是嘟嘟独立博客电子书互助计划得到的。1、 《Java 核心技术》卷一 、卷二 两本书，算是入门比较好的书籍了2、 Thinking in Java (Java 编程思想)GitBook 可下载阅读。第13章没有编辑，Java的GUI现在应用少，正合我意。3、 《Java 并发编程实战》4、 《实战Java高并发程序设计》5、 Effective Java 中文版 第2版GitBook 可下载阅读。算是 Java 的进阶书籍了，面试好多问题也是从这出来的6、 《图解数据结构-使用Java》7、 《Spring揭秘》8、 《设计模式之禅（第2版）》9、 《Redis实战》异步社区，购买的正版电子图书。超级清晰。在此推广一波10、《MyBatis从入门到精通__刘增辉(著)》11、《Android群英传：神兵利器》12、《图解HTTP》对互联网基盘-HTTP协议进行了全面系统的介绍13、《图解TCP/IP(第5版)》14、《Spring Boot实战 ,丁雪丰 (译者) 》15、《阿里巴巴Java开发手册（终极版）》 算法1、《数据结构与算法分析-Java语言描述 第3版》木有坚持读下来2、《算法 第4版》木有坚持读下来3、《程序员的数学1》4、《程序员的数学2：概率统计》5、《程序员的数学3：线性代数》 架构1、《大型网站技术架构：核心原理与案例分析》2、《淘宝技术这十年》3、《亿级流量网站架构核心技术(跟开涛学搭建高可用高并发系统)》4、《深入分布式缓存：从原理到实践》5、《Spring Cloud微服务实战》6、《架构探险：轻量级微服务架构（上）》黄勇。由此加入了勇哥建立的微信群，大佬云集7、《分布式服务框架原理与实践》8、《Netty权威指南第二版》 优秀博客推荐1、万维钢 用理工科思维理解世界2、刘未鹏3、酷壳-陈皓4、开涛的博客5、chenssy Java并发编程实战 人文书籍推荐1、《暗时间》 刘未鹏 | Mind Hacks思维改变生活2、《数学之美 （第二版）》吴军博士的，“数学之美”系列文章原刊载于谷歌黑板报3、《浪潮之巅》同样也是吴军博士的4、《三国机密》、《三国配角演义》马伯庸老爷子，有“文字鬼才”之誉5、《北京折叠》6、《人类简史》7、《万万没想到：用理工科思维理解世界》万维钢8、《黑客与画家》9、《如何变得有意思：阮一峰博客文集》10、《MacTalk 跨越边界》11、《禅与摩托车维修艺术》 商业、经济、财经1、《联盟：互联网时代的人才变革》参加了樊登读书会，因而知道的这本书2、《重新定义公司：谷歌是如何运营的》3、《罗辑思维 有种·有料·有趣》4、《魔鬼经济学》也是罗辑思维视频节目了解到的，共四册；只读了前两册。5、《从0到1开启商业与未来的秘密》6、《怪诞行为学：可预测的非理性》7、《怪诞行为学2：非理性的积极力量》8、《三体：黑暗森林》9、《我在碧桂园的1000天》电子版内部使用。以财务之眼看杨国强和他的地产王国。在碧桂园人称“三斌”之一吴建斌 著； 工具Git ： 廖雪峰的 Git 教程IDEA：IntelliJ IDEA 简体中文专题教程Maven：《Maven实战》 程序员的自我修养1、《程序员修炼之道-从小工到专家》2、《代码整洁之道》3、《重构：改善既有代码的设计》4、《软技能：代码之外的生存指南》 程序员除了写代码，还得懂点其他的软技能 生活、其他1、《悟空传》今何在。有这样一群人，他们宁肯死，也不肯输。2、《煮酒探西游》吴闲云3、《我不是潘金莲》刘震云的几乎都买来读过；12年、13年那两年很喜欢读他的书，一句顶一万句，温故一九四二、一地鸡毛、温故一九四二。4、《人民的名义》影视剧开播前就已经读完了，电视剧还是追了。5、《你我皆凡人》：从金庸武侠里读出来的现实江湖（六神磊磊处女作）。有微信大号“六神磊磊读金庸”，置顶公众号，粉丝支持所以买了这本书。6、《为什么你总是害怕来不及》7、《从你的全世界路过》张嘉佳8、《儒林外史》、三言两拍；9、《万历十五年》 计划要看的电子书1、《编程之法：面试和算法心得_迷你书》2、《架构即未来 现代企业可扩展的Web架构流程和组织原书第2版》3、《一线架构师实践指南》4、《O2O实战+他们是如何利用互联网的》5、《实战Elasticsearch、Logstash、Kibana++分布式大数据搜索与日志挖掘及可视化解决方案》6、《数据库查询优化器的艺术：原理解析与SQL性能优化》 最后个人认为，作为程序员不要吝啬对自己的投资，只有自己强大了才能更好的赚钱。每年都要买几本书投资一下，未来的回报会超出你的想象的，博主先准备把2017年买的书先看完先。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Cloud构建微服务架构]]></title>
      <url>%2F2018%2F03%2F07%2FSpring%20Boot%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F</url>
      <content type="text"><![CDATA[接触Spring Boot2016年 Spring Boot 还没有被广泛使用，到了现在经过2年的发展，很多互联网公司已经将 Spring Boot 搬上了生产，而使用 Spring Boot 的开源项目在 Github/码云 上面已有不少，很有必要开启一波学习潮了。 听到了一句挺中肯的话，“离开场景和业务的修炼都是伪命题”。所以呢，有必要总结一下Spring Boot 相关的开源项目，选取一个感兴趣的，然后深入学习提交pr，真正的提高自己的技术能力。 搜集 springcloud-app/dubbo-app 海信商业云平台的微服务落地实践马映辉 群分享 如何把复杂单体应用快速迁移到微服务 Spring Boot干货系列总纲 Spring Boot 那些事 Spring Boot基础教程 [江南一点雨（Spring Cloud教程合集）]作者参考了程序猿DD（翟永超）一书《Spring Cloud微服务实战》，可用来作为辩证学习的素材。 [江南一点雨] https://github.com/lenve 沉思录 Spring Cloud中国社区创始人，业余主要研究Spring Cloud。我们微信群猪的博客，强力推荐。 有思想的博客站点 黄勇 群主，强力推荐。 纯洁的微笑 微笑大佬，我们【原创技术博客作者交流群】群主。 程序猿DD 嘟嘟独立博客 泥瓦匠BYSocket 小柒2012 周立 Aresn iView 主力开发者 花裤衩（手摸手，带你用vue撸后台） 老齐 Goileo Lee 许彬 stormzhang 简单之美 独孤求胜 马勇发 任玉刚 见识（web前端） 猴子007 Litten IMWeb前端博客 Blankj 有个非常知名的 awesome-java-leetcode https://blankj.com/ 郭霖 张鸿洋 http://www.wanandroid.com/ 张鸿洋运营 eclipse_xu 《Android群英传：神兵利器》,买了读过。有意思的人儿 Lawlite zhisheng JumpByte 结构之法 算法之道 酷壳-陈皓 江南白衣 老司机 芋道源码的博客 文斌兄的地盘，另外也有知识星球，可以加入我们。 你假笨@JVM I WANNA RUN MOxFIVE Yelee主题开发者，很美观。 YouMeek 终极搜寻 Spring Cloud中国社区 http://www.spring4all.com/ Spring Boot 中文索引 Spring Boot 开源软件都有哪些？ http://www.gitnavi.com/ 结语朋友圈里看到了一句话，觉得特别好：不善于总结的人，就是在吃老本，吃惯性，吃你的智商和知识。所以呢建立博客，有的没的写一些技术、生活相关的东西，但愿不辜负青春，便想努力留下印记。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mac之神兵利器]]></title>
      <url>%2F2018%2F03%2F05%2FMac%E4%B9%8B%E7%A5%9E%E5%85%B5%E5%88%A9%E5%99%A8%2F</url>
      <content type="text"><![CDATA[接触Mac我是2016年底买的Mac，原因是在那时候通读了《MacTalk 跨越边界》、《MacTalk 人生元编程》这两本书，顿觉打开了一扇大门。随即宣告了我的联想Y570正式退役。现如今Mac上的开发利器、效率工具也装了不少，也该是从资料库整理一下的时机了。 搜集Mac Mac使用 Alfred 提高你的工作效率 神兵利器——Alfred 推荐几款我最喜爱的 Mac 软件（非技术） 从 Mac OS 到 macOS，一个新的轮回 Mac 与 Windows 的虚妄之争 程序员最常用的十个 Mac 工具（上） 程序员最常用的十个 Mac 工具（中） 程序员最常用的十个 Mac 工具（下） 我在大学里学到的几件事 OmniFocus 2 Pro for Mac 2.10 序号版 - 最优秀的GTD效率工具 Parallels Desktop 13 for Mac 13.2.0.43213 破解版 - Mac上最优秀的虚拟机 Paragon NTFS for Mac付费购买 CleanMyMac 3付费购买 Contexts 3花钱购买的 有思想的读物 普通程序员能实现财务自由吗？ 罗永浩-酷玩实验室 终极搜寻 爱情守望者 爱范儿]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[区块链与比特币破冰]]></title>
      <url>%2F2018%2F01%2F23%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E6%AF%94%E7%89%B9%E5%B8%81%E7%A0%B4%E5%86%B0%2F</url>
      <content type="text"><![CDATA[大咖说池大大在2018 年技术趋势预测中写道： 区块链是可以改变世界的发明。区块链源起比特币，但并不局限在币圈。区块链技术是储存、验证和数据保护等问题的实际解决办法。区块链可被视为分散的、极度安全的数据库。更专业一点来说，区块链是分布式的点对点的基于密码学的共享账本，可以在金融服务、保险、医疗、政府等领域内被广泛应用。2018年应该是区块链技术起飞并日趋成熟的一年。 2018 年技术趋势预测 由于是在池建强 MacTalk 公众号上发布的文章，网址链接较长，这里用了https://goo.gl 做了short URL。如果不能翻墙的话，还请前往微信阅读。 疑惑不解面对比特币的疯涨诱惑，很多人按捺不住躁动：“虽然我买不起比特币，那还可以入手其它币吗？” 自从有人，就有投机的存在。但是人类历史上第一次有记载的大规模的投机事件是17世纪荷兰的郁金香泡沫。区块链存在泡沫吗？ 还有 keso 描述的 区块链焦虑与错失恐惧症。 好多问题都需要我们自己来判断、决定，前提是我们需要学习、多了解一些，不管从大势上面还是技术层面上！尽力避免成为吃瓜群众，“山寨币”的韭菜。 了个究竟一个浪头打过来，最好的办法是迎上去了解个究竟，而不是漠视，或者干脆当事情没有发生。 区块链有多火？ 区块链焦虑与错失恐惧症 再不懂区块链，你就OUT了！ 比特币是如何被一群“囚犯”创造出来的 九分钟了解区块链 迅雷出局：想靠“山寨币”致富的人，是时候醒来搬砖了 不要试图挑战人性 一个足以颠覆微信、超越阿里的超级风口！40万亿大产业即将爆发！ 中国比特币矿机垄断全球：最被忽视的制造业样本 比特币和区块链(0)：骗局还是改变命运的科技 比特币和区块链(1)：真钱，电子货币以及区块链 比特币和区块链(2)：比特币中区块链的实现 比特币和区块链(3)：比特币的共识机制 比特币和区块链(4)：比特币成功的不可复制性 2018-01-25 我做比特币矿工这一年。 2018-02-02 互联网大佬谈区块链，看法爱憎分明 “币圈”暴富指南：致不愿醒来的韭菜们 2018-02-24 春节假期“三点钟”社群大佬激辩区块链2万字干货全记录，看这一篇足够了！ 2018-03-02 区块链性能提升：链上设计之道 韭菜席地而坐 2018年区块链落地的现状、阻碍与机遇 |捕手志 专访陈伟星：解密加密数字经济为何是未来 |捕手志 周鸿祎：写区块链最好的一篇文章 黄渊普：关于区块链，那些骗子都知道自己是骗子 2018-03-06 ICO裹挟区块链强势重来 深入研究的套路之黑客与区块链 5天钓到40枚以太币 杂谈区块链生态里的前端黑 区块链的十个吐槽 结语2016年在接受《财经》杂志专访时，张一鸣说过的那段特别具有张一鸣色彩的话： 历史上精英们一直在试图让大众拥有很高的精神追求，但社会整体从来没有达到过这个目标。以前的媒体精英意识不到这一点，他们认为自己特别希望导向的才是特别重要的。但多数人的强烈主张，从历史上看，多数都没有产生多大价值。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[如何搭建个人网站]]></title>
      <url>%2F2018%2F01%2F05%2F%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99%2F</url>
      <content type="text"><![CDATA[写在开头有了个人网站，可能就又多了一些学(zhuang)习(bi)的动力吧！所以，拥有自己的网站，算是迈出了第一步！ 好可惜最近才看到玉刚大神的文章，意识觉醒的晚了树立个人品牌：让名企hr们主动来找你 如何拥有自己的专属域名goileolee http://goileo.top/如何免费且快速的搭建个人网站 为 Github Pages 绑定的自定义域名启用 HTTPS 协议https://zhouhao.me/2017/07/21/using-https-with-custom-domain-name-on-github-pages/ hexo yilia主题添加文章访问量统计https://www.lookk.cn/2017/12/09/hexo-yilia主题添加文章访问量统计/ 原因在结尾在浏览器和访问的网站之间提供更安全的通讯HTTPS 比 HTTP 的速度更快能提高搜索引擎的优化排名]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[初探Visual Studio Code编写Vue]]></title>
      <url>%2F2017%2F12%2F28%2FVisual%20Studio%20Code%2F</url>
      <content type="text"><![CDATA[应用介绍https://code.visualstudio.com/界面简洁大方，^_^ Vue插件安装在 VSCode Marketplace https://marketplace.visualstudio.com/vscode 搜素Vue 出现关于语法高亮的插件有 Vue 2 Snippets，vue-beautify，vue-color，Vetur等等。花花绿绿的，往下翻看，目前使用率最高的就是Vetur了。安装插件：⌘P 然后输入 ext install vetur 然后回车点安装即可。但是如果你使用惯了Vim/Sublime/Atom等，VSCode允许安装自己的键盘快捷方式。我个人选择了Sublime，设置后并激活，这时按下command+shift+p输入 Vetur VS Code ESLint extension安装插件和Vetur类似。ESLint 不是安装后就可以用的，还需要一些环境和配置：eg：首先在自己的工作空间建立一个文件夹xmall-front，zsh中运行 npm init然后依次执行命令，快速体验下： ~/VSCodeProjects/xmall-front npm install --save-dev eslint eslint-plugin-html npm notice created a lockfile as package-lock.json. You should commit this file. npm WARN xmall-front@1.0.0 No repository field. + eslint-plugin-html@4.0.1 + eslint@4.14.0 added 146 packages in 14.54s ~/VSCodeProjects/xmall-front ./node_modules/.bin/eslint --init ? How would you like to configure ESLint? Answer questions about your style ? Are you using ECMAScript 6 features? Yes ? Are you using ES6 modules? Yes ? Where will your code run? Browser ? Do you use CommonJS? Yes ? Do you use JSX? Yes ? Do you use React? No ? What style of indentation do you use? Tabs ? What quotes do you use for strings? Single ? What line endings do you use? Unix ? Do you require semicolons? No ? What format do you want your config file to be in? JavaScript Successfully created .eslintrc.js file in /Users/jinkui/VSCodeProjects/xmall-front ~/VSCodeProjects/xmall-front la . .. .eslintrc.js node_modules package-lock.json package.json 在 vscode 中配置下 ESLint：eslint.validate - an array of language identifiers specify the files to be validated. Something like “eslint.validate”: [ “javascript”, “javascriptreact”, “html” ]. If the setting is missing, it defaults to [“javascript”, “javascriptreact”].查看扩展：ESLint 的Settings Options，发现确实默认不支持vue文件啊。所以说虽然安装了eslint-plugin-html还是需要配置一下的：On a Mac, click Code &gt; Preferences &gt; Settings // An array of language ids which should be validated by ESLint &quot;eslint.validate&quot;: [ &quot;javascript&quot;, &quot;javascriptreact&quot;, { &quot;language&quot;: &quot;html&quot;, &quot;autoFix&quot;: true }, &quot;vue&quot; ] 安装插件-提高效率所有插件都类似于Sublime使用Package Control安装，按下快捷键⌘⇧P，在命令提示框搜索插件即可。 Project Manager 在多个项目之前快速切换的工具 HTML Snippets Full HTML tags including HTML5 Snippets HTML CSS Support 让 html 标签上写class 智能提示当前项目所支持的样式 jQuery Code Snippets Over 130 jQuery Code Snippets Beautify Beautify code in place for VS Code vscode-fileheader insert header comment,and automatically update the time. Bracket Pair Colorizer 让括号拥有独立的颜色，易于区分。可以配合任意主题使用 Auto Close Tag Automatically add HTML/XML close tag, same as Visual Studio IDE or Sublime Text does Auto Rename Tag Auto rename paired HTML/XML tag Bookmarks 添加行书签 Indenticator 缩进高亮 Quokka.js 不需要手动运行，行内显示变量结果 JavaScript (ES6) code snippets ES6语法代码段 language-stylus Stylus语法高亮和提示 String Manipulation 字符串转换处理（驼峰、大写开头、下划线等等） VueHelper Vue2代码段（包括Vue2 api、vue-router2、vuex2） File Peek The extension supports all the normal capabilities of symbol definition tracking, but does it for file names Path Intellisense Visual Studio Code plugin that autocompletes filenames TODO Parser Parse TODOs in your working files Git History (git log) View git log, file or line History Git Lens 显示文件最近的commit和作者，显示当前行commit信息 Git History Diff View git history. View commit details. View diff of committed files. Multi-root workspaces supported. gitignore .gitignore文件语法 npm npm commands for VSCode npm Intellisense 导入模块时，提示已安装模块名称 Output Colorizer 彩色输出信息 markdownlint Markdown linting and style checking for Visual Studio Code vscode-icons Icons for Visual Studio Code(大大的好啊) 快捷键见官网。https://code.visualstudio.com/shortcuts/keyboard-shortcuts-macos.pdf 修改默认快捷键打开默认键盘快捷方式设置： 修改 keybindings.json： // 将键绑定放入此文件中以覆盖默认值 [ // &#39;删除一行&#39; { &quot;key&quot;: &quot;cmd+d&quot;, &quot;command&quot;: &quot;editor.action.deleteLines&quot;, &quot;when&quot;: &quot;editorTextFocus &amp;&amp; !editorReadonly&quot; }, // 与&#39;删除一行&#39;的快捷键互换 { &quot;key&quot;: &quot;shift+cmd+k&quot;, &quot;command&quot;: &quot;editor.action.addSelectionToNextFindMatch&quot;, &quot;when&quot;: &quot;editorFocus&quot; }, // 大小写转换快捷键，需安装 TextTransform 插件 { &quot;key&quot;: &quot;cmd+shift+y&quot;, &quot;command&quot;: &quot;editor.action.transformToUppercase&quot;, &quot;when&quot;: &quot;editorTextFocus&quot; }, { &quot;key&quot;: &quot;cmd+shift+x&quot;, &quot;command&quot;: &quot;editor.action.transformtolowercase&quot;, &quot;when&quot;: &quot;editorTextFocus&quot; } ] 结语开启一波Vue学习潮，干后端的也不能落伍啊 参考在此：使用Visual Studio Code编写Vue的札记vs code &amp; Atom 对比使用心得]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mac下之Sublime Text的好用之处]]></title>
      <url>%2F2017%2F12%2F27%2FSublime%20Text%2F</url>
      <content type="text"><![CDATA[应用介绍Sublime Text 拥有漂亮的用户界面和非凡的功能，而根据其官网介绍，Sublime Text的特点如下：拥有高效、没有干扰的界面，在编辑方面的多选、宏、代码片段等功能，以及很有特色的Minimap。用户广受喜爱的众多功能之一GOTO ANYTHING仅仅敲击几次键盘就能即刻jump to symbols, lines or words.Shortcuts: ⌘ + P 要支持一把的官网购买啊http://www.sublimetext.com/啊不花钱看这里：Sublime Text 3 Build 3156 主题插件安装soda-theme该插件主要能够使sublime 兼容mac的retina屏幕我采用Git安装最新版本，可以通过菜单 Preferences -&gt; Browse Packages….，定位到你的Sublime Text Packages文件夹，然后在这个文件夹下面 git clone就OK了。 git clone https://github.com/buymeasoda/soda-theme/ &quot;Theme - Soda&quot; Configure Sublime Text 3 打开配置文件： Sublime Text -&gt; Preferences -&gt; Settings - User 添加主题：”theme”: “Soda Light 3.sublime-theme” 我自己的主题和字体配置： 插件与配置安装插件所有插件都可以使用Package Control安装，按下快捷键⌘⇧P，在命令提示框搜索插件即可。前端开发 sublime text 常用插件和配置 快捷键 符号 说明 ⌘ command ⌃ control ⌥ option ⇧ shift ↩ enter ⌫ delete Shortcuts: ⌘ + P 即刻jump to symbols, lines or words. 快捷键 功能 @ jump to symbols # 查找文件内的单词 : 跳到行号处 Preferences -&gt; Key Bindings,在-User文件里自定义快捷键（会覆盖相应的-Default配置） 打开/关闭/前往 快捷键 功能 ⌘⇧N 打开一个新的sublime窗口 ⌘N 新建文件 ⌘⇧W 关闭sublime，关闭所有文件 ⌘W 关闭当前文件 ⌘P GOTO ANYTHING ⌘⇧T 重新打开最近关闭的文件 ⌘T 前往文件 ⌘R 前往method ⌘⇧P 命令提示 ⌃` 打开控制台 编辑 快捷键 功能 ⌘KK 从光标处删除至行尾 ⌘⌫ 从光标处删除至行首 ⌘KV paste_from_history ⌘L Select line - Repeat to select next lines ⌘D 删除行(⌃⇧K) ⌘E 选择词（重复按下时多重选择相同的词进行多重编辑）(⌘D) ⌘J 选择行（重复按下将下一行加入选择） ⌘JL Join line below to the end of the current line（⌘J） ⌃ + ⇧ + M Select all contents of the current parentheses ⌃ + M Jump to closing parentheses Repeat to jump to opening parentheses ⌘⇧↩ 在当前行前插入新行 ⌘↩ 在当前行后插入新行 ⌘+shift+y 改为大写（⌘KU） ⌘+shift+x 改为小写（⌘KL） ⌘C 复制 ⌘X 剪切 ⌘V 粘贴 ⌘Z 撤销 ⌘+shift+z 恢复撤销 ⌘y 重做 ⌘u soft_undo ⌘⇧u soft_redo ⌘/ 注释 ⌘] 向右缩进 ⌘[ 向左缩进 ⌃ + ⇧ + ↑ 一个或多行向上移动 ⌃ + ⇧ + ↓ 一个或多行向下移动 打开/关闭/前往 快捷键 功能 ⌘f 查找 ⌘⌥f 查找并替换 ⌘⌥g 查找下一个符合当前所选的内容 ⌘⌃g 查找所有符合当前选择的内容进行多重编辑 ⌘⇧F 在所有打开的文件中进行查找 ⌘ + I Incremental Find 结语Preferences -&gt; Key Bindings,在-User文件里自定义快捷键： [ { &quot;keys&quot;: [&quot;super+shift+y&quot;], &quot;command&quot;: &quot;upper_case&quot; }, { &quot;keys&quot;: [&quot;super+shift+x&quot;], &quot;command&quot;: &quot;lower_case&quot; }, { &quot;keys&quot;: [&quot;super+j&quot;], &quot;command&quot;: &quot;expand_selection&quot;, &quot;args&quot;: {&quot;to&quot;: &quot;line&quot;} }, { &quot;keys&quot;: [&quot;super+j+l&quot;], &quot;command&quot;: &quot;join_lines&quot; }, { &quot;keys&quot;: [&quot;super+e+s+f+s&quot;], &quot;command&quot;: &quot;slurp_find_string&quot; }, { &quot;keys&quot;: [&quot;super+e&quot;], &quot;command&quot;: &quot;find_under_expand&quot; }, { &quot;keys&quot;: [&quot;super+d&quot;], &quot;command&quot;: &quot;run_macro_file&quot;, &quot;args&quot;: {&quot;file&quot;: &quot;res://Packages/Default/Delete Line.sublime-macro&quot;} } ] 参考在此：Keyboard Shortcuts - OSX]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一张通往计算机世界的地图]]></title>
      <url>%2F2017%2F12%2F19%2F%E4%B8%80%E5%BC%A0%E9%80%9A%E5%BE%80%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%96%E7%95%8C%E7%9A%84%E5%9C%B0%E5%9B%BE%2F</url>
      <content type="text"><![CDATA[一张通往计算机世界的地图引述我们通过计算机来拓展我们自己的大脑。最开始计算机被用来解决和算数有关的问题，但其自身的价值很快地延伸到了各个领域。 像是运行互联网络，处理实时图像，制造人工智能，以及模拟整个宇宙等等。 而其神奇的地方就在于这一切强大功能的背后，竟然仅是 0 和 1 的来回变化。 原文作者：Surmon https://surmon.me/article/75]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis技术交流]]></title>
      <url>%2F2017%2F12%2F12%2Fredis%E6%8A%80%E6%9C%AF%E4%BA%A4%E6%B5%81%2F</url>
      <content type="text"><![CDATA[Redis原理与实战，不定期更新Redis是业界普遍应用的缓存组件，研究一个组件框架，就要探究它的设计哲学。https://redis.io/ 系列文章有些是从Redis源码，有些是从数据结构、内存优化、持久化、Redis集群实现原理探讨开来。总之，很是流行，有必要多方位了解一下啦。 张铁蕾 Redis压缩列表原理与应用分析 深入浅出Redis Cluster原理 Redis 集群的合纵与连横 360开源的类Redis存储系统:Pika 动态追踪技术（中） - Dtrace、SystemTap、火焰图 QCon上海2016的幻灯片合集 QCon北京2016幻灯片下载合集 QCon 上海 2017 PPT 合集 Redis源码学习(云栖社区) 基于Redis的BloomFilter算法去重 redis过期清除机制及应用方法 由浅入深介绍 Redis LRU 策略的具体实现 Nginx+Lua+Redis搭建高并发服务 Redis的hmget操作复杂度问题 Redis中BitMap的妙用 Redis的内存优化 理解Redis的RESP协议 深入学习 Redis：Redis API 的原子性分析 Redis 实现接口访问频率限制 Redis 源码学习之事件驱动 Redis 通信协议 —— 了解 Redis 客户端实现原理 有赞延迟队列设计 Redis内存分析方法 redis分布式内存锁：余量扣除示例(上) redis分布式内存锁：余量扣除示例(下) redisson GitHub将持久数据从Redis迁出 Redis架构之防雪崩设计：网站不宕机背后的兵法 千亿级高性能 KV 存储生态圈 Redis内核基于时间点的备份恢复和基于AOF日志的增量同步机制设计 TiDB技术内幕 Redis源码学习之事件驱动 揭秘 Reddit 愚人节项目的技术实现过程 Redis 通信协议 —— 了解 Redis 客户端实现原理 redis哨兵模式使用lua脚本实现分布式锁 CRUG | Redisson性能压测权威发布 听滴滴大神给你讲Redis Cluster迁移遇到的坑 Redis开启AOF导致的删库事件 唯品会海量实时OLAP分析技术升级之路 Jedis常见异常汇总 redis cluster 集群畅谈 Redis Performance Monitoring with the ELK Stack Redis 和 I/O 多路复用 使用 Redis 解决“树”形数据的复杂查询 JMeter’s Redis Data Set - An Introduction Redis 如何分布式，来看京东金融的设计与实践 Redis 新数据结构 - Streams Redis集群实现原理探讨 当主重启时sentinel没有切换导致数据丢失 大规模codis集群的治理与实践 springboot中redis的使用和分布式session共享问题 A Guide to Redis with Redisson 直击Redis持久化磁盘IO痛点，让存储不再有负担！ Redis Cluster 迁移案例 【译】Reddit如何统计每个帖子的浏览量 在Redis中进行分页排序查询 一个小改进，解决Redis数据在线加载大痛点 社区好友动态Feed流的Redis实现 Redis 应用案例 - 在问题中不断成长 国内外三个领域巨头告诉你Redis怎么用 Redis作为LRU Cache的实现 如何使用redis存储海量小数据 Redis性能问题排查解决手册 如何在Redis中实现事务 ansible-playbook配置redis的sentinel高可用集群 redis过期清除机制及应用方法 记一次 Redis 实战，实现答题系统 大规模排行榜系统实践及挑战 京东抢购服务高并发实践 教你看懂redis配置系列 Netty+Redis开发高并发应用的一些思考(二)/) 如何用 redis 造一把分布式锁 Redis 设计思路学习与总结 如何改变Redis用不好的误区 基于 Redis 的序列号服务的设计 Redis practice（一）基础篇 Redis practise（二）使用Docker部署Redis高可用，分布式集群 2017-12-29更新 Redis中的used_memory与maxmemory解惑 golang基于redis lua封装的优先级去重队列 搭建Redis&amp;Minerd安全应急演练环境 GeoBike: Building Location Aware Application with Redis 利用Redis实现Bloom-Filter 神奇的Redis延迟 Spring Boot + Redis 缓存方案深度解读 同程凤凰缓存系统基于Redis的设计与实践 2018-01-24更新 不管你的Redis集群规模有多大，都是时候思考下如何提升资源利用率了 Setting Up a Redis Test Environment using Docker Compose 2018-02-24 Redis 队列 Jmeter Redis插件开发 – 读写数据 线上redis迁移思路 基于Redis实现分布式应用限流 2018-03-05 Cache设计和使用上的套路 Shiro安全框架基于Redis的分布式集群方案 运用 Redis 构建分布式爬虫，抓妹子图 Redisson PRO Redis探索之路 Build a bikesharing app with Redis and Python 不停机分库分表迁移 豌豆夹Redis解决方案Codis源码剖析：Dashboard Redis消息通知系统的实现 Docker Swarm Part II: Rescheduling Redis Redis 集群搭建详细指南 参考在此：Redis技术交流群Redis技术交流群2：微信群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx + Keepalived 高可用]]></title>
      <url>%2F2017%2F11%2F22%2FNginx-Keepalived-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[Nginx + Keepalived 高可用 说明 高可用 HA（High Availability），简单讲就是：我某个应用挂了，自动有另外应用起来接着扛着，致使整个服务对外来看是没有中断过的。这里的重点就是不中断，致使公司整个业务能不断进行中，把影响减到最小，赚得更多。 因为要不中断，所以我们就需要用到了 Keepalived。Keepalived 一般不会单独使用，基本都是跟负载均衡软件（LVS、HAProxy、Nginx）一起工作来达到集群的高可用效果。 Keepalived 有双主、主备方案 常用词： 心跳：Master 会主动给 Backup 发送心跳检测包以及对外的网络功能，而 Backup 负责接收 Master 的心跳检测包，随时准备接管主机。为什么叫心跳不知道，但是挺形象的，心跳同步。 选举：Keepalived 配置的时候可以指定各台主机优先级，Master 挂了，各台 Backup 要选举出一个新的 Master。 Keepalived 官网：http://www.keepalived.org/ 官网下载：http://www.keepalived.org/download.html 官网文档：http://www.keepalived.org/documentation.html 搭建 软件版本： Nginx：1.8.1 Keepalived：1.2.20 JDK：8u72 Tomcat：8.0.32 部署环境（下文中以第几台来代表这些主机）： 虚拟 IP（VIP）：192.168.1.50 第一台主机：Nginx 1 + Keepalived 1 == 192.168.1.120（Master） 第二台主机：Nginx 2 + Keepalived 2 == 192.168.1.121（Backup） 第三台主机：Tomcat 1 == 192.168.1.122（Web 1） 第四台主机：Tomcat 2 == 192.168.1.123（Web 2） 所有机子进行时间校准：NTP（Network Time Protocol）介绍 第三、第四台主机部署： JDK 的安装：JDK 安装 Tomcat 的安装：Tomcat 安装和配置、优化 第一、二台主机部署（两台部署内容一样）： Nginx 的安装：Nginx 安装和配置 添加虚拟 IP： 复制一个网卡信息：sudo cp /etc/sysconfig/network-scripts/ifcfg-eth0 /etc/sysconfig/network-scripts/ifcfg-eth0:0 编辑配置文件：sudo vim /etc/sysconfig/network-scripts/ifcfg-eth0:0 修改内容为如下信息：DEVICE=eth0:0 &gt;&gt;&gt; 这个需要修改 TYPE=Ethernet UUID=8ddbb256-caab-4ddf-8e9a-6527b4ac5a26 ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=none IPADDR=192.168.1.50 &gt;&gt;&gt; 这个需要修改 PREFIX=24 GATEWAY=192.168.1.1 DNS1=101.226.4.6 DEFROUTE=yes IPV4_FAILURE_FATAL=yes IPV6INIT=no NAME=&quot;System eth0:0&quot; &gt;&gt;&gt; 这个需要修改 HWADDR=00:0c:29:f4:17:db LAST_CONNECT=1460213205 重启网卡服务：service network restart 如果你要绑定更多虚拟 IP，则多复制几个网卡配置出来，命名如下：ifcfg-eth0:0，ifcfg-eth0:1，ifcfg-eth0:2 …… Keepalived 开始安装 安装依赖：sudo yum install -y gcc openssl-devel popt-devel 解压包：cd /opt/setups/ ; tar zxvf keepalived-1.2.20.tar.gz 编译：cd /opt/setups/keepalived-1.2.20 ; ./configure --prefix=/usr/program/keepalived 编译安装：make &amp;&amp; make install Keepalived 设置服务和随机启动 复制配置文件到启动脚本目录：cp /usr/program/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/keepalived 增加权限：chmod +x /etc/init.d/keepalived 编辑配置文件：vim /etc/init.d/keepalived把 15 行的：. /etc/sysconfig/keepalived，改为： . /usr/program/keepalived/etc/sysconfig/keepalived（注意：前面有一个点和空格需要注意） 添加环境变量：vim /etc/profile# Keepalived 配置 KEEPALIVED_HOME=/usr/program/keepalived PATH=$PATH:$KEEPALIVED_HOME/sbin export KEEPALIVED_HOME export PATH 刷新环境变量：source /etc/profile 检测环境变量：keepalived -v ln -s /usr/program/keepalived/sbin/keepalived /usr/sbin/ vim /usr/program/keepalived/etc/sysconfig/keepalived把 14 行的：KEEPALIVED_OPTIONS=&quot;-D&quot;，改为： KEEPALIVED_OPTIONS=&quot;-D -f /usr/program/keepalived/etc/keepalived/keepalived.conf&quot; 加入随机启动：chkconfig keepalived on 第一、二台主机配置（两台在 Keepalived 配置上稍微有不一样）： 健康监测脚本（我个人放在：/opt/bash 目录下）：nginx_check.sh 健康监测脚本添加执行权限：chmod 755 /opt/bash/nginx_check.sh 运行监测脚本，看下是否有问题：sh /opt/bash/nginx_check.sh，如果没有报错，则表示改脚本没有问题 这个脚本很重要，如果脚本没法用，在启用 Keepalived 的时候可能会报：Keepalived_vrrp[5684]: pid 5959 exited with status 1 nginx 配置（两台一样配置）： worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # （重点） upstream tomcatCluster { server 192.168.1.122:8080 weight=1; server 192.168.1.123:8080 weight=1; } # （重点） server { listen 80; server_name 192.168.1.50; location / { proxy_pass http://tomcatCluster; index index.html index.htm; } } } Keepalived 配置文件编辑（第一、二台配置稍微不同，不同点具体看下面重点说明） 编辑：vim /usr/program/keepalived/etc/keepalived/keepalived.conf ``` nginx! Configuration File for keepalived 全局配置global_defs { 邮箱通知配置，keepalived 在发生切换时需要发送 email 到的对象，一行一个 notification_email { #acassen@firewall.loc #failover@firewall.loc #sysadmin@firewall.loc } 指定发件人 #notification_email_from Alexandre.Cassen@firewall.loc 指定smtp服务器地址 #smtp_server 192.168.200.1 指定smtp连接超时时间，单位秒 #smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict} （重点）脚本监控实现vrrp_script check_nginx { 运行脚本 script “/opt/bash/nginx_check.sh” 时间间隔，2秒 interval 2 权重 weight 2} vrrp_instance VI_1 { # （重点）Backup 机子这里是设置为：BACKUP state MASTER interface eth0 virtual_router_id 51 # （重点）Backup 机子要小于当前 Master 设置的 100，建议设置为 99 priority 100 # Master 与 Backup 负载均衡器之间同步检查的时间间隔，单位是秒 advert_int 1 authentication { auth_type PASS auth_pass 1111 } # （重点）配置虚拟 IP 地址，如果有多个则一行一个 virtual_ipaddress { 192.168.1.50 } # （重点）脚本监控调用 track_script { check_nginx } } ``` 启动各自服务 四台机子都停掉防火墙：service iptables stop 先启动两台 Tomcat：sh /usr/program/tomcat8/bin/startup.sh ; tail -200f /usr/program/tomcat8/logs/catalina.out 检查两台 Tomcat 是否可以单独访问，最好给首页加上不同标识，好方便等下确认是否有负载 http://192.168.1.122:8080 http://192.168.1.123:8080 启动两台 Nginx 服务：/usr/local/nginx/sbin/nginx 启动两台 Keepalived 服务：service keepalived start 查看 Master 和 Backup 两台主机的对应日志：tail -f /var/log/messages 高可用测试 模拟 Keepalived 挂掉 关闭 Master 主机的 Keepalived，查看 Master 和 Backup 两台主机的对应日志：tail -f /var/log/messages 关闭服务：service keepalived stop 如果第二台机接管了，则表示成功 重新开启 Master 主机的 Keepalived，查看 Master 和 Backup 两台主机的对应日志：tail -f /var/log/messages 重启服务：service keepalived restart 如果第一台机重新接管了，则表示成功 模拟 Nginx 挂掉 关闭 Master 主机的 Nginx，查看 Master 和 Backup 两台主机的对应日志：tail -f /var/log/messages 关闭服务：/usr/local/nginx/sbin/nginx -s stop 如果第二台机接管了，则表示成功 重新开启 Master 主机的 Nginx，查看 Master 和 Backup 两台主机的对应日志：tail -f /var/log/messages 重启 Nginx 服务：/usr/local/nginx/sbin/nginx -s reload 重启 Keepalived 服务：service keepalived restart 如果第一台机重新接管了，则表示成功 可以优化的地方，改为双主热备，监控脚本上带有自启动相关细节，后续再进行。 日志中常用的几句话解释： Entering to MASTER STATE，变成 Master 状态 Netlink reflector reports IP 192.168.1.50 added，一般变为 Master 状态，都要重新加入虚拟 IP，一般叫法叫做：虚拟 IP 重新漂移到 Master 机子上 Entering BACKUP STATE，变成 Backup 状态 Netlink reflector reports IP 192.168.1.50 removed，一般变为 Backup 状态，都要移出虚拟 IP，一般叫法叫做：虚拟 IP 重新漂移到 Master 机子上 VRRP_Script(check_nginx) succeeded，监控脚本执行成功 资料 http://xutaibao.blog.51cto.com/7482722/1669123 https://m.oschina.net/blog/301710 http://blog.csdn.net/u010028869/article/details/50612571 http://blog.csdn.net/wanglei_storage/article/details/51175418 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Jira 安装和配置]]></title>
      <url>%2F2017%2F11%2F22%2FJira-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[Jira 安装和配置 Jira 安装 Jira 安装 官网：https://www.atlassian.com/software/jira 官网下载：https://www.atlassian.com/software/jira/download 中文在线试用：http://www.jira.cn/secure/Dashboard.jspa 官网帮助说明：https://confluence.atlassian.com/jira/installing-jira-on-linux-191501165.html 官网中文语言包：https://translations.atlassian.com/dashboard/download?lang=zh_CN#/JIRA/6.3.6 Jira 6.3.6 网盘下载：http://pan.baidu.com/s/1eRjrz5C Jira 6.3.6 中文语言包网盘下载：http://pan.baidu.com/s/1i3VEsC1 环境要求： JDK 7 或更新版本； Mysql 我们要使用的版本：atlassian-jira-6.3.6.tar.gz 我个人习惯 /opt 目录下创建一个目录 setups 用来存放各种软件安装包；在 /usr 目录下创建一个 program 用来存放各种解压后的软件包，下面的讲解也都是基于此习惯 我个人已经使用了第三方源：EPEL、RepoForge，如果你出现 yum install XXXXX 安装不成功的话，很有可能就是你没有相关源，请查看我对源设置的文章 解压：tar zxvf atlassian-jira-6.3.6.tar.gz 修改目录名：mv atlassian-jira-6.3.6/ jira6.3.6/ 移到我个人的安装目录下：mv jira6.3.6/ /usr/program/ 创建存放数据目录：mkdir -p /usr/program/jira6.3.6/data/ 设置环境变量： 编辑：vim /etc/profile 在文件尾部添加：JIRA_HOME=/usr/program/jira6.3.6/data/ export JIRA_HOME 刷新配置：source /etc/profile 运行：/usr/program/jira6.3.6/bin/start-jira.sh 访问：http://192.168.0.111:8080/ 汉化：cp JIRA-6.3.6-language-pack-zh_CN.jar /usr/program/jira6.3.6/atlassian-jira/WEB-INF/lib/ 配置过程： 重新激活页面地址：http://192.168.0.111:8090/secure/admin/ViewLicense.jspa 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[FastDFS 安装和配置]]></title>
      <url>%2F2017%2F11%2F22%2FFastDFS-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[FastDFS 安装和配置 它是什么 FastDFS 介绍：http://www.oschina.net/p/fastdfs 官网下载：https://github.com/happyfish100/fastdfs/releases 为什么会出现哪些人喜欢它哪些人不喜欢它为什么学习它同类工具单机安装部署（CentOS 6.7 环境） 环境准备： 已经安装好 Nginx 软件准备： FastDFS_v5.05.tar.gz fastdfs-nginx-module_v1.16.tar.gz libfastcommon-1.0.7.tar.gz 安装依赖包：yum install -y libevent 安装 libfastcommon-1.0.7.tar.gz 解压：tar zxvf libfastcommon-1.0.7.tar.gz 进入解压后目录：cd libfastcommon-1.0.7/ 编译：./make.sh 安装：./make.sh install 设置几个软链接：ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so 设置几个软链接：ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so 设置几个软链接：ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so 设置几个软链接：ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so 安装 tracker （跟踪器）服务 FastDFS_v5.08.tar.gz 解压：tar zxvf FastDFS_v5.05.tar.gz 进入解压后目录：cd FastDFS/ 编译：./make.sh 安装：./make.sh install 安装结果：/usr/bin 存放有编译出来的文件 /etc/fdfs 存放有配置文件 配置 tracker 服务 复制一份配置文件：cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf 编辑：vim /etc/fdfs/tracker.conf，编辑内容看下面中文注释disabled=false bind_addr= port=22122 connect_timeout=30 network_timeout=60 # 下面这个路径是保存 store data 和 log 的地方，需要我们改下，指向我们一个存在的目录 # 创建目录：mkdir -p /opt/fastdfs/tracker/data-and-log base_path=/opt/fastdfs/tracker/data-and-log max_connections=256 accept_threads=1 work_threads=4 store_lookup=2 store_group=group2 store_server=0 store_path=0 download_server=0 reserved_storage_space = 10% log_level=info run_by_group= run_by_user= allow_hosts=* sync_log_buff_interval = 10 check_active_interval = 120 thread_stack_size = 64KB storage_ip_changed_auto_adjust = true storage_sync_file_max_delay = 86400 storage_sync_file_max_time = 300 use_trunk_file = false slot_min_size = 256 slot_max_size = 16MB trunk_file_size = 64MB trunk_create_file_advance = false trunk_create_file_time_base = 02:00 trunk_create_file_interval = 86400 trunk_create_file_space_threshold = 20G trunk_init_check_occupying = false trunk_init_reload_from_binlog = false trunk_compress_binlog_min_interval = 0 use_storage_id = false storage_ids_filename = storage_ids.conf id_type_in_filename = ip store_slave_file_use_link = false rotate_error_log = false error_log_rotate_time=00:00 rotate_error_log_size = 0 log_file_keep_days = 0 use_connection_pool = false connection_pool_max_idle_time = 3600 http.server_port=8080 http.check_alive_interval=30 http.check_alive_type=tcp http.check_alive_uri=/status.html 启动 tracker 服务：/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf 重启 tracker 服务：/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf restart 查看是否有 tracker 进程：ps aux | grep tracker storage （存储节点）服务部署 一般 storage 服务我们会单独装一台机子，但是这里为了方便我们安装在同一台。 如果 storage 单独安装的话，那上面安装的步骤都要在走一遍，只是到了编辑配置文件的时候，编辑的是 storage.conf 而已 复制一份配置文件：cp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf 编辑：vim /etc/fdfs/storage.conf，编辑内容看下面中文注释disabled=false group_name=group1 bind_addr= client_bind=true port=23000 connect_timeout=30 network_timeout=60 heart_beat_interval=30 stat_report_interval=60 # 下面这个路径是保存 store data 和 log 的地方，需要我们改下，指向我们一个存在的目录 # 创建目录：mkdir -p /opt/fastdfs/storage/data-and-log base_path=/opt/fastdfs/storage/data-and-log max_connections=256 buff_size = 256KB accept_threads=1 work_threads=4 disk_rw_separated = true disk_reader_threads = 1 disk_writer_threads = 1 sync_wait_msec=50 sync_interval=0 sync_start_time=00:00 sync_end_time=23:59 write_mark_file_freq=500 store_path_count=1 # 图片实际存放路径，如果有多个，这里可以有多行： # store_path0=/opt/fastdfs/storage/images-data0 # store_path1=/opt/fastdfs/storage/images-data1 # store_path2=/opt/fastdfs/storage/images-data2 # 创建目录：mkdir -p /opt/fastdfs/storage/images-data store_path0=/opt/fastdfs/storage/images-data subdir_count_per_path=256 # 指定 tracker 服务器的 IP 和端口 tracker_server=192.168.1.114:22122 log_level=info run_by_group= run_by_user= allow_hosts=* file_distribute_path_mode=0 file_distribute_rotate_count=100 fsync_after_written_bytes=0 sync_log_buff_interval=10 sync_binlog_buff_interval=10 sync_stat_file_interval=300 thread_stack_size=512KB upload_priority=10 if_alias_prefix= check_file_duplicate=0 file_signature_method=hash key_namespace=FastDFS keep_alive=0 use_access_log = false rotate_access_log = false access_log_rotate_time=00:00 rotate_error_log = false error_log_rotate_time=00:00 rotate_access_log_size = 0 rotate_error_log_size = 0 log_file_keep_days = 0 file_sync_skip_invalid_record=false use_connection_pool = false connection_pool_max_idle_time = 3600 http.domain_name= http.server_port=8888 启动 storage 服务：/usr/bin/fdfs_storaged /etc/fdfs/storage.conf，首次启动会很慢，因为它在创建预设存储文件的目录 重启 storage 服务：/usr/bin/fdfs_storaged /etc/fdfs/storage.conf restart 查看是否有 storage 进程：ps aux | grep storage 测试是否部署成功 利用自带的 client 进行测试 复制一份配置文件：cp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf 编辑：vim /etc/fdfs/client.conf，编辑内容看下面中文注释connect_timeout=30 network_timeout=60 # 下面这个路径是保存 store log 的地方，需要我们改下，指向我们一个存在的目录 # 创建目录：mkdir -p /opt/fastdfs/client/data-and-log base_path=/opt/fastdfs/client/data-and-log # 指定 tracker 服务器的 IP 和端口 tracker_server=192.168.1.114:22122 log_level=info use_connection_pool = false connection_pool_max_idle_time = 3600 load_fdfs_parameters_from_tracker=false use_storage_id = false storage_ids_filename = storage_ids.conf http.tracker_server_port=80 在终端中通过 shell 上传 opt 目录下的一张图片：/usr/bin/fdfs_test /etc/fdfs/client.conf upload /opt/test.jpg 如下图箭头所示，生成的图片地址为：http://192.168.1.114/group1/M00/00/00/wKgBclb0aqWAbVNrAAAjn7_h9gM813_big.jpg 即使我们现在知道图片的访问地址我们也访问不了，因为我们还没装 FastDFS 的 Nginx 模块 安装 fastdfs-nginx-module_v1.16.tar.gz，安装 Nginx 第三方模块相当于这个 Nginx 都是要重新安装一遍的 解压 Nginx 模块：tar zxvf fastdfs-nginx-module_v1.16.tar.gz，得到目录地址：/opt/setups/FastDFS/fastdfs-nginx-module 编辑 Nginx 模块的配置文件：vim /opt/setups/FastDFS/fastdfs-nginx-module/src/config 找到下面一行包含有 local 字眼去掉，因为这三个路径根本不是在 local 目录下的。CORE_INCS=&quot;$CORE_INCS /usr/local/include/fastdfs /usr/local/include/fastcommon/&quot; 改为如下：CORE_INCS=&quot;$CORE_INCS /usr/include/fastdfs /usr/include/fastcommon/&quot; 复制文件：cp /opt/setups/FastDFS/FastDFS/conf/http.conf /etc/fdfs 复制文件：cp /opt/setups/FastDFS/FastDFS/conf/mime.types /etc/fdfs 安装 Nginx 和 Nginx 第三方模块 安装 Nginx 依赖包：yum install -y gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel 预设几个文件夹，方便等下安装的时候有些文件可以进行存放： mkdir -p /usr/local/nginx /var/log/nginx /var/temp/nginx /var/lock/nginx 解压 Nginx：tar zxvf /opt/setups/nginx-1.8.1.tar.gz 进入解压后目录：cd /opt/setups/nginx-1.8.1/ 编译配置：（注意最后一行）./configure \ --prefix=/usr/local/nginx \ --pid-path=/var/local/nginx/nginx.pid \ --lock-path=/var/lock/nginx/nginx.lock \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --with-http_gzip_static_module \ --http-client-body-temp-path=/var/temp/nginx/client \ --http-proxy-temp-path=/var/temp/nginx/proxy \ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \ --http-scgi-temp-path=/var/temp/nginx/scgi \ --add-module=/opt/setups/FastDFS/fastdfs-nginx-module/src 编译：make 安装：make install 复制 Nginx 模块的配置文件：cp /opt/setups/FastDFS/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs 编辑 Nginx 模块的配置文件：vim /etc/fdfs/mod_fastdfs.conf，编辑内容看下面中文注释 如果在已经启动 Nginx 的情况下修改下面内容记得要重启 Nginx。 connect_timeout=2 network_timeout=30 # 下面这个路径是保存 log 的地方，需要我们改下，指向我们一个存在的目录 # 创建目录：mkdir -p /opt/fastdfs/fastdfs-nginx-module/data-and-log base_path=/opt/fastdfs/fastdfs-nginx-module/data-and-log load_fdfs_parameters_from_tracker=true storage_sync_file_max_delay = 86400 use_storage_id = false storage_ids_filename = storage_ids.conf # 指定 tracker 服务器的 IP 和端口 tracker_server=192.168.1.114:22122 storage_server_port=23000 group_name=group1 # 因为我们访问图片的地址是：http://192.168.1.114/group1/M00/00/00/wKgBclb0aqWAbVNrAAAjn7_h9gM813_big.jpg # 该地址前面是带有 /group1/M00，所以我们这里要使用 true，不然访问不到（原值是 false） url_have_group_name = true store_path_count=1 # 图片实际存放路径，如果有多个，这里可以有多行： # store_path0=/opt/fastdfs/storage/images-data0 # store_path1=/opt/fastdfs/storage/images-data1 # store_path2=/opt/fastdfs/storage/images-data2 store_path0=/opt/fastdfs/storage/images-data log_level=info log_filename= response_mode=proxy if_alias_prefix= flv_support = true flv_extension = flv group_count = 0 编辑 Nginx 配置文件 # 注意这一行行，我特别加上了使用 root 用户去执行，不然有些日记目录没有权限访问 user root; worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; # 访问本机 server_name 192.168.1.114; # 拦截包含 /group1/M00 请求，使用 fastdfs 这个 Nginx 模块进行转发 location /group1/M00 { ngx_fastdfs_module; } } } 启动 Nginx 停掉防火墙：service iptables stop 启动：/usr/local/nginx/sbin/nginx，启动完成 shell 是不会有输出的 访问：192.168.1.114，如果能看到：Welcome to nginx!，即可表示安装成功 检查 时候有 Nginx 进程：ps aux | grep nginx，正常是显示 3 个结果出来 刷新 Nginx 配置后重启：/usr/local/nginx/sbin/nginx -s reload 停止 Nginx：/usr/local/nginx/sbin/nginx -s stop 如果访问不了，或是出现其他信息看下错误立即：vim /var/log/nginx/error.log 多机安装部署（CentOS 6.7 环境）http://blog.csdn.net/ricciozhang/article/details/49402273 资料 fastdfs+nginx安装配置 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Bash 常用命令]]></title>
      <url>%2F2017%2F11%2F22%2FBash%2F</url>
      <content type="text"><![CDATA[Bash 常用命令 基础常用命令 某个命令 --h，对这个命令进行解释 某个命令 --help，解释这个命令(更详细) man某个命令，文档式解释这个命令(更更详细)(执行该命令后,还可以按/+关键字进行查询结果的搜索) Ctrl + c，结束命令 TAB键，自动补全命令（按一次自动补全，连续按两次，提示所有以输入开头字母的所有命令） 键盘上下键，输入临近的历史命令 history，查看所有的历史命令 Ctrl + r，进入历史命令的搜索功能模式 clear，清除屏幕里面的所有命令 pwd，显示当前目录路径（常用） firefox&amp;，最后后面的 &amp; 符号，表示使用后台方式打开 Firefox，然后显示该进程的 PID 值 jobs，查看后台运行的程序列表 ifconfig，查看 IP 等信息（常用） locate 搜索关键字，快速搜索系统文件/文件夹（类似 Windows 上的 everything 索引式搜索）（常用） updatedb，配合上面的 locate，给 locate 的索引更新（locate 默认是一天更新一次索引）（常用） date，查看系统时间（常用） date -s20080103，设置日期（常用） date -s18:24，设置时间，如果要同时更改 BIOS 时间，再执行 hwclock --systohc（常用） cal，在终端中查看日历，肯定没有农历显示的 uptime，查看系统已经运行了多久，当前有几个用户等信息（常用） echo &quot;字符串内容&quot;，输出 “字符串内容” cat 文件路名，显示文件内容（属于打印语句） cat -n 文件名，显示文件，并每一行内容都编号 more 文件名，用分页的方式查看文件内容（按 space 翻下一页，按 Ctrl + B 返回上页） less文件名，用分页的方式查看文件内容（带上下翻页） 按 j 向下移动，按 k 向上移动 按 / 后，输入要查找的字符串内容，可以对文件进行向下查询，如果存在多个结果可以按 n 调到下一个结果出 按 ？ 后，输入要查找的字符串内容，可以对文件进行向上查询，如果存在多个结果可以按 n 调到下一个结果出 tail -200f 文件名，查看文件被更新的新内容尾 200 行，如果文件还有在新增可以动态查看到（一般用于查看日记文件） shutdown shutdown -hnow，立即关机 shutdown -h+10，10 分钟后关机 shutdown -h23:30，23:30 关机 shutdown -rnew，立即重启 poweroff，立即关机（常用） reboot，立即重启（常用） zip mytest.zip /opt/test/，把 /opt 目录下的 test/ 目录进行压缩，压缩成一个名叫 mytest 的 zip 文件 unzip mytest.zip，对 mytest.zip 这个文件进行解压，解压到当前所在目录 unzip mytest.zip -d /opt/setups/，对 mytest.zip 这个文件进行解压，解压到 /opt/setups/ 目录下 tar -cvf mytest.tar mytest/，对 mytest/ 目录进行归档处理（归档和压缩不一样） tar -xvf mytest.tar，释放 mytest.tar 这个归档文件，释放到当前目录 tar -xvf mytest.tar -C /opt/setups/，释放 mytest.tar 这个归档文件，释放到 /opt/setups/ 目录下 last，显示最近登录的帐户及时间 lastlog，显示系统所有用户各自在最近登录的记录，如果没有登录过的用户会显示 从未登陆过 ls，列出当前目录下的所有没有隐藏的文件 / 文件夹。 ls -a，列出包括以．号开头的隐藏文件 / 文件夹（也就是所有文件） ls -R，显示出目录下以及其所有子目录的文件 / 文件夹（递归地方式，不显示隐藏的文件） ls -a -R，显示出目录下以及其所有子目录的文件 / 文件夹（递归地方式，显示隐藏的文件） ls -l，列出目录下所有文件的权限、所有者、文件大小、修改时间及名称（也就是显示详细信息，不显示隐藏文件）。显示出来的效果如下： -rwxr-xr-x. 1 root root 4096 3月 26 10:57，其中最前面的 - 表示这是一个普通文件 lrwxrwxrwx. 1 root root 4096 3月 26 10:57，其中最前面的 l 表示这是一个链接文件，类似 Windows 的快捷方式 drwxr-xr-x. 5 root root 4096 3月 26 10:57，其中最前面的 d 表示这是一个目录 ls -ld 目录名，显示该目录的基本信息 ls -t，依照文件最后修改时间的顺序列出文件名。 ls -F，列出当前目录下的文件名及其类型。以 / 结尾表示为目录名，以 * 结尾表示为可执行文件，以 @ 结尾表示为符号连接 ls -lg，同上，并显示出文件的所有者工作组名。 ls -lh，查看文件夹类文件详细信息，文件大小，文件修改时间 ls /opt | head -5，显示 opt 目录下前 5 条记录 ls -l /opt |grep &quot;^-&quot;|wc -l，统计 opt 目录下文件的个数，不会递归统计 ls -lR /opt |grep &quot;^-&quot;|wc -l，统计 opt 目录下文件的个数，会递归统计 ls -l /opt |grep &quot;^d&quot;|wc -l，统计 opt 目录下目录的个数，不会递归统计 ls -lR /opt |grep &quot;^d&quot;|wc -l，统计 opt 目录下目录的个数，会递归统计 ls -lR /opt |grep &quot;js&quot;|wc -l，统计 opt 目录下 js 文件的个数，会递归统计 cd，目录切换 cd ..，改变目录位置至当前目录的父目录(上级目录)。 cd ~，改变目录位置至用户登录时的工作目录。 cd 回车，回到家目录 cd -，上一个工作目录 cd dir1/，改变目录位置至 dir1 目录下。 cd ~user，改变目录位置至用户的工作目录。 cd ../user，改变目录位置至相对路径user的目录下。 cd /../..，改变目录位置至绝对路径的目录位置下。 cp 源文件 目标文件，复制文件 cp -r 源文件夹 目标文件夹，复制文件夹 cp -r -v 源文件夹 目标文件夹，复制文件夹(显示详细信息，一般用于文件夹很大，需要查看复制进度的时候) cp /usr/share/easy-rsa/2.0/keys/{ca.crt,server.{crt,key},dh2048.pem,ta.key} /etc/openvpn/keys/，复制同目录下花括号中的文件 tar cpf - . | tar xpf - -C /opt，复制当前所有文件到 /opt 目录下，一般如果文件夹文件多的情况下用这个更好，用 cp 比较容易出问题 mv 文件 目标文件夹，移动文件到目标文件夹 mv 文件，不指定目录重命名后的名字，用来重命名文件 touch 文件名，创建一个空白文件/更新已有文件的时间(后者少用) mkdir 文件夹名，创建文件夹 mkdir -p /opt/setups/nginx/conf/，创建一个名为 conf 文件夹，如果它的上级目录 nginx 没有也会跟着一起生成，如果有则跳过 rmdir 文件夹名，删除文件夹(只能删除文件夹里面是没有东西的文件夹) rm 文件，删除文件 rm -r 文件夹，删除文件夹 rm -r -i 文件夹，在删除文件夹里的文件会提示(要的话,在提示后面输入yes) rm -r -f 文件夹，强制删除 rm -r -f 文件夹1/ 文件夹2/ 文件夹3/删除多个 find，高级查找 find . -name *lin*，其中 . 代表在当前目录找，-name 表示匹配文件名 / 文件夹名，*lin* 用通配符搜索含有lin的文件或是文件夹 find . -iname *lin*，其中 . 代表在当前目录找，-iname 表示匹配文件名 / 文件夹名（忽略大小写差异），*lin* 用通配符搜索含有lin的文件或是文件夹 find / -name *.conf，其中 / 代表根目录查找，*.conf代表搜索后缀会.conf的文件 find /opt -name .oh-my-zsh，其中 /opt 代表目录名，.oh-my-zsh 代表搜索的是隐藏文件 / 文件夹名字为 oh-my-zsh 的 find /opt -type f -iname .oh-my-zsh，其中 /opt 代表目录名，-type f 代表只找文件，.oh-my-zsh 代表搜索的是隐藏文件名字为 oh-my-zsh 的 find /opt -type d -iname .oh-my-zsh，其中 /opt 代表目录名，-type d 代表只找目录，.oh-my-zsh 代表搜索的是隐藏文件夹名字为 oh-my-zsh 的 find . -name &quot;lin*&quot; -execls -l{}\;，当前目录搜索lin开头的文件，然后用其搜索后的结果集，再执行ls -l的命令（这个命令可变，其他命令也可以），其中 -exec 和 {}\; 都是固定格式 cat /etc/resolv.conf，查看 DNS 设置 用户、权限-相关命令 hostname，查看当前登陆用户全名 cat /etc/group，查看所有组 cat /etc/passwd，查看所有用户 useradd youmeek -p 123456，添加一个名为 youmeek 的用户，还有一个同名的组 userdel -r youmeek，删除名字为 youmeek 的用户 参数：-r，表示删除用户的时候连同用户的家目录一起删除 修改普通用户 youmeek 的权限跟 root 权限一样： 常用方法（原理是把该用户加到可以直接使用 sudo 的一个权限状态而已）： 编辑配置文件：`` 找到 98 行（预估），有一个：root ALL=(ALL) ALL，在这一行下面再增加一行，效果如下： root ALL=(ALL) ALL youmeek ALL=(ALL) ALL 另一种方法： 编辑系统用户的配置文件：vim /etc/passwd，找到 root 和 youmeek 各自开头的那一行，比如 root 是：root:x:0:0:root:/root:/bin/zsh，这个代表的含义为：用户名:密码:UserId:GroupId:描述:家目录:登录使用的 shell 通过这两行对比，我们可以直接修改 youmeek 所在行的 UserId 值 和 GroupId 值，都改为 0。 groupadd judasn，添加一个名为 judasn 的用户组 groupdel judasn，删除一个名为 judasn 的用户组（前提：先删除组下面的所有用户） passwd youmeek，修改 youmeek 用户的密码（前提：只有 root 用户才有修改其他用户的权限，其他用户只能修改自己的） chmod 777 文件名/目录，给指定文件增加最高权限，系统中的所有人都可以进行读写。 linux 的权限分为 rwx。r 代表：可读，w 代表：可写，x 代表：可执行 这三个权限都可以转换成数值表示，r = 4，w = 2，x = 1，- = 0，所以总和是 7，也就是最大权限。第一个 7 是所属主（user）的权限，第二个 7 是所属组（group）的权限，最后一位 7 是非本群组用户（others）的权限。 su：切换到 root 用户，终端目录还是原来的地方（常用） su -：切换到 root 用户，其中 - 号另起一个终端并切换账号 su 用户名，切换指定用户帐号登陆，终端目录还是原来地方。 su - 用户名，切换到指定用户帐号登陆，其中 - 号另起一个终端并切换账号 exit，注销当前用户（常用） sudo 某个命令，使用管理员权限使用命令，使用 sudo 回车之后需要输入当前登录账号的密码。（常用） passwd，修改当前用户密码（常用） 磁盘管理 df -h，自动以合适的磁盘容量单位查看磁盘大小和使用空间 df -k，以磁盘容量单位 K 为数值结果查看磁盘使用情况 df -m，以磁盘容量单位 M 为数值结果查看磁盘使用情况 du -sh /opt，查看 opt 这个文件夹大小 （h 的意思 human-readable 用人类可读性较好方式显示，系统会自动调节单位，显示合适大小的单位） du -sh ./*，查看当前目录下所有文件夹大小 （h 的意思 human-readable 用人类可读性较好方式显示，系统会自动调节单位，显示合适大小的单位） du -sh /opt/setups/，显示 /opt/setups/ 目录所占硬盘空间大小（s 表示 –summarize 仅显示总计，即当前目录的大小。h 表示 –human-readable 以 KB，MB，GB 为单位，提高信息的可读性） mount /dev/sdb5 /newDir/，把分区 sdb5 挂载在根目录下的一个名为 newDir 的空目录下，需要注意的是：这个目录最好为空，不然已有的那些文件将看不到，除非卸载挂载。 挂载好之后，通过：df -h，查看挂载情况。 umount /newDir/，卸载挂载，用目录名 如果这样卸载不了可以使用：umount -l /newDir/ umount /dev/sdb5，卸载挂载，用分区名 资料 http://wenku.baidu.com/view/1ad19bd226fff705cc170af3.html http://blog.csdn.net/nzing/article/details/9166057 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Crontab]]></title>
      <url>%2F2017%2F11%2F22%2FCrontab%2F</url>
      <content type="text"><![CDATA[Crontab 介绍 Crontab 安装 查看是否已安装： CentOS：rpm -qa | grep cron Ubuntu：dpkg -l | grep cron 安装（一般系统是集成的）： CentOS 6：sudo yum install -y vixie-cron crontabs Ubuntu：sudo apt-get install -y cron Crontab 服务器配置文件常用参数 配置文件介绍（记得先备份）：sudo vim /etc/crontab 该配置格式解释： 常用例子介绍： 30 21 * service httpd restart #每晚的 21:30 重启 apache 45 4 1,10,22 service httpd restart #每月的 1、10、22 日的 4:45 重启 apache 45 4 1-10 service httpd restart #每月的 1 到 10 日的 4:45 重启 apache /2 * service httpd restart #每隔两分钟重启 apache 1-59/2 service httpd restart #每隔两分钟重启 apache（这个比较特殊：1-59/2 这个表示过掉0分，从 1 分开始算，每隔两分执行，所以 1 分执行了，3 分执行了，5 分执行了….都是奇数进行执行。默认的 */2 都是偶数执行。） 0 23-7/2 * service httpd restart #晚上 11 点到早上 7 点之间，每隔 2 个小时重启 apache 0-59/30 18-23 * service httpd restart #每天 18:00 到 23：00 之间，每隔 30 分钟重启 apache（方法一） 0,30 18-23 * service httpd restart #每天 18:00 到 23：00 之间，每隔 30 分钟重启 apache（方法二） 执行记录日志：cd /var/log/cron Crontab 资料 http://www.imooc.com/video/4498 http://www.centoscn.com/image-text/config/2015/0901/6096.html 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Maven 安装和配置]]></title>
      <url>%2F2017%2F11%2F22%2FMaven-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[Maven 安装和配置 Maven 安装 Maven 安装 官网：http://maven.apache.org/ 官网下载：http://maven.apache.org/download.cgi 历史版本下载：https://archive.apache.org/dist/maven/binaries/ 此时（20160208） Maven 最新版本为：3.3.9 Maven 3.3 的 JDK 最低要求是 JDK 7 我个人习惯 /opt 目录下创建一个目录 setups 用来存放各种软件安装包；在 /usr 目录下创建一个 program 用来存放各种解压后的软件包，下面的讲解也都是基于此习惯 我个人已经使用了第三方源：EPEL、RepoForge，如果你出现 yum install XXXXX 安装不成功的话，很有可能就是你没有相关源，请查看我对源设置的文章 下载压缩包：wget http://mirrors.cnnic.cn/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz 解压：tar zxvf apache-maven-3.3.9-bin.tar.gz 修改目录名，默认的太长了：mv apache-maven-3.3.9/ maven3.3.9/ 移到我个人习惯的安装目录下：mv maven3.3.9/ /usr/program 环境变量设置：vim /etc/profile 在文件最尾巴添加下面内容： # Maven MAVEN_HOME=/usr/program/maven3.3.9 PATH=$PATH:$MAVEN_HOME/bin MAVEN_OPTS=&quot;-Xms256m -Xmx356m&quot; export MAVEN_HOME export PATH export MAVEN_OPTS 刷新配置文件：source /etc/profile 测试是否安装成功：mvn -version Maven 配置 配置项目连接上私服 全局方式配置： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;!--本地仓库位置--&gt; &lt;localRepository&gt;D:/maven/my_local_repository&lt;/localRepository&gt; &lt;pluginGroups&gt; &lt;/pluginGroups&gt; &lt;proxies&gt; &lt;/proxies&gt; &lt;!--设置 Nexus 认证信息--&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;!--设置 Nexus 镜像，后面只要本地没对应的以来，则到 Nexus 去找--&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://localhost:8081/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://localhost:8081/nexus/content/groups/public-snapshots&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;url&gt;http://nexus-releases&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;url&gt;http://nexus-snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;url&gt;http://nexus-releases&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;url&gt;http://nexus-snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;nexus&lt;/activeProfile&gt; &lt;/activeProfiles&gt; &lt;/settings&gt; 项目级别： 资料 http://maven.apache.org/install.html http://www.tutorialspoint.com/maven/index.htm http://maven.apache.org/guides/getting-started/maven-in-five-minutes.html http://maven.apache.org/guides/getting-started/index.html http://maven.apache.org/general.html http://stackoverflow.com/questions/6950346/infrastructure-with-maven-jenkins-nexus http://blog.csdn.net/sxyx2008/article/details/7975129 http://blog.csdn.net/xuke6677/article/details/8482472 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[NFS]]></title>
      <url>%2F2017%2F11%2F22%2FNFS%2F</url>
      <content type="text"><![CDATA[NFS（Network FileSystem）介绍 NFS 安装 查看是否已安装： CentOS：rpm -qa | grep nfs-* Ubuntu：dpkg -l | grep nfs-* 安装： CentOS 5：sudo yum install -y nfs-utils portmap CentOS 6：sudo yum install -y nfs-utils rpcbind Ubuntu：sudo apt-get install -y nfs-common nfs-kernel-server NFS 服务器配置文件常用参数 配置文件介绍（记得先备份）：sudo vim /etc/exports 默认配置文件里面是没啥内容的，我们需要自己加上配置内容，一行表示共享一个目录。为了方便使用，共享的目录最好将权限设置为 777（chmod 777 folderName）。 假设在配置文件里面加上：/opt/mytest 192.168.0.0/55(rw,sync,all_squash,anonuid=501,anongid=501,no_subtree_check) 该配置解释： /opt/mytest 表示我们要共享的目录 192.168.0.0/55 表示内网中这个网段区间的IP是可以进行访问的，如果要任意网段都可以访问，可以用 * 号表示 (rw,sync,all_squash,anonuid=501,anongid=501,no_subtree_check) 表示权限 rw：是可读写（ro是只读） sync：同步模式，表示内存中的数据时时刻刻写入磁盘（async：非同步模式，内存中数据定期存入磁盘） all_squash：表示不管使用NFS的用户是谁，其身份都会被限定为一个指定的普通用户身份。（no_root_squash：其他客户端主机的root用户对该目录有至高权限控制。root_squash：表示其他客户端主机的root用户对该目录有普通用户权限控制） anonuid/anongid：要和root_squash或all_squash选项一同使用，表示指定使用NFS的用户被限定后的uid和gid，前提是本图片服务器的/etc/passwd中存在这一的uid和gid no_subtree_check：不检查父目录的权限 启动服务： /etc/init.d/rpcbind restart /etc/init.d/nfs-kernel-server restart NFS 客户端访问 客户端要访问服务端的共享目录需要对其共享的目录进行挂载，在挂载之前先检查下：showmount -e 192.168.1.25（这个 IP 是 NFS 的服务器端 IP） 如果显示：/opt/mytest 相关信息表示成功了。 现在开始对其进行挂载：mount -t nfs 192.168.1.25:/opt/mytest/ /mytest/ 在客户端机器上输入命令：df -h 可以看到多了一个 mytest 分区。然后我们可以再创建一个软链接，把软链接放在 war 包的目录下，这样上传的图片都会跑到另外一台服务器上了。软链接相关内容请自行搜索。 NFS 资料 http://wiki.jikexueyuan.com/project/linux/nfs.html http://www.jb51.net/os/RedHat/77993.html http://www.cnblogs.com/Charles-Zhang-Blog/archive/2013/02/05/2892879.html http://www.linuxidc.com/Linux/2013-08/89154.htm http://www.centoscn.com/image-text/config/2015/0111/4475.html 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[NTP]]></title>
      <url>%2F2017%2F11%2F22%2FNTP%2F</url>
      <content type="text"><![CDATA[NTP（Network Time Protocol）介绍 NTP 安装 查看是否已安装： CentOS：rpm -qa | grep ntp-* Ubuntu：dpkg -l | grep ntp-* 安装： CentOS 6：sudo yum install -y ntp Ubuntu：sudo apt-get install -y ntp NTP 服务器配置文件常用参数 世界上可以校对时间节点：http://www.pool.ntp.org/zh 中国时间校对服务器节点：http://www.pool.ntp.org/zone/cn 配置文件介绍（记得先备份）：sudo vim /etc/ntp.conf 该配置解释： 标注 1 是默认内容，我们这里进行了注释。 标注 2 是新增内容，表示使用中国时间校对服务器节点地址。server 0.asia.pool.ntp.org server 1.asia.pool.ntp.org server 2.asia.pool.ntp.org server 3.asia.pool.ntp.org 启动服务： sudo service ntpd start 服务加到启动项 CentOS 系统 sudo chkconfig ntpd on Ubuntu 系统 sudo apt-get install -y sysv-rc-conf sudo sysv-rc-conf ntpd on NTP 资料 http://www.jikexueyuan.com/course/1710.html http://www.pool.ntp.org/zh http://blog.kissdata.com/2014/10/28/ubuntu-ntp.html 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title></title>
      <url>%2F2017%2F11%2F22%2Fcentos-settings%2FClear-Cache%2F</url>
      <content type="text"><![CDATA[清除系统缓存初衷 本身 Linux 有比较成熟的内存管理机制，但是不免也是会抽风的，有些程序在被 kill 掉之后系统内存依然没有大的变化，这时候就需要手动清除。 清除缓存 官网说明：http://www.kernel.org/doc/Documentation/sysctl/vm.txt 先查看目前系统内存使用情况：free -m 同步缓存数据到硬盘：sync 开始清理：echo 3 &gt; /proc/sys/vm/drop_caches 0：不清除 1：清除页缓存 2：清除目录项缓存与文件结点缓存 3：清除所有缓存（常用） 再查看清除后效果：free -m]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL 安装和配置]]></title>
      <url>%2F2017%2F11%2F22%2FMysql-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[MySQL 安装和配置 MySQL 安装 Mysql 安装 官网：http://www.mysql.com/ 官网下载：http://dev.mysql.com/downloads/mysql/ 官网 5.5 下载：http://dev.mysql.com/downloads/mysql/5.5.html#downloads 官网 5.6 下载：http://dev.mysql.com/downloads/mysql/5.6.html#downloads 官网 5.7 下载：http://dev.mysql.com/downloads/mysql/5.7.html#downloads 官网帮助中心：http://dev.mysql.com/doc/refman/5.6/en/source-installation.html 此时（20160210） Mysql 5.5 最新版本为：5.5.48 此时（20160210） Mysql 5.6 最新版本为：5.6.29 此时（20160210） Mysql 5.7 最新版本为：5.7.11 我个人习惯 /opt 目录下创建一个目录 setups 用来存放各种软件安装包；在 /usr 目录下创建一个 program 用来存放各种解压后的软件包，下面的讲解也都是基于此习惯 我个人已经使用了第三方源：EPEL、RepoForge，如果你出现 yum install XXXXX 安装不成功的话，很有可能就是你没有相关源，请查看我对源设置的文章 Mysql 5.6 下载：wget http://dev.mysql.com/get/Downloads/MySQL-5.6/mysql-5.6.29.tar.gz （大小：31 M） Mysql 5.7 下载：wget http://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.11.tar.gz （大小：47 M） 我们这次安装以 5.6 为实例 进入下载目录：cd /opt/setups 解压压缩包：tar zxvf mysql-5.6.29.tar.gz 移到解压包：mv /opt/setups/mysql-5.6.29 /usr/program/ 安装依赖包、编译包：yum install -y make gcc-c++ cmake bison-devel ncurses-devel 进入解压目录：cd /usr/program/mysql-5.6.29/ 生成安装目录：mkdir -p /usr/program/mysql/data 生成配置（使用 InnoDB）：sudo cmake -DCMAKE_INSTALL_PREFIX=/usr/program/mysql -DMYSQL_DATADIR=/usr/program/mysql/data -DMYSQL_UNIX_ADDR=/tmp/mysql.sock -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DWITH_EXTRA_CHARSETS:STRING=utf8 -DWITH_MYISAM_STORAGE_ENGINE=1 -DWITH_INNOBASE_STORAGE_ENGINE=1 -DENABLED_LOCAL_INFILE=1 更多参数说明可以查看：http://dev.mysql.com/doc/refman/5.6/en/source-configuration-options.html 编译：sudo make，这个过程比较漫长，一般都在 30 分钟左右，具体还得看机子配置，如果最后结果有 error，建议删除整个 mysql 目录后重新解压一个出来继续处理 安装：sudo make install 配置开机启动： sudo cp /usr/program/mysql-5.6.29/support-files/mysql.server /etc/init.d/mysql sudo chmod 755 /etc/init.d/mysql sudo chkconfig mysql on 复制一份配置文件： sudo cp /usr/program/mysql-5.6.29/support-files/my-default.cnf /etc/my.cnf 删除安装的目录：rm -rf /usr/program/mysql-5.6.29/ 添加组和用户及安装目录权限 sudo groupadd mysql #添加组 sudo useradd -g mysql mysql -s /bin/false #创建用户mysql并加入到mysql组，不允许mysql用户直接登录系统 sudo chown -R mysql:mysql /usr/program/mysql/data #设置MySQL数据库目录权限 初始化数据库：sudo /usr/program/mysql/scripts/mysql_install_db --basedir=/usr/program/mysql --datadir=/usr/program/mysql/data --skip-name-resolve --user=mysql 开放防火墙端口： sudo iptables -I INPUT -p tcp -m tcp --dport 3306 -j ACCEPT sudo service iptables save sudo service iptables restart 禁用 selinux 编辑配置文件：vim /etc/selinux/config 把 SELINUX=enforcing 改为 SELINUX=disabled 常用命令软连接，才可以在终端直接使用：mysql 和 mysqladmin 命令 sudo ln -s /usr/program/mysql/bin/mysql /usr/bin sudo ln -s /usr/program/mysql/bin/mysqladmin /usr/bin MySQL 配置 官网配置参数解释：http://dev.mysql.com/doc/refman/5.6/en/mysqld-option-tables.html 找一下当前系统中有多少个 my.cnf 文件：find / -name &quot;my.cnf&quot;，我查到的结果： /etc/my.cnf /usr/program/mysql/my.cnf /usr/program/mysql/mysql-test/suite/ndb/my.cnf /usr/program/mysql/mysql-test/suite/ndb_big/my.cnf ............. /usr/program/mysql/mysql-test/suite/ndb_rpl/my.cnf 保留 /etc/my.cnf 和 /usr/program/mysql/mysql-test/ 目录下配置文件，其他删除掉。 我整理的一个单机版配置说明（MySQL 5.6，适用于 1G 内存的服务器）： my.cnf 修改 root 账号密码 启动 Mysql 服务器：service mysql start 查看是否已经启动了：ps aux | grep mysql 默认安装情况下，root 的密码是空，所以为了方便我们可以设置一个密码，假设我设置为：123456 终端下执行：mysql -uroot 现在进入了 mysql 命令行管理界面，输入：SET PASSWORD = PASSWORD(&#39;123456&#39;); 修改密码后，终端下执行：mysql -uroot -p 根据提示，输入密码进度 mysql 命令行状态。 如果你在其他机子上连接该数据库机子报：Access denied for user ‘root’@’localhost’ (using password: YES) 解决办法： 在终端中执行：service mysql stop 在终端中执行：/usr/program/mysql/bin/mysqld --skip-grant-tables 此时 MySQL 服务会一直处于监听状态，你需要另起一个终端窗口来执行接下来的操作 在终端中执行：mysql -u root mysql 进入 MySQL 命令后执行：UPDATE user SET Password=PASSWORD(&#39;填写你要的新密码&#39;) where USER=&#39;root&#39;;FLUSH PRIVILEGES; 重启 MySQL 服务：service mysql restart MySQL 主从复制环境说明和注意点 假设有两台服务器，一台做主，一台做从 MySQL 主信息： IP：12.168.1.113 端口：3306 MySQL 从信息： IP：12.168.1.115 端口：3306 注意点 主 DB server 和从 DB server 数据库的版本一致 主 DB server 和从 DB server 数据库数据一致 主 DB server 开启二进制日志，主 DB server 和从 DB server 的 server-id 都必须唯一 优先操作： 把主库的数据库复制到从库并导入 主库机子操作 主库操作步骤 创建一个目录：mkdir -p /usr/program/mysql/data/mysql-bin 主 DB 开启二进制日志功能：vim /etc/my.cnf， 添加一行：log-bin = /usr/program/mysql/data/mysql-bin 指定同步的数据库，如果不指定则同步全部数据库，其中 ssm 是我的数据库名：binlog-do-db=ssm 主库关掉慢查询记录，用 SQL 语句查看当前是否开启：SHOW VARIABLES LIKE &#39;%slow_query_log%&#39;;，如果显示 OFF 则表示关闭，ON 表示开启 重启主库 MySQL 服务 进入 MySQL 命令行状态，执行 SQL 语句查询状态：SHOW MASTER STATUS; 在显示的结果中，我们需要记录下 File 和 Position 值，等下从库配置有用。 设置授权用户 slave01 使用 123456 密码登录主库，这里 @ 后的 IP 为从库机子的 IP 地址，如果从库的机子有多个，我们需要多个这个 SQL 语句。 grant replication slave on *.* to &#39;slave01&#39;@&#39;192.168.1.135&#39; identified by &#39;123456&#39;; flush privileges; 从库机子操作 从库操作步骤 从库开启慢查询记录，用 SQL 语句查看当前是否开启：SHOW VARIABLES LIKE &#39;%slow_query_log%&#39;;，如果显示 OFF 则表示关闭，ON 表示开启。 测试从库机子是否能连上主库机子：sudo mysql -h 192.168.1.105 -u slave01 -p，必须要连上下面的操作才有意义。 由于不能排除是不是系统防火墙的问题，所以建议连不上临时关掉防火墙：service iptables stop 或是添加防火墙规则： 添加规则：sudo iptables -I INPUT -p tcp -m tcp --dport 3306 -j ACCEPT 保存规则：sudo service iptables save 重启 iptables：sudo service iptables restart 修改配置文件：vim /etc/my.cnf，把 server-id 改为跟主库不一样 在进入 MySQL 的命令行状态下，输入下面 SQL： CHANGE MASTER TO master_host=&#39;192.168.1.113&#39;, master_user=&#39;slave01&#39;, master_password=&#39;123456&#39;, master_port=3306, master_log_file=&#39;mysql3306-bin.000006&#39;,&gt;&gt;&gt;这个值复制刚刚让你记录的值 master_log_pos=1120;&gt;&gt;&gt;这个值复制刚刚让你记录的值 执行该 SQL 语句，启动 slave 同步：START SLAVE; 执行该 SQL 语句，查看从库机子同步状态：SHOW SLAVE STATUS; 在查看结果中必须下面两个值都是 Yes 才表示配置成功： Slave_IO_Running:Yes 如果不是 Yes 也不是 No，而是 Connecting，那就表示从机连不上主库，需要你进一步排查连接问题。 Slave_SQL_Running:Yes 如果你的 Slave_IO_Running 是 No，一般如果你是在虚拟机上测试的话，从库的虚拟机是从主库的虚拟机上复制过来的，那一般都会这样的，因为两台的 MySQL 的 UUID 值一样。你可以检查从库下的错误日志：cat /usr/program/mysql/data/mysql-error.log 如果里面提示 uuid 错误，你可以编辑从库的这个配置文件：vim /usr/program/mysql/data/auto.cnf，把配置文件中的：server-uuid 值随便改一下，保证和主库是不一样即可。 资料 http://www.cnblogs.com/xiongpq/p/3384681.html 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL 优化]]></title>
      <url>%2F2017%2F11%2F22%2FMysql-Optimize%2F</url>
      <content type="text"><![CDATA[MySQL 优化 下面说的优化基于 MySQL 5.6，理论上 5.5 之后的都算试用，具体还是要看官网 服务状态查询 查看当前数据库的状态，常用的有： 查看当前MySQL中已经记录了多少条慢查询，前提是配置文件中开启慢查询记录了. SHOW STATUS LIKE &#39;%slow_queries%&#39;; 查询当前MySQL中查询、更新、删除执行多少条了，可以通过这个来判断系统是侧重于读还是侧重于写，如果是写要考虑使用读写分离。 SHOW STATUS LIKE &#39;%Com_select%&#39;; SHOW STATUS LIKE &#39;%Com_update%&#39;; SHOW STATUS LIKE &#39;%Com_delete%&#39;; 显示MySQL服务启动运行了多少时间，如果MySQL服务重启，该时间重新计算，单位秒 SHOW STATUS LIKE &#39;uptime&#39;; 查询优化 使用 EXPLAIN 进行 SQL 语句分析：EXPLAIN SELECT * FROM sys_user; 得到的结果有下面几列： id，该列表示当前结果序号，无特殊意义，不重要 select_type，表示 SELECT 语句的类型，有下面几种 SIMPLE，表示简单查询，其中不包括连接查询和子查询 PRIMARY，表示主查询，或者是最外面的查询语句。比如你使用一个子查询语句，比如这条 SQL：EXPLAIN SELECT * FROM (SELECT sys_user_id FROM sys_user WHERE sys_user_id = 1) AS temp_table; 这条 SQL 有两个结果，其中有一个结果的类型就是 PRIMARY UNION，使用 UNION 的SQL是这个类型 DERIVED，在 SQL 中 From 后面子查询 SUBQUERY，子查询 还有其他一些 table，表名或者是子查询的一个结果集 type，表示表的链接类型，分别有（以下的连接类型的顺序是从最佳类型到最差类型）（这个属性重要）： 性能好： system，表仅有一行，这是const类型的特列，平时不会出现，这个也可以忽略不计。 const，数据表最多只有一个匹配行，因为只匹配一行数据，所以很快，常用于PRIMARY KEY或者UNIQUE索引的查询，可理解为const是最优化的。 eq_ref，mysql手册是这样说的:”对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型。它用在一个索引的所有部分被联接使用并且索引是UNIQUE(唯一键)也不是PRIMARY KEY(主键)”。eq_ref可以用于使用=比较带索引的列。 ref，查询条件索引既不是UNIQUE(唯一键)也不是PRIMARY KEY(主键)的情况。ref可用于=或&lt;或&gt;操作符的带索引的列。 ref_or_null，该联接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值的行。在解决子查询中经常使用该联接类型的优化。 性能较差： index_merge，该联接类型表示使用了索引合并优化方法。在这种情况下，key列包含了使用的索引的清单，key_len包含了使用的索引的最长的关键元素。 unique_subquery，该类型替换了下面形式的IN子查询的ref: value IN (SELECT primary_key FROM single_table WHERE some_expr)。unique_subquery 是一个索引查找函数,可以完全替换子查询,效率更高。 index_subquery，该联接类型类似于unique_subquery。可以替换IN子查询,但只适合下列形式的子查询中的非唯一索引: value IN (SELECT key_column FROM single_table WHERE some_expr) range，只检索给定范围的行,使用一个索引来选择行。 index，该联接类型与ALL相同,除了只有索引树被扫描。这通常比ALL快,因为索引文件通常比数据文件小。 性能最差： ALL，对于每个来自于先前的表的行组合,进行完整的表扫描。（性能最差） possible_keys，指出MySQL能使用哪个索引在该表中找到行。如果该列为NULL，说明没有使用索引，可以对该列创建索引来提供性能。（这个属性重要） key，显示MySQL实际决定使用的键(索引)。如果没有选择索引,键是NULL。（这个属性重要） key_len，显示MySQL决定使用的键长度。如果键是NULL,则长度为NULL。注意：key_len是确定了MySQL将实际使用的索引长度。 ref，显示使用哪个列或常数与key一起从表中选择行。 rows，显示MySQL认为它执行查询时必须检查的行数。（这个属性重要） Extra，该列包含MySQL解决查询的详细信息： Distinct:MySQL发现第1个匹配行后,停止为当前的行组合搜索更多的行。 Not exists:MySQL能够对查询进行LEFT JOIN优化,发现1个匹配LEFT JOIN标准的行后,不再为前面的的行组合在该表内检查更多的行。 range checked for each record (index map: #):MySQL没有发现好的可以使用的索引,但发现如果来自前面的表的列值已知,可能部分索引可以使用。 Using filesort:MySQL需要额外的一次传递,以找出如何按排序顺序检索行。 Using index:从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。 Using temporary:为了解决查询,MySQL需要创建一个临时表来容纳结果。 Using where:WHERE 子句用于限制哪一个行匹配下一个表或发送到客户。 Using sort_union(…), Using union(…), Using intersect(…):这些函数说明如何为index_merge联接类型合并索引扫描。 Using index for group-by:类似于访问表的Using index方式,Using index for group-by表示MySQL发现了一个索引,可以用来查 询GROUP BY或DISTINCT查询的所有列,而不要额外搜索硬盘访问实际的表。 了解对索引不生效的查询情况 （这个属性重要） 使用LIKE关键字的查询，在使用LIKE关键字进行查询的查询语句中，如果匹配字符串的第一个字符为“%”，索引不起作用。只有“%”不在第一个位置，索引才会生效。 使用联合索引的查询，MySQL可以为多个字段创建索引，一个索引可以包括16个字段。对于联合索引，只有查询条件中使用了这些字段中第一个字段时，索引才会生效。 使用OR关键字的查询，查询语句的查询条件中只有OR关键字，且OR前后的两个条件中的列都是索引列时，索引才会生效，否则，索引不生效。 子查询优化 MySQL从4.1版本开始支持子查询，使用子查询进行SELECT语句嵌套查询，可以一次完成很多逻辑上需要多个步骤才能完成的SQL操作。 子查询虽然很灵活，但是执行效率并不高。 执行子查询时，MYSQL需要创建临时表，查询完毕后再删除这些临时表，所以，子查询的速度会受到一定的影响。 优化： 可以使用连接查询（JOIN）代替子查询，连接查询时不需要建立临时表，其速度比子查询快。 数据库结构优化 将字段很多的表分解成多个表 对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。 因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。 增加中间表 对于需要经常联合查询的表，可以建立中间表以提高查询效率。 通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询。 增加冗余字段 设计数据表时应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设计看起来精致、优雅。但是，合理的加入冗余字段可以提高查询速度。 插入数据的优化（适用于 InnoDB） 插入数据时，影响插入速度的主要是索引、唯一性校验、一次插入的数据条数等。 开发环境情况下的考虑： 开发场景中，如果需要初始化数据，导入数据等一些操作，而且是开发人员进行处理的，可以考虑在插入数据之前，先禁用整张表的索引， 禁用索引使用 SQL：ALTER TABLE table_name DISABLE KEYS; 当导入完数据之后，重新让MySQL创建索引，并开启索引：ALTER TABLE table_name ENABLE KEYS; 如果表中有字段是有唯一性约束的，可以先禁用，然后在开启： 禁用唯一性检查的语句：SET UNIQUE_CHECKS = 0; 开启唯一性检查的语句：SET UNIQUE_CHECKS = 1; 禁用外键检查（建议还是少量用外键，而是采用代码逻辑来处理） 插入数据之前执行禁止对外键的检查，数据插入完成后再恢复，可以提供插入速度。 禁用：SET foreign_key_checks = 0; 开启：SET foreign_key_checks = 1; 使用批量插入数据 禁止自动提交 插入数据之前执行禁止事务的自动提交，数据插入完成后再恢复，可以提供插入速度。 禁用：SET autocommit = 0; 开启：SET autocommit = 1; 服务器优化 好硬件大家都知道，这里没啥好说 通过优化 MySQL 的参数可以提高资源利用率，从而达到提高 MySQL 服务器性能的目的。 可以看我整理的这篇文章：https://github.com/judasn/Linux-Tutorial/blob/master/MySQL-Settings/MySQL-5.6/1G-Memory-Machine/my-for-comprehensive.cnf 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[nmon]]></title>
      <url>%2F2017%2F11%2F22%2FNmon%2F</url>
      <content type="text"><![CDATA[nmon 系统性能监控工具的使用 nmon 说明 官网：http://nmon.sourceforge.net/pmwiki.php 分析工具 nmon analyser：https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/Power+Systems/page/nmon_analyser nmon是一种在AIX与各种Linux操作系统上广泛使用的监控与分析工具， nmon所记录的信息是比较全面的，它能在系统运行过程中实时地捕捉系统资源的使用情况，并且能输出结果到文件中。 下载/安装 Ubuntu：sudo apt-get install -y nmon CentOS：sudo yum install -y nmon，前提是你已经有安装 epel 源 或者使用 RPM 包：http://pan.baidu.com/s/1hsFEoeg 安装命令：rpm -ivh nmon-14i-8.el6.x86_64.rpm 分析工具 nmon analyser：http://pan.baidu.com/s/1pKBLXrX 运行 实时监控：nmon 后台监控：cd /opt ; nmon -f -s 10 -c 360 前面的 cd /opt 表示，进入 opt 目录，nmon 生成的文件是在当前目录下。 -f ：按标准格式输出文件名称：_YYYYMMDD_HHMM.nmon -s ：每隔n秒抽样一次，这里为10秒 -c ：取出多少个抽样数量，这里为360，即监控=10*360/3600=1小时 该命令启动后，nmon 会在当前目录下生成监控文件，并持续写入资源数据，直至360个监控点收集完成——即监控1小时，这些操作均自动完成，无需手工干预，测试人员可以继续完成其他操作。如果想停止该监控，需要通过 ps –ef|grep nmon 查询进程号，然后杀掉该进程以停止监控。 定期监控：本质是 crontab 加上后台监控命令 解析监控文件 把 nmon 文件转换成 csv 文件：sort localhost_120427_0922.nmon &gt; localhost_120427_0922.csv 把 csv 转换成 Excel 图表文件： 打开 nmon analyser 分析工具：nmon analyser v50_2.xlsm 点击 Analyse nmon data 会弹出一个弹出框，选择刚刚转换的 csv 文件，然后就会自动再转化成 excel 文件 资料 Nmon命令行：Linux系统性能的监测利器 性能监控和分析工具–nmon nmon以及nmon analyser 教程 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Yum 下载安装包及对应依赖包]]></title>
      <url>%2F2017%2F11%2F22%2FOff-line-Yum-Install%2F</url>
      <content type="text"><![CDATA[Yum 下载安装包及对应依赖包 安装 安装该软件：yum install -y yum-plugin-downloadonly 以下载 openssh-server 为例： yum install -y openssh-server --downloadonly --downloaddir=/opt/ssh 在 /opt/ssh 目录下有如下内容： -rw-r--r--. 1 root root 280524 Aug 13 2015 openssh-5.3p1-112.el6_7.x86_64.rpm -rw-r--r--. 1 root root 448872 Aug 13 2015 openssh-clients-5.3p1-112.el6_7.x86_64.rpm -rw-r--r--. 1 root root 331544 Aug 13 2015 openssh-server-5.3p1-112.el6_7.x86_64.rpm 安装下载的 rpm 文件：sudo rpm -ivh *.rpm 利用 yum 安装 rpm 文件，并自动满足依赖的 rpm 文件：sudo yum localinstall *.rpm 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nexus 安装和配置]]></title>
      <url>%2F2017%2F11%2F22%2FNexus-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[Nexus 安装和配置 Nexus 安装 Nexus 安装 官网：http://www.sonatype.org/nexus/ 官网下载：http://www.sonatype.org/nexus/archived/ 此时（20160207） Nexus 最新版本为：2.12.0-01 JDK 要求是 JDK 7，官网要求 7u6 或之后版本，包括 JDK 8 官网帮助说明 1：http://books.sonatype.com/nexus-book/2.11/reference/install.html 官网帮助说明 2：http://books.sonatype.com/sonatype-clm-book/html/clm-book/installation-configuration.html 我个人习惯 /opt 目录下创建一个目录 setups 用来存放各种软件安装包；在 /usr 目录下创建一个 program 用来存放各种解压后的软件包，下面的讲解也都是基于此习惯 我个人已经使用了第三方源：EPEL、RepoForge，如果你出现 yum install XXXXX 安装不成功的话，很有可能就是你没有相关源，请查看我对源设置的文章 压缩包下载（由于国内网络的原因不排除你下载不了）：wget http://download.sonatype.com/nexus/oss/nexus-2.12.0-01-bundle.tar.gz 如果地址下载不了，那是因为你需要开 VPN，你也可以选择降低要求下载 2.11.4-01 版本：http://pan.baidu.com/s/1mgSNJtA 解压压缩包：tar zxvf nexus-2.11.4-01-bundle.tar.gz 解压出来有两个文件夹： 这是程序目录：nexus-2.11.4-01 这是仓库目录：sonatype-work 移到目录到我的安装目录下：mv nexus-2.11.4-01/ /usr/program/ 进入安装目录：cd /usr/program/ 把目录名字改为更好看点：mv nexus-2.11.4-01/ nexus2.11.4/ 编辑系统配置文件：vim /etc/profile 在文件的尾巴增加下面内容： # Nexus NEXUS_HOME=/usr/program/nexus2.11.4 export NEXUS_HOME RUN_AS_USER=root export RUN_AS_USER 刷新配置：source /etc/profile 由于目录 sonatype-work 以后是做仓库用的，会存储很多 jar，所以这个目录一定要放在磁盘空间大的区内，目前我们还没第一次启动 Nexus，所以这里还是空文件 我个人习惯把这类目录放在 /opt 下，所以你要特别注意，下面有内容对这个文件夹进行操作的都是基于 opt 目录的：mv /opt/setup/sonatype-work/ /opt/ 设置配置文件：vim /usr/program/nexus2.11.4/conf/nexus.properties 把文件中该值：nexus-work=${bundleBasedir}/../sonatype-work/nexus 改为：nexus-work=/opt/sonatype-work/nexus 默认情况下如果你的 JDK 等系统变量设置好的是无需编辑 Nexus 的配置文件，但是这里还是给大家一下配置文件路径：vim /usr/program/nexus2.11.4/bin/jsw/conf/wrapper.conf 开放防火墙端口： 添加规则：sudo iptables -I INPUT -p tcp -m tcp --dport 8081 -j ACCEPT 保存规则：sudo /etc/rc.d/init.d/iptables save 重启 iptables：sudo service iptables restart 测试安装结果： 启动 Nexus：/usr/program/nexus2.11.4/bin/nexus start 查看启动日志：tail -200f /usr/program/nexus2.11.4/logs/wrapper.log 关闭 Nexus：/usr/program/nexus2.11.4/bin/nexus stop 访问：http://192.168.0.110:8081/nexus 登录账号密码： 账号密码：admin 密码：admin123 Nexus 配置 修改默认端口：vim /usr/program/nexus2.11.4/conf/nexus.properties，修改该值：application-port=8081 下载远程中央库的索引到服务器 如上图标注 4 所示，把默认是 False 改为 True 如上图 gif 所示，创建任务开始进行索引下载。需要特别提醒的是，如果你的私服是虚拟机，那得保证你分配的硬盘足够大，别像我一样吝啬只给 10 G（现在还剩下 1.9 G），结果报：设备上没有空间 项目上配置链接连接私服（下面内容涉及到 maven 的基础知识，请自行私下学习）： 对项目独立设置： 打开项目的 pom.xml 文件： 添加下面内容：&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;Nexus&lt;/id&gt; &lt;name&gt;虚拟机-192.168.0.110-Nexus&lt;/name&gt; &lt;url&gt;http://192.168.0.110:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; 对全局配置进行设置： 打开 maven 的 settings.xml 文件： 添加下面内容：&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;YouMeekNexus&lt;/id&gt; &lt;name&gt;YouMeek Nexus&lt;/name&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://192.168.0.110:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; 持续集成自动构建后发布到 Nexus 上 在 Maven 的 settings.xml 加上连接服务器信息： &lt;!--设置私库认证信息，用户名和密码我就用默认的，如果你们有权限控制的需求可以创建对应的一些账号--&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; 在项目的 pom.xml 文件加上： &lt;!-- nexus-releases nexus-snapshots 与 Maven 的配置文件 settings.xml 中 server 下的 id 对应 --&gt; &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Releases Repository&lt;/name&gt; &lt;url&gt;http://192.168.0.110:8081/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshots Repository&lt;/name&gt; &lt;url&gt;http://192.168.0.110:8081/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; Nexus 手动更新索引文件 手动更新索引 关闭 Nexus：/usr/program/nexus2.11.4/bin/nexus stop 命令：cd /opt/sonatype-work/nexus/indexer/central-ctx 删除里面默认的文件：rm -rf * 访问官网索引：http://repo.maven.apache.org/maven2/.index/ 下载文件：nexus-maven-repository-index.gz：wget http://repo.maven.apache.org/maven2/.index/nexus-maven-repository-index.gz 下载文件：nexus-maven-repository-index.properties：wget http://repo.maven.apache.org/maven2/.index/nexus-maven-repository-index.properties 下载索引解压工具：wget https://repo1.maven.org/maven2/org/apache/maven/indexer/indexer-cli/5.1.1/indexer-cli-5.1.1.jar 执行解压命令（该命令执行需要4分钟左右）：java -jar indexer-cli-5.1.0.jar -u nexus-maven-repository-index.gz -d ./ 删除解压前文件：rm -rf indexer-cli-5.1.0.jar nexus-maven-repository-index.gz nexus-maven-repository-index.properties 重启服务：/usr/program/nexus2.11.4/bin/nexus start 资料 http://www.cnblogs.com/leefreeman/p/4211530.html http://www.itdadao.com/article/89071/ http://blog.zhaojunling.me/p/17 http://m.blog.csdn.net/article/details?id=49228873 http://mritd.me/2015/12/29/Nexus-2-11-CentOS%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/ http://mritd.me/2015/12/28/Nexus-%E7%A7%81%E6%9C%8D%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/ http://my.oschina.net/liangbo/blog/195739 http://www.mamicode.com/info-detail-1016489.html http://blog.csdn.net/shawyeok/article/details/23564681 http://zyjustin9.iteye.com/blog/2017321 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RabbitMQ 安装和配置]]></title>
      <url>%2F2017%2F11%2F22%2FRabbitMQ-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[RabbitMQ 安装和配置 RabbitMQ 说明 MQ 全称为 Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。 RabbitMQ 是一个在 AMQP 基础上完整的，可复用的企业消息系统。他遵循 Mozilla Public License 开源协议。 RabbitMQ WIKI：https://zh.wikipedia.org/zh/RabbitMQ RabbitMQ 百科：http://baike.baidu.com/view/4095865.htm RabbitMQ 官网：http://www.rabbitmq.com/ RabbitMQ 官网下载：http://www.rabbitmq.com/download.html RabbitMQ 官网安装文档：http://www.rabbitmq.com/install-rpm.html RabbitMQ 文档： 优先：http://www.rabbitmq.com/getstarted.html 次要：http://www.rabbitmq.com/documentation.html 先安装 Erlang 有 EPEL 源的情况（需要安装的内容较多，宽带要能跟上）：sudo yum install erlang RabbitMQ 官网提供 Erlang 安装包： 下载地址：http://www.rabbitmq.com/releases/erlang/ 下载好之后，安装下面两个文件： sudo yum localinstall -y esl-erlang_18.1-1~centos~6_amd64.rpm sudo yum localinstall -y esl-erlang-compat-18.1-1.noarch.rpm 安装 RabbitMQ 此时（2016-04），最新版：3.6.1 安装：rpm --import https://www.rabbitmq.com/rabbitmq-signing-key-public.asc 安装：sudo yum install -y rabbitmq-server-3.6.1-1.noarch.rpm 启动服务： 先看下自己的主机名：hostname，我的主机名是：judasnHost2 先修改一下 host 文件：vim /etc/hosts，添加一行：127.0.0.1 judasnHost2（必须这样做） 启动：service rabbitmq-server start，启动一般都比较慢，所以别急 停止：service rabbitmq-server stop 重启：service rabbitmq-server restart 设置开机启动：chkconfig rabbitmq-server on 配置 查找默认配置位置：find / -name &quot;rabbitmq.config.example&quot;，我这边搜索结果是：/usr/share/doc/rabbitmq-server-3.6.1/rabbitmq.config.example 复制默认配置：cp /usr/share/doc/rabbitmq-server-3.6.1/rabbitmq.config.example /etc/rabbitmq/ 修改配置文件名：cd /etc/rabbitmq ; mv rabbitmq.config.example rabbitmq.config 编辑配置文件，开启用户远程访问：vim rabbitmq.config 在 64 行，默认有这样一句话：%% {loopback_users, []},，注意，该语句最后有一个逗号，等下是要去掉的 我们需要改为：{loopback_users, []}， 开启 Web 界面管理：rabbitmq-plugins enable rabbitmq_management 重启 RabbitMQ 服务：service rabbitmq-server restart 开放防火墙端口： sudo iptables -I INPUT -p tcp -m tcp --dport 15672 -j ACCEPT sudo iptables -I INPUT -p tcp -m tcp --dport 5672 -j ACCEPT sudo service iptables save sudo service iptables restart 浏览器访问：http://192.168.1.114:15672 默认管理员账号：guest 默认管理员密码：guest 添加新授权用户（如下图所示）： 添加 Host（如下图所示）： 给添加的 Host 设置权限（如下图所示）： 交换机绑定队列（如下图所示）： 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis 安装和配置]]></title>
      <url>%2F2017%2F11%2F22%2FRedis-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[Redis 安装和配置 Redis 安装 Redis 安装 官网：http://redis.io/ 官网下载：http://redis.io/download 官网 Github 地址：https://github.com/redis 此时（20160212） Redis 最新稳定版本为：3.0.7 官网帮助中心：http://redis.io/documentation 我个人习惯 /opt 目录下创建一个目录 setups 用来存放各种软件安装包；在 /usr 目录下创建一个 program 用来存放各种解压后的软件包，下面的讲解也都是基于此习惯 我个人已经使用了第三方源：EPEL、RepoForge，如果你出现 yum install XXXXX 安装不成功的话，很有可能就是你没有相关源，请查看我对源设置的文章 Redis 下载：wget http://download.redis.io/releases/redis-3.0.7.tar.gz （大小：1.4 M） 安装依赖包：yum install -y gcc-c++ tcl 解压：tar zxvf redis-3.0.7.tar.gz 移动到我个人安装目录：mv redis-3.0.7/ /usr/program/ 进入解压后目录：cd /usr/program/redis-3.0.7/ 编译：make 编译安装：make install 安装完之后会在：/usr/local/bin 目录下生成好几个 redis 相关的文件 复制配置文件：cp /usr/program/redis-3.0.7/redis.conf /etc/ 修改配置：vim /etc/redis.conf 把旧值：daemonize no 改为新值：daemonize yes 启动：/usr/local/bin/redis-server /etc/redis.conf 查看是否启动：ps -ef | grep redis 进入客户端：redis-cli 关闭客户端：redis-cli shutdown 开机启动配置：echo &quot;/usr/local/bin/redis-server /etc/redis.conf&quot; &gt;&gt; /etc/rc.local 开放防火墙端口： 添加规则：sudo iptables -I INPUT -p tcp -m tcp --dport 6379 -j ACCEPT 保存规则：sudo /etc/rc.d/init.d/iptables save 重启 iptables：sudo service iptables restart Redis 配置 编辑配置文件：vim /usr/program/redis-3.0.7/redis.conf Redis 默认的配置文件内容： # 是否以后台daemon方式运行，默认是 no，一般我们会改为 yes daemonize no pidfile /var/run/redis.pid port 6379 tcp-backlog 511 timeout 0 tcp-keepalive 0 loglevel notice logfile &quot;&quot; # 开启数据库的数量，Redis 是有数据库概念的，默认是 16 个，数字从 0 ~ 15 databases 16 save 900 1 save 300 10 save 60 10000 stop-writes-on-bgsave-error yes rdbcompression yes rdbchecksum yes dbfilename dump.rdb dir ./ slave-serve-stale-data yes slave-read-only yes repl-diskless-sync no repl-diskless-sync-delay 5 repl-disable-tcp-nodelay no slave-priority 100 appendonly no appendfilename &quot;appendonly.aof&quot; appendfsync everysec no-appendfsync-on-rewrite no auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb aof-load-truncated yes lua-time-limit 5000 slowlog-log-slower-than 10000 slowlog-max-len 128 latency-monitor-threshold 0 notify-keyspace-events &quot;&quot; hash-max-ziplist-entries 512 hash-max-ziplist-value 64 list-max-ziplist-entries 512 list-max-ziplist-value 64 set-max-intset-entries 512 zset-max-ziplist-entries 128 zset-max-ziplist-value 64 hll-sparse-max-bytes 3000 activerehashing yes client-output-buffer-limit normal 0 0 0 client-output-buffer-limit slave 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 hz 10 aof-rewrite-incremental-fsync yes Redis 常用命令 命令是不区分大小写的，但是这里为了方便和后面的 key value 进行区分所以我全部写大写，你也可以用小写。 但是需要注意的是：key 是完全区分大小写的，比如 key=codeBlog 和 key=codeblog 是两个键值 官网命令列表：http://redis.io/commands SET key value，设值。eg：SET myblog www.youmeek.com GET key，取值 INCR key，递增数字 DECR key，递减数字 KEYS *，查看当前数据库下所有的 key APPEND key value，给尾部追加内容，如果要追加的 key 不存在，则相当于 SET key value STRLEN key，返回键值的长度，如果键不存在则返回 0 MSET key1 value1 key2 value2，同时设置多值 MGET key1 value1 key2 value2，同时取多值 EXPIRE key 27，设置指定键的生存时间，27 的单位是秒 TTL key，查看键的剩余生存时间 返回 -2，表示不存在，过了生存时间后被删除 返回 -1，表示没有生存时间，永久存储 返回正整数，表示还剩下对应的生存时间 PERSIST key，清除生成时间，重新变成永久存储（重新设置 key 的值也可以起到清除生存时间的效果） FLUSHDB，清空当前数据库所有键值 FLUSHALL，清空所有数据库的所有键值 Redis 客户端 Java：http://redis.io/clients#java Jedis 官网：https://github.com/xetorthio/jedis Redis GUI 管理工具 Redis Desktop Manager 官网：http://redisdesktop.com/ 官网下载：http://redisdesktop.com/download 效果如下图： Redis 主从（主从从）配置Redis 主从架构 假设有两台服务器，一台做主，一台做从 Redis 主信息： IP：12.168.1.114= 端口：6379 Redis 从信息： IP：12.168.1.115 端口：6379 编辑从机的 Redis 配置文件，找到 210 行（大概），默认这一行应该是注释的：# slaveof &lt;masterip&gt; &lt;masterport&gt; 我们需要去掉该注释，并且填写我们自己的主机的 IP 和 端口，比如：slaveof 192.168.1.114 6379 配置完成后重启从机 Redis 服务 重启完之后，进入主机的 redis-cli 状态下，输入：INFO replication 可以查询到当前主机的 redis 处于什么角色，有哪些从机已经连上主机。 此时已经完成了主从配置，我们可以测试下： 我们进入主机的 redis-cli 状态，然后 set 某个值，比如：set myblog YouMeek.com 我们切换进入从机的 redis-cli 的状态下，获取刚刚设置的值看是否存在：get myblog，此时，我们可以发现是可以获取到值的。 但是有一个需要注意的：从库不具备写入数据能力，不然会报错。 从库只有只读能力。 Redis主从从架构 Redis 主从从的意思：看桌面上的截图。 优点，除了减少主库连接的压力，还有可以关掉主库的持久化功能，把持久化的功能交给从库进行处理。 第一个从库配置的信息是连上主库，后面的第二个从库配置的连接信息是连上第一个从库， 假如还有第三个从库的话，我们可以把第三个从库的配置信息连上第二个从库上，以此类推。 资料 http://yanshisan.blog.51cto.com/7879234/1377992 https://segmentfault.com/a/1190000002685224 http://itbilu.com/linux/management/4kB2ninp.html http://keenwon.com/1335.html 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Rap 安装和配置]]></title>
      <url>%2F2017%2F11%2F22%2FRap-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[Rap 安装和配置本机环境 系统：CentOS 6.7 64 位 MySQL 5.6 JDK 1.8 Tomcat 8 Redis 3.0.7 Rap 0.14.1 Rap 说明 官网：https://github.com/thx/RAP 在线版：http://rap.taobao.org/ 官网 Wiki：https://github.com/thx/RAP/wiki/home_cn 官网部署手册：https://github.com/thx/RAP/wiki/deploy_manual_cn 用户手册：https://github.com/thx/RAP/wiki/user_manual_cn 下载 官网下载：https://github.com/thx/RAP/releases 当前最新版本：0.14.1 下载 war 部署包：https://github.com/thx/RAP/releases 安装 MySQL、JDK、Tomcat、Redis MySQL 安装和配置 JDK 安装 Tomcat 安装和配置、优化 Redis 安装和配置 安装 Rap 创建数据库，并创建权限用户 CREATE DATABASE `rap_db` CHARACTER SET utf8; CREATE USER &#39;rap&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;; GRANT ALL PRIVILEGES ON rap_db.* TO &#39;rap&#39;@&#39;%&#39;; FLUSH PRIVILEGES; 把 RAP-0.14.1-SNAPSHOT.war 移动到 tomcat 的 webapp 目录下，删除其他多余的文件夹 解压：unzip -x RAP-0.14.1-SNAPSHOT.war -d ROOT 初始化数据库：mysql -u rap -p rap_db &lt; /usr/program/tomcat8/webapps/ROOT/WEB-INF/classes/database/initialize.sql 修改连接数据库的配置信息：vim /usr/program/tomcat8/webapps/ROOT/WEB-INF/classes/config.properties 停掉防火墙：service iptables stop 启动 Redis：/usr/local/bin/redis-server /etc/redis.conf 启动 Tomcat：sh /usr/program/tomcat8/bin/startup.sh ; tail -200f /usr/program/tomcat8/logs/catalina.out 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx 安装和配置]]></title>
      <url>%2F2017%2F11%2F22%2FNginx-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[Nginx 安装和配置 Nginx 说明 Nginx 是一个很强大的高性能 Web 和反向代理服务器，常被我们用作负载均衡服务器，也可以作为邮件代理服务器 Nginx WIKI：https://zh.wikipedia.org/zh/Nginx Nginx 百科：http://baike.baidu.com/item/nginx Nginx 官网：http://nginx.org/en/ Nginx 官网下载：http://nginx.org/en/download.html 源码包方式下载：http://nginx.org/en/download.html，注意该页面的：Stable version，这个表示稳定版本，2016-03-22 最新版本是：nginx-1.8.1，这是一个 tar.gz 的文件链接。 构建包方式下载：http://nginx.org/en/linux_packages.html#stable Nginx 文档： 优先：https://www.nginx.com/resources/wiki/ 次要：http://nginx.org/en/docs/ Nginx 模块地址：https://www.nginx.com/resources/wiki/modules/ 来自网络上的一个好介绍 来源：https://help.aliyun.com/knowledge_detail/6703521.html?spm=5176.788314854.2.2.CdMGlB 传统上基于进程或线程模型架构的 Web 服务通过每进程或每线程处理并发连接请求，这势必会在网络和 I/O 操作时产生阻塞，其另一个必然结果则是对内存或 CPU 的利用率低下。生成一个新的进程/线程需要事先备好其运行时环境，这包括为其分配堆内存和栈内存，以及为其创建新的执行上下文等。这些操作都需要占用 CPU，而且过多的进程/线程还会带来线程抖动或频繁的上下文切换，系统性能也会由此进一步下降。 在设计的最初阶段，Nginx 的主要着眼点就是其高性能以及对物理计算资源的高密度利用，因此其采用了不同的架构模型。受启发于多种操作系统设计中基于“事件”的高级处理机制，nginx采用了模块化、事件驱动、异步、单线程及非阻塞的架构，并大量采用了多路复用及事件通知机制。在 Nginx 中，连接请求由为数不多的几个仅包含一个线程的进程 Worker 以高效的回环(run-loop)机制进行处理，而每个 Worker 可以并行处理数千个的并发连接及请求。 如果负载以 CPU 密集型应用为主，如 SSL 或压缩应用，则 Worker 数应与 CPU 数相同；如果负载以 IO 密集型为主，如响应大量内容给客户端，则 Worker 数应该为 CPU 个数的 1.5 或 2 倍。 Nginx会按需同时运行多个进程：一个主进程(Master)和几个工作进程(Worker)，配置了缓存时还会有缓存加载器进程(Cache Loader)和缓存管理器进程(Cache Manager)等。所有进程均是仅含有一个线程，并主要通过“共享内存”的机制实现进程间通信。主进程以root用户身份运行，而 Worker、Cache Loader 和 Cache manager 均应以非特权用户身份运行。 主进程主要完成如下工作： 1.读取并验正配置信息； 2.创建、绑定及关闭套接字； 3.启动、终止及维护worker进程的个数； 4.无须中止服务而重新配置工作特性； 5.控制非中断式程序升级，启用新的二进制程序并在需要时回滚至老版本； 6.重新打开日志文件，实现日志滚动； 7.编译嵌入式perl脚本； Worker 进程主要完成的任务包括： 1.接收、传入并处理来自客户端的连接； 2.提供反向代理及过滤功能； 3.nginx任何能完成的其它任务； Cache Loader 进程主要完成的任务包括： 1.检查缓存存储中的缓存对象； 2.使用缓存元数据建立内存数据库； Cache Manager 进程的主要任务： 1.缓存的失效及过期检验； Nginx 源码编译安装 官网下载最新稳定版本 1.8.1，大小：814K 官网安装说明：https://www.nginx.com/resources/wiki/start/topics/tutorials/install/ 源码编译配置参数说明： https://www.nginx.com/resources/wiki/start/topics/tutorials/installoptions/ http://nginx.org/en/docs/configure.html 开始安装： 安装依赖包：yum install -y gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel 预设几个文件夹，方便等下安装的时候有些文件可以进行存放： mkdir -p /usr/local/nginx /var/log/nginx /var/temp/nginx /var/lock/nginx 下载源码包：`wget http://nginx.org/download/nginx-1.8.1.tar.gz 解压：tar zxvf nginx-1.8.1.tar.gz 进入解压后目录：cd nginx-1.8.1/ 编译配置： ./configure \ --prefix=/usr/local/nginx \ --pid-path=/var/local/nginx/nginx.pid \ --lock-path=/var/lock/nginx/nginx.lock \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --with-http_gzip_static_module \ --http-client-body-temp-path=/var/temp/nginx/client \ --http-proxy-temp-path=/var/temp/nginx/proxy \ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \ --http-scgi-temp-path=/var/temp/nginx/scgi 编译：make 安装：make install 启动 Nginx 先检查是否在 /usr/local 目录下生成了 Nginx 等相关文件：cd /usr/local/nginx;ll，正常的效果应该是显示这样的： drwxr-xr-x. 2 root root 4096 3月 22 16:21 conf drwxr-xr-x. 2 root root 4096 3月 22 16:21 html drwxr-xr-x. 2 root root 4096 3月 22 16:21 sbin 停止防火墙：service iptables stop 或是把 80 端口加入到的排除列表： sudo iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT sudo service iptables save sudo service iptables restart 启动：/usr/local/nginx/sbin/nginx，启动完成 shell 是不会有输出的 检查 时候有 Nginx 进程：ps aux | grep nginx，正常是显示 3 个结果出来 检查 Nginx 是否启动并监听了 80 端口：netstat -ntulp | grep 80 访问：192.168.1.114，如果能看到：Welcome to nginx!，即可表示安装成功 检查 Nginx 启用的配置文件是哪个：/usr/local/nginx/sbin/nginx -t 刷新 Nginx 配置后重启：/usr/local/nginx/sbin/nginx -s reload 停止 Nginx：/usr/local/nginx/sbin/nginx -s stop 如果访问不了，或是出现其他信息看下错误立即：vim /var/log/nginx/error.log 把 Nginx 添加到系统服务中 新建文件：vim /etc/init.d/nginx 添加如下内容： #!/bin/bash #nginx执行程序路径需要修改 nginxd=/usr/local/nginx/sbin/nginx # nginx配置文件路径需要修改 nginx_config=/usr/local/nginx/conf/nginx.conf # pid 地址需要修改 nginx_pid=/var/local/nginx/nginx.pid RETVAL=0 prog=&quot;nginx&quot; # Source function library. . /etc/rc.d/init.d/functions # Source networking configuration. . /etc/sysconfig/network # Check that networking is up. [ ${NETWORKING} = &quot;no&quot; ] &amp;&amp; exit 0 [ -x $nginxd ] || exit 0 # Start nginx daemons functions. start() { if [ -e $nginx_pid ];then echo &quot;nginx already running....&quot; exit 1 fi echo -n $&quot;Starting $prog: &quot; daemon $nginxd -c ${nginx_config} RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch /var/lock/subsys/nginx return $RETVAL } # Stop nginx daemons functions. # pid 地址需要修改 stop() { echo -n $&quot;Stopping $prog: &quot; killproc $nginxd RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f /var/lock/subsys/nginx /var/local/nginx/nginx.pid } # reload nginx service functions. reload() { echo -n $&quot;Reloading $prog: &quot; #kill -HUP `cat ${nginx_pid}` killproc $nginxd -HUP RETVAL=$? echo } # See how we were called. case &quot;$1&quot; in start) start ;; stop) stop ;; reload) reload ;; restart) stop start ;; status) status $prog RETVAL=$? ;; *) echo $&quot;Usage: $prog {start|stop|restart|reload|status|help}&quot; exit 1 esac exit $RETVAL 修改权限：chmod 755 /etc/init.d/nginx 启动服务：service nginx start 停止服务：service nginx stop 重启服务：service nginx restart Nginx 配置 Nginx 默认配置文件：vim /usr/local/nginx/conf/nginx.conf Nginx 在 1.8.1 版本下的默认配置（去掉注释）worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } HTTP 服务，虚拟主机 停止防火墙：service iptables stop，防止出现特别干扰 编辑默认的配置文件：vim /usr/local/nginx/conf/nginx.conf 设置两个虚拟主机（通过端口来区分开） worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # 一个 server 代表一个虚拟主机 server { listen 80; server_name localhost; location / { # 虚拟机根目录是 /usr/local/nginx/html 目录 root html; # 虚拟机首页是 /usr/local/nginx/html 目录下这两个文件 index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } server { # 第二个虚拟机的端口是 90，服务地址还是本地 listen 90; server_name localhost; location / { root html90; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } 设置两个虚拟主机（通过域名来区分开） worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # 一个 server 代表一个虚拟主机 server { listen 80; # 两个虚拟主机都使用 80 端口，设置不同域名 server_name code.youmeek.com; location / { # 虚拟机根目录是 /usr/local/nginx/html 目录 root html; # 虚拟机首页是 /usr/local/nginx/html 目录下这两个文件 index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } server { listen 80; # 两个虚拟主机都使用 80 端口，设置不同域名 server_name i.youmeek.com; location / { root html-i; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } 反向代理和负载均衡 最精简的环境：一台虚拟机 1 个 JDK 1 个 Nginx 2 个 Tomcat Nginx 配置： worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # 自己定义的两个 tomcat 请求地址和端口 # 也就是当浏览器请求：tomcat.youmeek.com 的时候从下面这两个 tomcat 中去找一个进行转发 upstream tomcatCluster { server 192.168.1.114:8080; server 192.168.1.114:8081; # 添加 weight 字段可以表示权重，值越高权重越大，默认值是 1，最大值官网没说，一般如果设置也就设置 3,5,7 这样的数 # 官网：https://www.nginx.com/resources/admin-guide/load-balancer/#weight # server 192.168.1.114:8080 weight=2; # server 192.168.1.114:8081 weight=1; } server { listen 80; server_name tomcat.youmeek.com; location / { proxy_pass http://tomcatCluster; index index.html index.htm; } } } HTTP 服务，绑定多个域名 https://www.ttlsa.com/nginx/use-nginx-proxy/ 安装第三方模块生成规格图启用 Gzip 压缩防盗链 https://help.aliyun.com/knowledge_detail/5974693.html?spm=5176.788314853.2.18.s4z1ra Nginx 禁止特定用户代理（User Agents）访问，静止指定 IP 访问 https://www.ttlsa.com/nginx/how-to-block-user-agents-using-nginx/ https://help.aliyun.com/knowledge_detail/5974693.html?spm=5176.788314853.2.18.s4z1ra &lt;&gt; &lt;&gt; &lt;&gt; Nginx 缓存Nginx 自动分割日志文件Nginx 处理跨域请求安全相预防在配置文件中设置自定义缓存以限制缓冲区溢出攻击的可能性client_body_buffer_size 1K;client_header_buffer_size 1k;client_max_body_size 1k;large_client_header_buffers 2 1k; 将timeout设低来防止DOS攻击所有这些声明都可以放到主配置文件中。client_body_timeout 10;client_header_timeout 10;keepalive_timeout 5 5;send_timeout 10; 限制用户连接数来预防DOS攻击limit_zone slimits $binary_remote_addr 5m;limit_conn slimits 5; 杂七杂八 nginx实现简体繁体字互转以及中文转拼音 nginx记录分析网站响应慢的请求(ngx_http_log_request_speed) nginx空白图片(empty_gif模块) 资料 https://help.aliyun.com/knowledge_detail/5974693.html?spm=5176.788314853.2.18.s4z1ra http://www.ydcss.com/archives/466 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SSH]]></title>
      <url>%2F2017%2F11%2F22%2FSSH%2F</url>
      <content type="text"><![CDATA[SSH（Secure Shell）介绍 SSH 安装 查看是否已安装： CentOS：rpm -qa | grep openssh Ubuntu：dpkg -l | grep openssh 安装： CentOS 6：sudo yum install -y openssh-server openssh-clients Ubuntu：sudo apt-get install -y openssh-server openssh-client SSH 配置文件常用参数 配置文件介绍（记得先备份）：sudo vim /etc/ssh/sshd_config Port 22 #默认指定 22 端口，可以自己修改 Protocol 2,1 #指定了 SSH 协议版本，目前 SSH 只有两个版本 2 和 1 PasswordAuthentication yes #是否开启密码验证，因为 SSH 也可以设置秘钥类授权登录的方式，如果用这种方式我们可以考虑关掉密码登录的方式。 PermitEmptyPasswords no #是否允许密码为空，与上面参数配合用。 SSH 允许 root 账户登录 编辑配置文件（记得先备份）：sudo vim /etc/ssh/sshd_config 允许 root 账号登录 注释掉：PermitRootLogin without-password 新增一行：PermitRootLogin yes SSH 密钥登录 生成秘钥和公钥文件，命令：sudo ssh-keygen，在交互提示中连续按三次回车，如果看得懂交互的表达，那就根据你自己需求来。默认生成密钥和公钥文件是在：/root/.ssh。 进入生成目录：cd /root/.ssh，可以看到有两个文件：id_rsa (私钥) 和 id_rsa.pub (公钥) 在 .ssh 目录下创建 SSH 认证文件，命令：touch /root/.ssh/authorized_keys 将公钥内容写到SSH认证文件里面，命令：cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys 修改SSH认证文件权限，命令： sudo chmod 700 /root/.ssh sudo chmod 600 /root/.ssh/authorized_keys 重启服务：sudo service ssh restart 设置 SSH 服务默认启动：sudo sysv-rc-conf ssh on 现在 SSH 客户端可以去拿着 SSH 服务器端上的 id_rsa，在客户端指定秘钥文件地址即可，这个一般由于你使用的客户端决定的，我这里推荐的是 Xshell 软件。 SSH 资料 http://www.jikexueyuan.com/course/861_1.html?ss=1 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[VMware 克隆 CentOS 后网卡信息修改]]></title>
      <url>%2F2017%2F11%2F22%2FCentOS-Virtual-Machine-Copy-Settings%2F</url>
      <content type="text"><![CDATA[VMware 克隆 CentOS 后网卡信息修改 概述 在我们需要多台 CentOS 虚拟机的时候，对已有虚拟机的系统进行克隆或是复制。但是这样做又有一个问题，克隆出来的虚拟机启动的时候你输入命令：ifconfig，eth0 网卡信息没了，只有一个 eth1。 对于处女座的人来讲这是不允许的。所以我们需要改动下。 复制虚拟机后，首次打开该会提示如下内容，一般选择 copy 这个配置。 修改方法 命令：sudo vim /etc/udev/rules.d/70-persistent-net.rules 该文件中正常此时应该有两行信息 在文件中把 NAME=”eth0″ 的这一行注释掉 对于另一行，把 NAME=”eth1″ 的这一行，把 NAME=”eth1″ 改为 NAME=”eth0″，并且把该行：ATTRS{address}==”00:0c:29:4c:46:01″ 这个属性信息记下来，每台机子都不一样，我这段信息只是例子，你不要直接复制我的。 命令：sudo vim /etc/sysconfig/network-scripts/ifcfg-eth0 修改 IP 地址 把 HWADDR 的值改为上面要求记下来的：00:0c:29:4c:46:01 命令：nmcli con 如果显示两行 UUID 的信息的话，复制不是 System eth0 的那个 UUID 值，下面有用。 编辑：sudo vim /etc/sysconfig/network-scripts/ifcfg-eth0 把文件中的 UUID 值 改为上面要求复制的 UUID 值。 保存配置文件，重启系统，正常应该是可以了。 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[iptables]]></title>
      <url>%2F2017%2F11%2F22%2FCentOS-Install%2F</url>
      <content type="text"><![CDATA[CentOS 安装概括 本教程中主要演示了 VirtualBox 和 VMware Workstation 下安装 CentOS 6.6 的过程。 VirtualBox 是免费开源，我个人在使用经历中遇到过很多次崩溃、安装有问题等，所以它不是我主推的虚拟机 VMware Workstation 是商业软件，很好用，一些辅助功能也很到位，主推该虚拟机。 VirtualBox 下安装 CentOS 过程 VirtualBox 的介绍和下载 官网：https://www.virtualbox.org/ wiki：https://zh.wikipedia.org/zh/VirtualBox 百度 wiki：http://baike.baidu.com/view/1047853.htm 百度云下载（32 位和 64 位一体）：http://pan.baidu.com/s/1kTR3hOj 官网下载：https://www.virtualbox.org/wiki/Downloads 安装细节开始： 如上图标注 1 所示：点击 新建 一个虚拟机。 如上图标注 2 所示：在填写 名称 的时候，输入 CentOS 相关字眼的时候，下面的版本类型会跟着变化，自动识别为 Red Hat 如上图标注 1 所示：我们装的是 64 位系统，如果你本机内存足够大，建议可以给 2 ~ 4 G 的容量 如上图所示，命名最好规范，最好要带上系统版本号，硬盘大小建议在 8 ~ 20 G 如上图 gif 演示，当我们创建好虚拟机之后，需要选择模拟光驱进行系统镜像安装 如上图箭头所示，我们这里选择 Skip，跳过对镜像的检查，这个一般需要检查很久，而且我们用 iso 文件安装的，一般没这个必要 如上图标注 1 所示，建议 Linux 纯新手使用简体中文环境 如上图标注 1 所示，因为我们是用全新的虚拟机，虚拟出来的硬盘都是空的，所以这里可以忽略所有数据 再次强调下，root 账号也就是图上所说的 根账号，它是最顶级账号，密码最好别忘记了 如上图标注 1 所示，因为我们是用全新的虚拟机，所以这里选择 使用所有空间 ，然后 CentOS 会按它默认的方式进行分区 Desktop 代表：图形界面版，会默认安装很多软件，建议新手选择此模式，我后面其他文章的讲解都是基于此系统下，如果你不是此模式的系统可能在安装某些软件的时候会出现某些依赖包没有安装的情况 basic sever 代表：命令行界面，有良好基础的基本都会喜欢这个 上一步我选择的是 Desktop 所以有很多软件需要安装，这个过程大概需要 5 ~ 10 分钟 安装完成 安装完成后一定要把盘片删除，防止系统启动的时候去读盘，重新进入安装系统模式 VMware 下安装 CentOS 过程 VMware Workstation 的介绍和下载 官网：https://www.vmware.com/products/workstation wiki：https://zh.wikipedia.org/wiki/VMware_Workstation 百度 wiki：http://baike.baidu.com/view/555554.htm 百度云下载（64 位）：http://pan.baidu.com/s/1eRuJAFK 官网下载：http://www.vmware.com/products/workstation/workstation-evaluation 安装细节开始： 默认 VMware 选择的是 典型 我不推荐，我下面的步骤是选择 自定义（高级）。如果你非常了解 Linux 系统倒是可以考虑选择 典型，在它默认安装完的系统上可以很好地按你的需求进行修改 牢记：不要在这一步就选择镜像文件，不然也会直接进入 典型 模式，直接按它的规则进行系统安装 桥接模式：（建议选择此模式）创建一个独立的虚拟主机，在桥接模式下的虚拟主机网络一般要为其配 IP 地址、子网掩码、默认网关（虚拟机ip地址要与主机ip地址处于同网段） NAT 模式：把物理主机作为路由器进行访问互联网，优势:联网简单，劣势:虚拟主机无法与物理主机通讯 主机模式：把虚拟主机网络与真实网络隔开，但是各个虚拟机之间可以互相连接，虚拟机和物理机也可以连接 上面解释来源：http://jingyan.baidu.com/article/3f16e003cd0a0d2591c103b4.html Buslogic 和 LSIlogic 都是虚拟硬盘 SCSI 设备的类型，旧版本的 OS 默认的是 Buslogic，LSIlogic 类型的硬盘改进了性能，对于小文件的读取速度有提高，支持非 SCSI 硬盘比较好。 上面解释来源：http://www.cnblogs.com/R-zqiang/archive/2012/11/23/2785134.html 强烈建议至少要给 20 G，不然装不了多少软件的 如上图 gif 所示，在创建完虚拟机之后，我们要加载系统镜像，然后启动虚拟机进行安装，接下来的安装步骤跟上面使用 VirtualBox 安装细节基本一样，不一样的地方是我这里选择的是自定义分区，不再是选择默认分区方式 如上图箭头所示，这里我们选择自定义分区方式 如上图 gif 所示，我只把最基本的区分出来，如果你有自己的需求可以自己设置 简单分区方案： /boot == 500 M（主分区） /swap == 2 G（逻辑分区）一般大家的说法这个大小是跟你机子的内存大小相关的，也有说法内存大不需要这个，但是还是建议分，虚拟机内存 2 G，所以我分 2 G / == 剩余容量（逻辑分区）剩余的空间都给了根分区 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[iptables]]></title>
      <url>%2F2017%2F11%2F22%2FSamba%2F</url>
      <content type="text"><![CDATA[Samba 介绍 Samba 安装 查看是否已安装： CentOS：rpm -qa | grep samba Ubuntu：dpkg -l | grep samba 安装： CentOS 6：XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Ubuntu：sudo apt-get install -y samba samba-client Samba 服务器配置文件常用参数 配置文件介绍（记得先备份）：sudo vim /etc/samba/smb.conf 该配置解释： 在 [globle] 区域 workgroup = WORKGROUP #WORKGROUP表示Windows默认的工作组名称，一般共享给windows是设置为WORKGROUP security = user #ubuntu下配置文件默认没有这句,这个是自己填上去的。表示指定samba的安全等级，安全等级分别有四种：share（其他人不需要账号密码即可访问共享目录）、user（检查账号密码）、server（表示检查密码由另外一台服务器负责）、domain（指定Windows域控制服务器来验证用户的账号和密码） 在新区域区域 当 security = share 使用下面这段，这段自己添加的，其中myshare这个名字表示其他机子访问该分享地址时用：file://该服务机IP/myshare[myshare] comment = share all path = /opt/mysamba #分享的目录，其中这个目录需要chmod 777 /opt/mysamba权限 browseable = yes writable = yes public =yes 当 security = user 使用下面这段，这段自己添加的，其中 myshare2 这个名字表示其他机子访问该分享地址时用：file://该服务机IP/myshare2 可以返回的账号必须是系统已经存在的账号。先给系统添加账号：useradd user1，再用samba的设置添加账号：pdbedit -a user1，会让你设立该samba账号密码。列出账号：pdbedit -L[myshare2] comment = share for users path = /opt/mysamba2 #分享的目录，其中这个目录需要chmod 777 /opt/mysamba权限 browseable = yes writable = yes public = no 启动服务： sudo service samba restart Samba 资料 http://www.lvtao.net/linux/555.html https://www.centos.bz/2011/07/centos5-install-samba-windows-linux-fileshare/ https://wsgzao.github.io/post/samba/ http://linux.vbird.org/linux_server/0370samba.php 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title></title>
      <url>%2F2017%2F11%2F22%2Fcentos-settings%2FClose-XWindow%2F</url>
      <content type="text"><![CDATA[CentOS 图形界面的关闭与开启初衷 本地开多个虚拟机搞集群测试，为了节省资源，关掉图形界面更好点 设置方法 编辑配置文件：vim /etc/inittab 把默认值：id:5:initdefault:，改为：id:3:initdefault: 重启系统：reboot，重启后就只有 shell 界面了。 在 shell 界面中如果你还希望临时开启图形界面可以输入：init 5 在图形界面中如果你希望临时关闭图形界面可以输入：init 3]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[FTP]]></title>
      <url>%2F2017%2F11%2F22%2FFTP%2F</url>
      <content type="text"><![CDATA[FTP（File Transfer Protocol）介绍 FTP 安装 查看是否已安装： CentOS：rpm -qa | grep vsftpd Ubuntu：dpkg -l | grep vsftpd 安装： CentOS 6：sudo yum install -y vsftpd Ubuntu：sudo apt-get install -y vsftpd FTP 使用之前要点 关闭 CentOS 上的 SELinux 组件（Ubuntu 体系是没有这东西的）。 查看 SELinux 开启状态：sudo getenforce 有如下三种状态，默认是 Enforcing Enforcing（开启） Permissive（开启，但是只起到警告作用，属于比较轻的开启） Disabled（关闭） 临时关闭： 命令：sudo setenforce 0 临时开启： 命令：sudo setenforce 1 永久关闭： 命令：sudo vim /etc/selinux/config 将：SELINUX=enforcing 改为 SELINUX=disbaled，配置好之后需要重启系统。 FTP 服务器配置文件常用参数 vsftpd 默认是支持使用 Linux 系统里的账号进行登录的（登录上去可以看到自己的 home 目录内容），权限跟 Linux 的账号权限一样。但是建议使用软件提供的虚拟账号管理体系功能，用虚拟账号登录。 配置文件介绍（记得先备份）：sudo vim /etc/vsftpd/vsftpd.conf，比较旧的系统版本是：vim /etc/vsftpd.conf 该配置主要参数解释： anonymous_enable=NO #不允许匿名访问，改为YES即表示可以匿名登录 anon_upload_enable=YES #是否允许匿名用户上传 anon_mkdir_write_enable=YES #是否允许匿名用户创建目录 local_enable=YES #是否允许本地用户，也就是linux系统的已有账号，如果你要FTP的虚拟账号，那可以改为NO write_enable=YES #是否允许本地用户具有写权限 local_umask=022 #本地用户掩码 chroot_list_enable=YES #不锁定用户在自己的家目录，默认是注释，建议这个一定要开，比如本地用户judasn，我们只能看到/home/judasn，没办法看到/home目录 chroot_list_file=/etc/vsftpd/chroot_list #该选项是配合上面选项使用的。此文件中的用户将启用 chroot，如果上面的功能开启是不够的还要把用户名加到这个文件里面。配置好后，登录的用户，默认登录上去看到的根目录就是自己的home目录。 listen=YES #独立模式 userlist_enable=YES #用户访问控制，如果是YES，则表示启用vsftp的虚拟账号功能，虚拟账号配置文件是/etc/vsftpd/user_list userlist_deny=NO #这个属性在配置文件是没有的，当userlist_enable=YES，这个值也为YES，则user_list文件中的用户不能登录FTP，列表外的用户可以登录，也可以起到一个黑名单的作用。当userlist_enable=YES，这个值为NO，则user_list文件中的用户能登录FTP，列表外的用户不可以登录，也可以起到一个白名单的作用。如果同一个用户即在白名单中又在ftpusers黑名单文件中，那还是会以黑名单为前提，对应账号没法登录。 tcp_wrappers=YES #是否启用TCPWrappers管理服务 FTP用户黑名单配置文件：sudo vim /etc/vsftpd/ftpusers，默认root用户也在黑名单中 控制FTP用户登录配置文件：sudo vim /etc/vsftpd/user_list 启动服务： service vsftpd restart vsftpd 的两种传输模式 分为：主动模式（PORT）和被动模式（PASV）。这两个模式会涉及到一些端口问题，也就涉及到防火墙问题，所以要特别注意。主动模式比较简单，只要在防火墙上放开放开 21 和 20 端口即可。被动模式则要根据情况放开一个端口段。 上图箭头：xftp 新建连接默认都是勾选被动模式的，所以如果要使用主动模式，在该连接的属性中是要去掉勾选。 vsftpd 的两种运行模式 分为：xinetd 模式和 standalone 模式 xinetd 模式：由 xinetd 作为 FTP 的守护进程，负责 21 端口的监听，一旦外部发起对 21 端口的连接，则调用 FTP 的主程序处理，连接完成后，则关闭 FTP 主程序，释放内存资源。好处是资源占用少，适合 FTP 连接数较少的场合。 standalone 模式：直接使用 FTP 主程序作为 FTP 的守护进程，负责 21 端口的监听，由于无需经过 xinetd 的前端代理，响应速度快，适合连接数 较大的情况，但由于 FTP 主程序长期驻留内存，故较耗资源。 standalone 一次性启动，运行期间一直驻留在内存中，优点是对接入信号反应快，缺点是损耗了一定的系统资源，因此经常应用于对实时反应要求较高的 专业 FTP 服务器。 xinetd 恰恰相反，由于只在外部连接发送请求时才调用 FTP 进程，因此不适合应用在同时连接数量较多的系统。此外，xinetd 模式不占用系统资源。除了反应速度和占用资源两方面的影响外，vsftpd 还提供了一些额外的高级功能，如 xinetd 模式支持 per_IP (单一 IP)限制，而 standalone 模式则更有利于 PAM 验证功能的应用。 配置 xinetd 模式： 编辑配置文件：sudo vim /etc/xinetd.d/vsftpd 属性信息改为如下信息： disable = no socket_type = stream wait = no #这表示设备是激活的，它正在使用标准的TCP Sockets 编辑配置文件：sudo vim /etc/vsftpd/vsftpd.conf 如果该配置选项中的有 listen=YES，则要注释掉 重启 xinetd 服务，命令：sudo /etc/rc.d/init.d/xinetd restart 配置 standalone 模式： 编辑配置文件：sudo vim /etc/xinetd.d/vsftpd 属性信息改为如下信息： disable = yes 编辑配置文件：sudo vim /etc/vsftpd/vsftpd.conf 属性信息改为如下信息： Listen=YES（如果是注释掉则要打开注释） 重启服务：sudo service vsftpd restart FTP 资料 http://www.jikexueyuan.com/course/994.html http://www.while0.com/36.html http://www.cnblogs.com/CSGrandeur/p/3754126.html http://www.centoscn.com/image-text/config/2015/0613/5651.html http://wiki.ubuntu.org.cn/Vsftpd 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Subversion 1.8 安装]]></title>
      <url>%2F2017%2F11%2F22%2FSVN-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[Subversion 1.8 安装 RPM 安装（推荐） wandisco 整理的 RPM 文件官网：http://opensource.wandisco.com/centos/6/svn-1.8/RPMS/x86_64/ 下载下面几个 RPM 文件： 创建目录来保存下载的 RPM：sudo mkdir -p /opt/setups/subversion/ ; cd /opt/setups/subversion/ wget http://opensource.wandisco.com/centos/6/svn-1.8/RPMS/x86_64/mod_dav_svn-1.8.15-1.x86_64.rpm wget http://opensource.wandisco.com/centos/6/svn-1.8/RPMS/x86_64/serf-1.3.7-1.x86_64.rpm wget http://opensource.wandisco.com/centos/6/svn-1.8/RPMS/x86_64/subversion-1.8.15-1.x86_64.rpm wget http://opensource.wandisco.com/centos/6/svn-1.8/RPMS/x86_64/subversion-gnome-1.8.15-1.x86_64.rpm wget http://opensource.wandisco.com/centos/6/svn-1.8/RPMS/x86_64/subversion-javahl-1.8.15-1.x86_64.rpm wget http://opensource.wandisco.com/centos/6/svn-1.8/RPMS/x86_64/subversion-perl-1.8.15-1.x86_64.rpm wget http://opensource.wandisco.com/centos/6/svn-1.8/RPMS/x86_64/subversion-python-1.8.15-1.x86_64.rpm wget http://opensource.wandisco.com/centos/6/svn-1.8/RPMS/x86_64/subversion-tools-1.8.15-1.x86_64.rpm 如果上面的 RPM 链接失效，你也可以考虑下载我提供的百度云盘地址：http://pan.baidu.com/s/1pKnGia3 安装下载的 RPM 文件： sudo rpm -ivh *.rpm 检查安装后的版本： svn --version 编译安装（不推荐） subversion 1.8 编译安装（本人没有尝试成功，所以不推荐，下面内容只供参考） 官网安装说明（查找关键字 Dependency Overview）：http://svn.apache.org/repos/asf/subversion/trunk/INSTALL 此时 1.8 最新版本为：subversion-1.8.15.tar.gz 我个人习惯 /opt 目录下创建一个目录 setups 用来存放各种软件安装包；在 /usr 目录下创建一个 program 用来存放各种解压后的软件包，下面的讲解也都是基于此习惯 我个人已经使用了第三方源：EPEL、RepoForge，如果你出现 yum install XXXXX 安装不成功的话，很有可能就是你没有相关源，请查看我对源设置的文章 安装编译所需工具： sudo yum install -y gcc gcc-c++ autoconf libtool 所需依赖包说明： （必要包）apr 和 apr-util 官网地址：http://archive.apache.org/dist/apr/ （必要包）zlib 官网地址：ttp://www.zlib.net/ （必要包）SQLite 官网地址：http://www.sqlite.org/download.html （必要包）Subversion 官网地址：https://subversion.apache.org/download.cgi 所需依赖包下载： apr 下载：wget http://archive.apache.org/dist/apr/apr-1.5.2.tar.gz apr-util 下载：wget http://archive.apache.org/dist/apr/apr-util-1.5.4.tar.gz zlib 下载：wget http://zlib.net/zlib-1.2.8.tar.gz SQLite 下载：wget http://www.sqlite.org/2016/sqlite-amalgamation-3100200.zip Subversion 下载：wget http://apache.fayea.com/subversion/subversion-1.8.15.tar.gz 安装依赖包： apr 安装： 解压：tar -zxvf apr-1.5.2.tar.gz 移动到我个人习惯的安装目录下：mv apr-1.5.2/ /usr/program/ 标准的 GNU 源码安装方式： cd /usr/program/apr-1.5.2 ./configure make make install 安装完得到安装的配置路径：/usr/local/apr/bin/apr-1-config，这个需要记下来，下面会用到 apr-util 安装： 解压：tar -zxvf apr-util-1.5.4.tar.gz 移动到我个人习惯的安装目录下：mv apr-util-1.5.4/ /usr/program/ 标准的 GNU 源码安装方式： cd /usr/program/apr-util-1.5.4/ ./configure --with-apr=/usr/local/apr/bin/apr-1-config make make install 安装完得到安装的配置路径：/usr/local/apr/bin/apu-1-config，这个需要记下来，下面会用到 zlib 安装： 解压：tar -zxvf zlib-1.2.8.tar.gz 移动到我个人习惯的安装目录下：mv zlib-1.2.8/ /usr/program/ 标准的 GNU 源码安装方式： cd /usr/program/zlib-1.2.8/ ./configure make make install Subversion 解压： 解压：tar -zxvf subversion-1.8.15.tar.gz 移动到我个人习惯的安装目录下：mv subversion-1.8.15/ /usr/program/ SQLite 安装： 解压：unzip sqlite-amalgamation-3100200.zip 移动到 subversion 目录下：mv sqlite-amalgamation-3100200/ /usr/program/subversion-1.8.15/ Subversion 安装： 标准的 GNU 源码安装方式： cd /usr/program/subversion-1.8.15/ ./configure --prefix=/usr/local/subversion --with-apr=/usr/local/apr/bin/apr-1-config --with-apr-util=/usr/local/apr/bin/apu-1-config make make install SVN 配置 在系统上创建一个目录用来存储所有的 SVN 文件：mkdir -p /opt/svn/repo/ 新建一个版本仓库：svnadmin create /opt/svn/repo/ 生成如下目录和文件： 目录：locks 目录：hooks 目录：db 目录：conf 文件：format 文件：README.txt 其中，目录 conf 最为重要，常用的配置文件都在里面 svnserve.conf 是 svn 服务综合配置文件 passwd 是用户名和密码配置文件 authz 是权限配置文件 设置配置文件 编辑配置文件：vim /opt/svn/repo/conf/svnserve.conf 配置文件中下面几个参数（默认是注释的）： anon-access： 对不在授权名单中的用户访问仓库的权限控制，有三个可选性：write、read、none none 表示没有任何权限 read 表示只有只读权限 write 表示有读写权限 auth-access：对在授权名单中的用户访问仓库的权限控制，有三个可选性：write、read、none none 表示没有任何权限 read 表示只有只读权限 write 表示有读写权限 password-db：指定用户数据配置文件 authz-db：指定用户权限配置文件 realm：指定版本库的认证域，即在登录时提示的认证域名称。若两个版本库的认证域相同，建议使用相同的用户名口令数据文件 当前实例的配置内容：realm = myrepo 添加用户 编辑配置文件：vim /opt/svn/repo/conf/passwd 添加用户很简答，如上图所示在配置文中添加一个格式为：用户名 = 密码 的即可 设置用户权限 编辑配置文件：vim /opt/svn/repo/conf/authz 配置文件中几个参数解释： r 表示可写 w 表示可读 rw 表示可读可写 * = 表示除了上面设置的权限用户组以外，其他所有用户都设置空权限，空权限表示禁止访问本目录，这很重要一定要加上 [groups] 表示下面创建的是用户组，实际应用中一般我们对使用者都是进行分组的，然后把权限控制在组上，这样比较方便。使用组权限方式：@组名 = rw 启动服务 svnserve -d -r /opt/svn/repo/ --listen-port 3690 -d 表示后台运行 -r /opt/svn/repo/ 表示指定根目录 --listen-port 3690 表示指定端口，默认就是 3690，所以如果要用默认端口这个也是可以省略掉的 停止服务 killall svnserve 测试 iptables 处理 一种方式：先关闭 iptables，防止出现拦截问题而测试不了：service iptables stop 一种方式：在 iptables 中添加允许规则（svn 默认端口是 3690）： 添加规则：sudo iptables -I INPUT -p tcp -m tcp --dport 3690 -j ACCEPT 保存规则：sudo /etc/rc.d/init.d/iptables save 重启 iptables：sudo service iptables restart 在 Windows 的 svn 客户端上访问:svn://192.168.0.110 SVN 设置提交之后可修改提交的 Message 信息 默认的 SVN 是无法修改提交后的 Message 信息的，修改会报如下错误： 解决办法： 下载我 hooks 文件：http://pan.baidu.com/s/1c1jtlmw 把 pre-revprop-change 文件放在你的仓库下，比如我仓库地址是：/opt/svn/repo/hooks 编辑该文件：vim /opt/svn/repo/hooks/pre-revprop-change 把文件尾巴的这句脚本：echo &quot;$1 $2 $3 $4 $5&quot; &gt;&gt; /opt/svn/repo/logchanges.log，改为：echo &quot;$1 $2 $3 $4 $5&quot; &gt;&gt; /你的仓库地址/logchanges.log 你在该目录下也可以看到一个文件 pre-revprop-change.tmpl，这个其实就是 svn 提供给你模板，其他的那些你有兴趣也可以研究下 资料 http://tecadmin.net/install-subversion-1-8-on-centos-rhel/ http://svn.apache.org/repos/asf/subversion/trunk/INSTALL http://chenpipi.blog.51cto.com/8563610/1613007 https://blog.linuxeye.com/348.html http://jingyan.baidu.com/article/046a7b3efb6a5df9c27fa991.html http://www.ha97.com/4467.html http://blog.feehi.com/linux/7.html http://my.oschina.net/lionel45/blog/298305?fromerr=1NdIndN0 http://www.centoscn.com/CentosServer/ftp/2015/0622/5708.html http://blog.csdn.net/tianlesoftware/article/details/6119231 http://www.scmeye.com/thread-419-1-1.html http://m.blog.csdn.net/article/details?id=7908907 设置可编辑提交信息：http://stackoverflow.com/questions/692851/can-i-go-back-and-edit-comments-on-an-svn-checkin 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[FastDFS 结合 GraphicsMagick]]></title>
      <url>%2F2017%2F11%2F22%2FFastDFS-Nginx-Lua-GraphicsMagick%2F</url>
      <content type="text"><![CDATA[FastDFS 结合 GraphicsMagick 单机安装部署（CentOS 6.7 环境）先安装 FastDFS 软件准备： 我这边统一提供了一个压缩包，方便使用。 下载地址：http://pan.baidu.com/s/1hsg2brA 安装依赖包：yum install -y gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel libevent 安装 libfastcommon-1.0.7.tar.gz 解压：tar zxvf libfastcommon-1.0.7.tar.gz 进入解压后目录：cd libfastcommon-1.0.7/ 编译：./make.sh 安装：./make.sh install 设置几个软链接：ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so 设置几个软链接：ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so 设置几个软链接：ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so 设置几个软链接：ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so 安装 tracker （跟踪器）服务 FastDFS_v5.08.tar.gz 解压：tar zxvf FastDFS_v5.05.tar.gz 进入解压后目录：cd FastDFS/ 编译：./make.sh 安装：./make.sh install 配置 tracker 服务 复制一份配置文件：cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf 编辑：vim /etc/fdfs/tracker.conf，编辑内容看下面中文注释disabled=false bind_addr= port=22122 connect_timeout=30 network_timeout=60 # 下面这个路径是保存 store data 和 log 的地方，需要我们改下，指向我们一个存在的目录 # 创建目录：mkdir -p /opt/fastdfs/tracker/data-and-log base_path=/opt/fastdfs/tracker/data-and-log max_connections=256 accept_threads=1 work_threads=4 store_lookup=2 store_group=group2 store_server=0 store_path=0 download_server=0 reserved_storage_space = 10% log_level=info run_by_group= run_by_user= allow_hosts=* sync_log_buff_interval = 10 check_active_interval = 120 thread_stack_size = 64KB storage_ip_changed_auto_adjust = true storage_sync_file_max_delay = 86400 storage_sync_file_max_time = 300 use_trunk_file = false slot_min_size = 256 slot_max_size = 16MB trunk_file_size = 64MB trunk_create_file_advance = false trunk_create_file_time_base = 02:00 trunk_create_file_interval = 86400 trunk_create_file_space_threshold = 20G trunk_init_check_occupying = false trunk_init_reload_from_binlog = false trunk_compress_binlog_min_interval = 0 use_storage_id = false storage_ids_filename = storage_ids.conf id_type_in_filename = ip store_slave_file_use_link = false rotate_error_log = false error_log_rotate_time=00:00 rotate_error_log_size = 0 log_file_keep_days = 0 use_connection_pool = false connection_pool_max_idle_time = 3600 http.server_port=8080 http.check_alive_interval=30 http.check_alive_type=tcp http.check_alive_uri=/status.html 启动 tracker 服务：/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf 重启 tracker 服务：/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf restart 查看是否有 tracker 进程：ps aux | grep tracker storage （存储节点）服务部署 一般 storage 服务我们会单独装一台机子，但是这里为了方便我们安装在同一台。 如果 storage 单独安装的话，那上面安装的步骤都要在走一遍，只是到了编辑配置文件的时候，编辑的是 storage.conf 而已 复制一份配置文件：cp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf 编辑：vim /etc/fdfs/storage.conf，编辑内容看下面中文注释disabled=false group_name=group1 bind_addr= client_bind=true port=23000 connect_timeout=30 network_timeout=60 heart_beat_interval=30 stat_report_interval=60 # 下面这个路径是保存 store data 和 log 的地方，需要我们改下，指向我们一个存在的目录 # 创建目录：mkdir -p /opt/fastdfs/storage/data-and-log base_path=/opt/fastdfs/storage/data-and-log max_connections=256 buff_size = 256KB accept_threads=1 work_threads=4 disk_rw_separated = true disk_reader_threads = 1 disk_writer_threads = 1 sync_wait_msec=50 sync_interval=0 sync_start_time=00:00 sync_end_time=23:59 write_mark_file_freq=500 store_path_count=1 # 图片实际存放路径，如果有多个，这里可以有多行： # store_path0=/opt/fastdfs/storage/images-data0 # store_path1=/opt/fastdfs/storage/images-data1 # store_path2=/opt/fastdfs/storage/images-data2 # 创建目录：mkdir -p /opt/fastdfs/storage/images-data store_path0=/opt/fastdfs/storage/images-data subdir_count_per_path=256 # 指定 tracker 服务器的 IP 和端口 tracker_server=192.168.1.114:22122 log_level=info run_by_group= run_by_user= allow_hosts=* file_distribute_path_mode=0 file_distribute_rotate_count=100 fsync_after_written_bytes=0 sync_log_buff_interval=10 sync_binlog_buff_interval=10 sync_stat_file_interval=300 thread_stack_size=512KB upload_priority=10 if_alias_prefix= check_file_duplicate=0 file_signature_method=hash key_namespace=FastDFS keep_alive=0 use_access_log = false rotate_access_log = false access_log_rotate_time=00:00 rotate_error_log = false error_log_rotate_time=00:00 rotate_access_log_size = 0 rotate_error_log_size = 0 log_file_keep_days = 0 file_sync_skip_invalid_record=false use_connection_pool = false connection_pool_max_idle_time = 3600 http.domain_name= http.server_port=8888 启动 storage 服务：/usr/bin/fdfs_storaged /etc/fdfs/storage.conf，首次启动会很慢，因为它在创建预设存储文件的目录 重启 storage 服务：/usr/bin/fdfs_storaged /etc/fdfs/storage.conf restart 查看是否有 storage 进程：ps aux | grep storage 测试是否部署成功 利用自带的 client 进行测试 复制一份配置文件：cp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf 编辑：vim /etc/fdfs/client.conf，编辑内容看下面中文注释connect_timeout=30 network_timeout=60 # 下面这个路径是保存 store log 的地方，需要我们改下，指向我们一个存在的目录 # 创建目录：mkdir -p /opt/fastdfs/client/data-and-log base_path=/opt/fastdfs/client/data-and-log # 指定 tracker 服务器的 IP 和端口 tracker_server=192.168.1.114:22122 log_level=info use_connection_pool = false connection_pool_max_idle_time = 3600 load_fdfs_parameters_from_tracker=false use_storage_id = false storage_ids_filename = storage_ids.conf http.tracker_server_port=80 在终端中通过 shell 上传 opt 目录下的一张图片：/usr/bin/fdfs_test /etc/fdfs/client.conf upload /opt/test.jpg 如下图箭头所示，生成的图片地址为：http://192.168.1.114/group1/M00/00/00/wKgBclb0aqWAbVNrAAAjn7_h9gM813_big.jpg 即使我们现在知道图片的访问地址我们也访问不了，因为我们还没装 FastDFS 的 Nginx 模块 安装 nginx-lua-GraphicsMagick 来源：https://github.com/yanue/nginx-lua-GraphicsMagick/blob/master/nginx-install.md 添加专用用户，后面有用 groupadd www useradd -g www www -s /bin/false 安装依赖包 yum install -y gcc gcc-c++ zlib zlib-devel openssl openssl-devel pcre pcre-devel yum install -y libpng libjpeg libpng-devel libjpeg-devel ghostscript libtiff libtiff-devel freetype freetype-devel yum install -y GraphicsMagick GraphicsMagick-devel 下面的这些软件都在本文在开头的那个压缩包里面。现在我们需要解压这些压缩包 cd /opt/setups tar -zxvf nginx-1.8.0.tar.gz tar -zxvf LuaJIT-2.0.4.tar.gz tar -zxvf GraphicsMagick-1.3.21.tar.gz tar -zxvf zlib-1.2.8.tar.gz 安装 LuaJIT cd /opt/setups/LuaJIT-2.0.4 make make install export LUAJIT_LIB=/usr/local/lib export LUAJIT_INC=/usr/local/include/luajit-2.0 ln -s /usr/local/lib/libluajit-5.1.so.2 /lib64/libluajit-5.1.so.2 修改一些配置文件 编辑 Nginx 模块的配置文件：vim /opt/setups/fastdfs-nginx-module/src/config 找到下面一行包含有 local 字眼去掉，因为这三个路径根本不是在 local 目录下的。（如果你的配置文件没有这个 local，那这一步跳过）CORE_INCS=&quot;$CORE_INCS /usr/local/include/fastdfs /usr/local/include/fastcommon/&quot; 改为如下：CORE_INCS=&quot;$CORE_INCS /usr/include/fastdfs /usr/include/fastcommon/&quot; 复制文件：cp /opt/setups/FastDFS/conf/http.conf /etc/fdfs 复制文件：cp /opt/setups/FastDFS/conf/mime.types /etc/fdfs 开始安装 Nginx cd /opt/setups/nginx-1.8.0 mkdir -p /usr/local/nginx /var/log/nginx /var/temp/nginx /var/lock/nginx 执行下面编译语句：./configure --prefix=/usr/local/nginx \ --user=www \ --group=www \ --pid-path=/var/local/nginx/nginx.pid \ --lock-path=/var/lock/nginx/nginx.lock \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --http-client-body-temp-path=/var/temp/nginx/client \ --http-proxy-temp-path=/var/temp/nginx/proxy \ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \ --http-scgi-temp-path=/var/temp/nginx/scgi \ --sbin-path=/usr/local/nginx/sbin/nginx \ --with-http_ssl_module \ --with-http_realip_module \ --with-http_sub_module \ --with-http_flv_module \ --with-http_dav_module \ --with-http_gzip_static_module \ --with-http_stub_status_module \ --with-http_addition_module \ --with-http_spdy_module \ --with-pcre \ --with-zlib=/opt/setups/zlib-1.2.8 \ --add-module=/opt/setups/nginx-http-concat \ --add-module=/opt/setups/lua-nginx-module \ --add-module=/opt/setups/ngx_devel_kit \ --add-module=/opt/setups/fastdfs-nginx-module/src make make install 修改一下配置 复制 Nginx 模块的配置文件：cp /opt/setups/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs 编辑 Nginx 模块的配置文件：vim /etc/fdfs/mod_fastdfs.conf，编辑内容看下面中文注释 如果在已经启动 Nginx 的情况下修改下面内容记得要重启 Nginx。connect_timeout=2 network_timeout=30 # 下面这个路径是保存 log 的地方，需要我们改下，指向我们一个存在的目录 # 创建目录：mkdir -p /opt/fastdfs/fastdfs-nginx-module/data-and-log base_path=/opt/fastdfs/fastdfs-nginx-module/data-and-log load_fdfs_parameters_from_tracker=true storage_sync_file_max_delay = 86400 use_storage_id = false storage_ids_filename = storage_ids.conf # 指定 tracker 服务器的 IP 和端口 tracker_server=192.168.1.114:22122 storage_server_port=23000 group_name=group1 # 因为我们访问图片的地址是：http://192.168.1.114/group1/M00/00/00/wKgBclb0aqWAbVNrAAAjn7_h9gM813_big.jpg # 该地址前面是带有 /group1/M00，所以我们这里要使用 true，不然访问不到（原值是 false） url_have_group_name = true store_path_count=1 # 图片实际存放路径，如果有多个，这里可以有多行： # store_path0=/opt/fastdfs/storage/images-data0 # store_path1=/opt/fastdfs/storage/images-data1 # store_path2=/opt/fastdfs/storage/images-data2 store_path0=/opt/fastdfs/storage/images-data log_level=info log_filename= response_mode=proxy if_alias_prefix= flv_support = true flv_extension = flv group_count = 0 创建文件夹：mkdir -p /opt/fastdfs/thumb 编辑 Nginx 配置文件 vim /usr/local/nginx/conf/nginx.conf``` nginx注意这一行行，我特别加上了使用 root 用户去执行，不然有些日记目录没有权限访问user root;worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server{ listen 80; server_name 192.168.1.112; set $img_thumbnail_root /opt/fastdfs/thumb; set $img_file $img_thumbnail_root$uri; # like：/pic/M00/xx/xx/xx.jpg_200x100.jpg # /group1/M00 location ~* ^(\/(\w+)(\/M00)(.+\.(jpg|jpeg|gif|png))_(\d+)+x(\d+)+\.(jpg|jpeg|gif|png))$ { root $img_thumbnail_root; set $fdfs_group_root /opt/fastdfs/storage/images-data/data; # 如果缩略图不存在 if (!-f $img_file) { add_header X-Powered-By &#39;Nginx+Lua+GraphicsMagick By Yanue&#39;; add_header file-path $request_filename; set $request_filepath $fdfs_group_root$4; set $img_width $6; set $img_height $7; set $img_ext $5; content_by_lua_file /opt/setups/lua/cropSize.lua; } } location /group1/M00 { alias /opt/fastdfs/storage/images-data/data; ngx_fastdfs_module; } } } ``` - 启动 Nginx - 停掉防火墙：`service iptables stop` - 启动：`/usr/local/nginx/sbin/nginx`，启动完成 shell 是不会有输出的 - 访问：`192.168.1.114`，如果能看到：`Welcome to nginx!`，即可表示安装成功 - 检查 时候有 Nginx 进程：`ps aux | grep nginx`，正常是显示 3 个结果出来 - 刷新 Nginx 配置后重启：`/usr/local/nginx/sbin/nginx -s reload` - 停止 Nginx：`/usr/local/nginx/sbin/nginx -s stop` - 如果访问不了，或是出现其他信息看下错误立即：`vim /var/log/nginx/error.log` 多机安装部署（CentOS 6.7 环境） 多机部署的情况，对生成大小图的 Nginx 也有地方要修改。 资料：http://blog.csdn.net/ricciozhang/article/details/49402273 资料 fastdfs+nginx安装配置 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Tomcat 8 安装和配置、优化]]></title>
      <url>%2F2017%2F11%2F22%2FTomcat-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[Tomcat 8 安装和配置、优化 Tomcat 8 安装 Tomcat 8 安装 官网：http://tomcat.apache.org/ Tomcat 8 官网下载：http://tomcat.apache.org/download-80.cgi 此时（20160207） Tomcat 8 最新版本为：apache-tomcat-8.0.32.tar.gz 我个人习惯 /opt 目录下创建一个目录 setups 用来存放各种软件安装包；在 /usr 目录下创建一个 program 用来存放各种解压后的软件包，下面的讲解也都是基于此习惯 我个人已经使用了第三方源：EPEL、RepoForge，如果你出现 yum install XXXXX 安装不成功的话，很有可能就是你没有相关源，请查看我对源设置的文章 Tomcat 8 下载：wget http://apache.fayea.com/tomcat/tomcat-8/v8.0.32/bin/apache-tomcat-8.0.32.tar.gz 压缩包解压：tar -zxvf apache-tomcat-8.0.32.tar.gz 移到解压出来文件夹到 /usr 下：mv apache-tomcat-8.0.32/ /usr/program/ 为了方便，修改解压目录的名字：mv /usr/program/apache-tomcat-8.0.32/ /usr/program/tomcat8/ 设置 Iptables 规则（这一步是必须设置的）： 一种方式：先关闭 iptables，防止出现拦截问题而测试不了：service iptables stop 一种方式：在 iptables 中添加允许规则（Tomcat 默认端口是 8080）： 添加规则：sudo iptables -I INPUT -p tcp -m tcp --dport 8080 -j ACCEPT 保存规则：sudo /etc/rc.d/init.d/iptables save 重启 iptables：sudo service iptables restart 测试安装好后的 Tomcat： 启动 Tomcat：sh /usr/program/tomcat8/bin/startup.sh ; tail -200f /usr/program/tomcat8/logs/catalina.out 访问：http://服务器 IP 地址:8080/ 停止 Tomcat：sh /usr/program/tomcat8/bin/shutdown.sh Tomcat 8 配置 设置 Tomcat 相关变量： sudo vim /usr/program/tomcat8/bin/catalina.sh 在配置文件的可编辑内容最上面（98 行开始），加上如下内容（具体参数根据你服务器情况自行修改）：JAVA_HOME=/usr/program/jdk1.8.0_72 CATALINA_HOME=/usr/program/tomcat8 CATALINA_OPTS=&quot;-server -Xms528m -Xmx528m -XX:PermSize=256m -XX:MaxPermSize=358m&quot; CATALINA_PID=$CATALINA_HOME/catalina.pid 如果使用 shutdown.sh 还无法停止 tomcat，可以修改其配置：vim /usr/program/tomcat8/bin/shutdown.sh 把最尾巴这一行：exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; stop &quot;$@&quot; 改为：exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; stop 10 -force Tomcat 8 优化 Tomcat 6/7/8 的优化参数有点不一样，最好按下面的方式看一下官网这个文档是否还保留着这个参数 启动tomcat，访问该地址，下面要讲解的一些配置信息，在该文档下都有说明的： 文档：http://127.0.0.1:8080/docs/config 你也可以直接看网络版本： Tomcat 6 文档：https://tomcat.apache.org/tomcat-6.0-doc/config Tomcat 7 文档：https://tomcat.apache.org/tomcat-7.0-doc/config/ Tomcat 8 文档：https://tomcat.apache.org/tomcat-8.0-doc/config/ 如果你需要查看 Tomcat 的运行状态可以配置tomcat管理员账户，然后登陆 Tomcat 后台进行查看 编辑 /opt/tomcat7/bin/conf/tomcat-users.xml 文件，在里面添加下面信息：&lt;role rolename=&quot;manager&quot;/&gt; &lt;role rolename=&quot;manager-gui&quot;/&gt; &lt;role rolename=&quot;admin&quot;/&gt; &lt;role rolename=&quot;admin-gui&quot;/&gt; &lt;user username=&quot;tomcat&quot; password=&quot;tomcat&quot; roles=&quot;admin-gui,admin,manager-gui,manager&quot;/&gt; 编辑配置文件：vim /usr/program/tomcat7/conf/server.xml 打开默认被注释的连接池配置： 默认值：&lt;!-- &lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot; maxThreads=&quot;150&quot; minSpareThreads=&quot;4&quot;/&gt; --&gt; 修改为：&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot; maxThreads=&quot;500&quot; minSpareThreads=&quot;100&quot; prestartminSpareThreads = &quot;true&quot; maxQueueSize = &quot;100&quot; /&gt; 重点参数解释： maxThreads，最大并发数，默认设置 200，一般建议在 500 ~ 800，根据硬件设施和业务来判断 minSpareThreads，Tomcat 初始化时创建的线程数，默认设置 25 prestartminSpareThreads，在 Tomcat 初始化的时候就初始化 minSpareThreads 的参数值，如果不等于 true，minSpareThreads 的值就没啥效果了 maxQueueSize，最大的等待队列数，超过则拒绝请求 修改默认的链接参数配置： 默认值：&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; 修改为：&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot; connectionTimeout=&quot;20000&quot; maxConnections=&quot;10000&quot; redirectPort=&quot;8443&quot; enableLookups=&quot;false&quot; acceptCount=&quot;100&quot; maxPostSize=&quot;10485760&quot; compression=&quot;on&quot; disableUploadTimeout=&quot;true&quot; compressionMinSize=&quot;2048&quot; acceptorThreadCount=&quot;2&quot; compressableMimeType=&quot;text/html,text/xml,text/plain,text/css,text/javascript,application/javascript&quot; URIEncoding=&quot;utf-8&quot; /&gt; 重点参数解释： protocol，Tomcat 8 设置 nio2 更好：org.apache.coyote.http11.Http11Nio2Protocol（如果这个用不了，就用下面那个） protocol，Tomcat 6、7 设置 nio 更好：org.apache.coyote.http11.Http11NioProtocol enableLookups，禁用DNS查询 acceptCount，指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理，默认设置 100 maxPostSize，以 FORM URL 参数方式的 POST 提交方式，限制提交最大的大小，默认是 2097152(2兆)，它使用的单位是字节。10485760 为 10M。如果要禁用限制，则可以设置为 -1。 acceptorThreadCount，用于接收连接的线程的数量，默认值是1。一般这个指需要改动的时候是因为该服务器是一个多核CPU，如果是多核 CPU 一般配置为 2. 禁用 AJP（如果你服务器没有使用 Apache） 把下面这一行注释掉，默认 Tomcat 是开启的。&lt;!-- &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; --&gt; JVM 优化 模型资料来源：http://xmuzyq.iteye.com/blog/599750 Java 的内存模型分为： Young，年轻代（易被 GC）。Young 区被划分为三部分，Eden 区和两个大小严格相同的 Survivor 区，其中 Survivor 区间中，某一时刻只有其中一个是被使用的，另外一个留做垃圾收集时复制对象用，在 Young 区间变满的时候，minor GC 就会将存活的对象移到空闲的Survivor 区间中，根据 JVM 的策略，在经过几次垃圾收集后，任然存活于 Survivor 的对象将被移动到 Tenured 区间。 Tenured，终身代。Tenured 区主要保存生命周期长的对象，一般是一些老的对象，当一些对象在 Young 复制转移一定的次数以后，对象就会被转移到 Tenured 区，一般如果系统中用了 application 级别的缓存，缓存中的对象往往会被转移到这一区间。 Perm，永久代。主要保存 class,method,filed 对象，这部门的空间一般不会溢出，除非一次性加载了很多的类，不过在涉及到热部署的应用服务器的时候，有时候会遇到 java.lang.OutOfMemoryError : PermGen space 的错误，造成这个错误的很大原因就有可能是每次都重新部署，但是重新部署后，类的 class 没有被卸载掉，这样就造成了大量的 class 对象保存在了 perm 中，这种情况下，一般重新启动应用服务器可以解决问题。 Linux 修改 /usr/program/tomcat7/bin/catalina.sh 文件，把下面信息添加到文件第一行。Windows 和 Linux 有点不一样的地方在于，在 Linux 下，下面的的参数值是被引号包围的，而 Windows 不需要引号包围。 如果服务器只运行一个 Tomcat 机子内存如果是 8G，一般 PermSize 配置是主要保证系统能稳定起来就行： JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms6144m -Xmx6144m -XX:NewSize=1024m -XX:MaxNewSize=2048m -XX:PermSize=512m -XX:MaxPermSize=512m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot; 机子内存如果是 16G，一般 PermSize 配置是主要保证系统能稳定起来就行： JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms13312m -Xmx13312m -XX:NewSize=3072m -XX:MaxNewSize=4096m -XX:PermSize=512m -XX:MaxPermSize=512m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot; 机子内存如果是 32G，一般 PermSize 配置是主要保证系统能稳定起来就行： JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms29696m -Xmx29696m -XX:NewSize=6144m -XX:MaxNewSize=9216m -XX:PermSize=1024m -XX:MaxPermSize=1024m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot; 如果是开发机 -Xms550m -Xmx1250m -XX:PermSize=550m -XX:MaxPermSize=1250m 参数说明：-Dfile.encoding：默认文件编码 -server：表示这是应用于服务器的配置，JVM 内部会有特殊处理的 -Xmx1024m：设置JVM最大可用内存为1024MB -Xms1024m：设置JVM最小内存为1024m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。 -XX:NewSize：设置年轻代大小 -XX:MaxNewSize：设置最大的年轻代大小 -XX:PermSize：设置永久代大小 -XX:MaxPermSize：设置最大永久代大小 -XX:NewRatio=4：设置年轻代（包括 Eden 和两个 Survivor 区）与终身代的比值（除去永久代）。设置为 4，则年轻代与终身代所占比值为 1：4，年轻代占整个堆栈的 1/5 -XX:MaxTenuringThreshold=10：设置垃圾最大年龄，默认为：15。如果设置为 0 的话，则年轻代对象不经过 Survivor 区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在 Survivor 区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。 -XX:+DisableExplicitGC：这个将会忽略手动调用 GC 的代码使得 System.gc() 的调用就会变成一个空调用，完全不会触发任何 GC 其他 Tomcat 历史版本下载地址整理（不间断更新）： Tomcat 9.0.0.M4：wget http://mirror.bit.edu.cn/apache/tomcat/tomcat-9/v9.0.0.M4/bin/apache-tomcat-9.0.0.M4.tar.gz Tomcat 8.0.32：wget http://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.0.32/bin/apache-tomcat-8.0.32.tar.gz Tomcat 7.0.68：wget http://apache.fayea.com/tomcat/tomcat-7/v7.0.68/bin/apache-tomcat-7.0.68.tar.gz Tomcat 6.0.45：wget http://mirrors.cnnic.cn/apache/tomcat/tomcat-6/v6.0.45/bin/apache-tomcat-6.0.45.tar.gz 资料 http://www.jikexueyuan.com/course/2064_3.html?ss=1 http://www.wellho.net/mouth/2163_CATALINA-OPTS-v-JAVA-OPTS-What-is-the-difference-.html http://blog.csdn.net/sunlovefly2012/article/details/47395165 http://blog.csdn.net/lifetragedy/article/details/7708724 http://ihuangweiwei.iteye.com/blog/1233941 http://www.cnblogs.com/ggjucheng/archive/2013/04/16/3024731.html https://tomcat.apache.org/tomcat-8.0-doc/config/http.html#Connector_Comparison http://www.apelearn.com/study_v2/chapter23.html 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[VPN]]></title>
      <url>%2F2017%2F11%2F22%2FVPN%2F</url>
      <content type="text"><![CDATA[VPN（Virtual Private Network）介绍VPN 介绍VPN 分类有很多，这里主要讲 PPTPD 和 L2TPD、OpenVPN PPTPD 安装 查看是否已安装： CentOS：rpm -qa | grep pptpd Ubuntu：dpkg -l | grep pptpd 先安装依赖包： CentOS 6：sudo yum -y install ppp Ubuntu：sudo apt-get install -y ppp 安装： CentOS 6：sudo yum -y install pptpd Ubuntu：sudo apt-get install -y pptpd PPTPD 服务配置 注意：PPTPD 默认端口是 1723，所以防火墙要取消对其限制，查看 1723 端口是否开启：sudo netstat -apnl | grep 1723 编辑 PPTPD 配置文件介绍（记得先备份）：sudo vim /etc/pptpd.conf 修改配置信息： option /etc/ppp/options.pptpd #配置文件中有一行这样的参数，如果没有自己添加上去，正常默认是有的。同时也有可能是这样的一句话：option /etc/ppp/pptpd-options，具体你自己看下你的配置文件里面是什么内容。 logwtmp #默认这个是没有被注释的，这里要进行注释 localip 172.31.0.1 #本机服务器的内网IP地址，建议你的内网IP一般不要用常见网段，默认这个被注释，取消注释 remoteip 192.168.0.10-200 #客户端的IP地址范围，默认这个被注释，取消注释 编辑 PPP 配置文件介绍（记得先备份）：sudo vim /etc/ppp/options.pptpd 或是 sudo vim /etc/ppp/pptpd-options 在文件尾巴添加如下配置信息（默认配置文件应该有，只是被注释了）： ms-dns 8.8.8.8 #配置DNS，如果是境外服务器最好改为google的，国内的看情况 ms-dns 8.8.4.4 #配置DNS，如果是境外服务器最好改为google的，国内的看情况 开启系统转发（记得先备份）：sudo vim /etc/sysctl.conf 修改配置信息该值改为 1： net.ipv4.ip_forward=1 # 默认是注释掉的，要取消注释，也有出现是没有注释，但是默认是0：net.ipv4.ip_forward=0 刷新配置：sudo sysctl -p 设置 iptables 转发： 追加 iptables 规则：sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE 设置默认启动使用该规则：sudo vim /etc/rc.local 在配置文件中添加：iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE 添加登录账号（记得先备份）：sudo vim /etc/ppp/chap-secrets 在文件尾巴添加如下配置信息： mytest1 pptpd 123456 * #该格式分别表示：登录名、登录协议、密码、该连接上的客户端用什么 IP（* 表示随机一个 IP） 重启服务：sudo service pptpd restart Windows 连接 VPN 方法：http://www.cnblogs.com/yuzeren48/p/4123879.html L2TPD 安装 查看是否已安装： CentOS：rpm -qa | grep xl2tpd Ubuntu：dpkg -l | grep xl2tpd 安装： CentOS 6：XXXXXXXXXXXXXXXXXXXXXXXX Ubuntu：sudo apt-get install -y xl2tpd ppp openswan L2TPD 服务配置 注意：L2TPD 默认端口是 1701，所以防火墙要取消对其限制，查看 1701 端口是否开启：sudo netstat -apnl | grep 1701 编辑 Openswan 配置文件介绍（记得先备份）：sudo vim /etc/ipsec.conf left=172.31.201.255 #其中这里的IP地址改为本机的内网IP，文件中有两处，都进行修改 编辑 IPsec-based 配置文件介绍（记得先备份）：sudo vim /etc/ipsec.secrets 172.31.201.255 %any: PSK”adc123456” #在文件最后一行补充：（格式是：本机内网IP，后面是配置密钥。密钥不配置也可以但是建议配上去） 编辑 L2TPD 配置文件介绍（记得先备份）：sudo vim /etc/xl2tpd/xl2tpd.conf 修改配置信息： ipsec saref = yes require chap = yes refuse pap = yes require authentication = yes ppp debug = yes length bit = yes ip range = 192.168.1.10-192.168.1.200 #这是客户端连接本机的IP端限制 local ip = 172.31.201.255 #这是本机服务器端的内网 IP pppoptfile = /etc/ppp/options.xl2tpd #指定本机的 PPP 配置文件地址，如果你的 PPP 配置文件地址不是这里那就改下 编辑 PPP 配置文件介绍（记得先备份）：sudo vim /etc/ppp/options.xl2tpd (如果没有这个文件自己创建) 在文件尾巴添加如下配置信息： refuse-mschap-v2 refuse-mschap ms-dns 8.8.8.8 #配置DNS，如果是境外服务器最好改为google的，国内的看情况 ms-dns 8.8.4.4 #配置DNS，如果是境外服务器最好改为google的，国内的看情况 asyncmap 0 auth lock hide-password local name l2tpd proxyarp lcp-echo-interval 30 lcp-echo-failure 4 refuse refuse refuse 在终端输入命令：sudo sh -c ‘for each in /proc/sys/net/ipv4/conf/* do echo 0 &gt; $each/accept_redirects echo 0 &gt; $each/send_redirects done’ 开启系统转发（记得先备份）：sudo vim /etc/sysctl.conf 修改配置信息： net.ipv4.ip_forward=1 #默认是注释掉的，要取消注释 刷新配置：sudo sysctl -p 设置 iptables 转发： 追加 iptables 规则：sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE 设置默认启动使用该规则：sudo vim /etc/rc.local 在配置文件中添加：iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE 添加登录账号（记得先备份）：sudo vim /etc/ppp/chap-secrets 在文件尾巴添加如下配置信息： mytest1 l2tpd 123456 #该格式分别表示：登录名、登录协议、密码、该连接上的客户端用什么 IP（ 表示随机一个 IP） 重启服务：sudo service l2tpd restart Windows 连接 VPN 方法：http://www.cnblogs.com/yuzeren48/p/4123879.html OpenVPN 安装 主要软件版本信息： OpenVPN：2.3.11-1.el6 EasyRsa：2.2.2-1.el6 检查系统环境是否支持：cat /dev/net/tun，如果出现：cat: /dev/net/tun: File descriptor in bad state，则表示支持。如果现实的是：cat: /dev/net/tun: No such device，则不支持 需要先安装 EPEL 源，具体可以看这篇文章：CentOS 源设置 安装： 安装依赖包： yum install -y gcc make rpm-build autoconf.noarch openssl openssl-devel lzo lzo-devel pam pam-devel automake pkgconfig 安装 OpenVPN： yum install -y openvpn easy-rsa OpenVPN 服务配置禁用 selinux 编辑配置文件：vim /etc/selinux/config 把 SELINUX=enforcing 改为 SELINUX=disabled 生成OpenVPN需要的服务器、客户端证书 使用 easy-rsa 的脚本产生证书 修改vars文件 cd /usr/share/easy-rsa/2.0，后面关于证书的操作都是在这个目录下 vim vars 需要修改的内容主要有下面这些信息（在文件 64 行）：注册信息，比如公司地址、公司名称、部门名称等。 export KEY_COUNTRY=&quot;CN&quot; export KEY_PROVINCE=&quot;GuangDong&quot; export KEY_CITY=&quot;GuangZhou&quot; export KEY_ORG=&quot;YouMeekOrganization&quot; export KEY_EMAIL=&quot;admin@youmeek.com&quot; export KEY_OU=&quot;YouMeekOrganizationalUnit&quot; 初始化环境变量 source vars 清除keys目录下所有与证书相关的文件，下面步骤生成的证书和密钥都在 /usr/share/easy-rsa/2.0/keys 目录里 ./clean-all 生成根证书 ca.crt 和根密钥 ca.key（会有好几个提示，你都不需要输入什么内容，一路按回车即可，除非你懂原理） ./build-ca 为服务端生成证书和密钥（也会有好几个提示，你都不需要输入什么内容，一路按回车即可，直到提示需要输入y/n时，输入y再按回车继续走） 其中：server，这个名字别改，照着来，等下那些就可以直接使用。 ./build-key-server server 每一个登陆的VPN客户端需要有一个证书，每个证书在同一时刻只能供一个客户端连接，下面语句是建立2份demo，你可以只输入第一个即可。 为客户端生成证书和密钥（一路按回车，直到提示需要输入y/n时，输入y再按回车，一共两次） 其中：client1，这个名字别改，照着来，等下那些就可以直接使用，除非你会。 ./build-key client1 ./build-key client2 创建迪菲·赫尔曼密钥，会在 keys 目录里面生成dh2048.pem文件（生成过程比较慢，在此期间不要去中断它，我这边花的时间是：2分钟） ./build-dh 设置OpenVPN服务端配置文件 复制一份服务器端配置文件模板server.conf到/etc/openvpn/ 其中，我这边现在的版本是：2.3.11，所以我这边是填这个，你的不一定就跟我一样，所以你先到 doc 目录下，看下你具体是哪个版本，改下下面这句命令即可。 cp /usr/share/doc/openvpn-2.3.11/sample/sample-config-files/server.conf /etc/openvpn/ 编辑 server.conf，把下面的内容替换到已有的文件中，记得去掉后面的注释，我这样写只是为了方便解释对应的内容含义： vim /etc/openvpn/server.conf port 1194 # 端口一般我们不改 proto udp # 默认使用udp，如果使用HTTP Proxy，改成tcp，必须使用tcp协议，还需要注意的是：需要与客户端配置保持一致，等下客户端配置会说道 dev tun ca /usr/share/easy-rsa/2.0/keys/ca.crt # 这一行默认值为：ca ca.crt cert /usr/share/easy-rsa/2.0/keys/server.crt # 这一行默认值为：cert server.crt key /usr/share/easy-rsa/2.0/keys/server.key # 这一行默认值为：key server.key dh /usr/share/easy-rsa/2.0/keys/dh2048.pem # 这一行默认值为：dh dh2048.pem server 10.192.170.0 255.255.255.0 # 给客户的分配的局域网IP段，默认虚拟局域网网段，不要和实际的局域网冲突即可，这个10.192.170.0跟下面还有一个地方配置也有关联，需要注意 ifconfig-pool-persist ipp.txt # 启用了ipp.txt作为客户端和virtual IP的对应表，以方便客户端重新连接可以获得同样的IP； keepalive 10 120 comp-lzo persist-key persist-tun status openvpn-status.log # OpenVPN的状态日志，默认为/etc/openvpn/openvpn-status.log log openvpn.log # OpenVPN的运行日志，默认为/etc/openvpn/openvpn.log log-append openvpn.log verb 3 push &quot;redirect-gateway def1 bypass-dhcp&quot; push &quot;dhcp-option DNS 8.8.8.8&quot; push &quot;dhcp-option DOMAIN-SEARCH ap-northeast-1.compute.internal&quot; push &quot;dhcp-option DOMAIN-SEARCH ec2.drawbrid.ge&quot; 配置内核和防火墙，开启nat功能，启动服务 开启路由转发功能 sed -i &#39;/net.ipv4.ip_forward/s/0/1/&#39; /etc/sysctl.conf 刷新配置：sudo sysctl -p 辨别你的 VPS 是属于那种虚拟方式，主流有：Xen KVM OpenVZ，方法： sudo yum install -y virt-what，virt-what是一个判断当前环境所使用的虚拟技术的脚本，常见的虚拟技术基本上都能正常识别出来 sudo virt-what，我这边 Vultr 输出的结果是：KVM 配置防火墙 iptables -A INPUT -p udp --dport 1194 -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT 设置IP转发，若你的 VPS 虚拟方案是：Xen 或 KVM的请输入：（eth0要根据具体的网卡标示来，可以通过ifconfig查看），其中：10.192.170.0/16 表示客户端连接上去后从这个区间中分配给客户端的IP地址 iptables -t nat -A POSTROUTING -s 10.192.170.0/16 -o eth0 -j MASQUERADE 若你的 VPS 虚拟方案是：OpenVZ 的请输入：（45.32.90.22是你VPS的IP） iptables -t nat -A POSTROUTING -s 10.192.170.0/16 -j SNAT --to-source 45.32.90.22 保存防火墙配置 service iptables save service iptables restart 启动openvpn并设置为开机启动 service openvpn start chkconfig openvpn on OpenVPN客户端配置下载 Windows 客户端：https://openvpn.net/index.php/download/community-downloads.html Mac 用户下载这个 tunnelblick（该地址需要开穿越）：http://code.google.com/p/tunnelblick/ 从服务器上下载证书文件到本地： /usr/share/easy-rsa/2.0/keys/ca.crt /usr/share/easy-rsa/2.0/keys/client1.crt /usr/share/easy-rsa/2.0/keys/client1.key 到你本地的电脑上（window电脑在安装好OpenVPN软件后可以把如上证书拷贝到如下文件夹里：C:\Program Files\OpenVPN\config ） 从服务器找到这个文件：/usr/share/doc/openvpn-2.3.11/sample/sample-windows/sample.ovpn，下载到本地电脑这个目录下：C:\Program Files\OpenVPN\config然后把这个文件改名字为：client1.ovpn 文件内如如下, 其他不用改只要把SERVER-IP 改成你服务器的 IP client #这个client不是自定义名称 不能更改 dev tun #要与前面server.conf中的配置一致。 proto udp #要与前面server.conf中的配置一致。 remote 45.32.90.22 1194 #将45.32.90.22替换为你VPS的IP，端口也与前面的server.conf中配置一致。 resolv-retry infinite nobind persist-key persist-tun ca ca.crt #具体名称以刚下载的为准 cert client1.crt #具体名称以刚下载的为准 key client1.key #具体名称以刚下载的为准 comp-lzo verb 3 打开 OpenVPN 客户端，连接试试看。 VPN 资料 http://www.jikexueyuan.com/course/1692_2.html?ss=1 http://gnailuy.com/linux/2011/07/04/pptp-vpn/ http://www.centoscn.com/CentosServer/test/2014/1120/4153.html https://linux.cn/article-3706-1.html http://www.bkjia.com/yjs/1041400.html http://blog.liujason.com/1663.html http://shit.name/openvpn-on-centos/ http://kunsland.github.io/blogs/2015/03/22/vps-openvpn/ http://neolee.com/web/centos-openvz-vps-configuration-openvpn/ Freeradius 服务（用于账号认证管理的工具，可以扩展到VPN的账号管理） 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Vim 安装和配置、优化]]></title>
      <url>%2F2017%2F11%2F22%2FVim-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[Vim 安装和配置、优化Vim 介绍 Vim 官网：http://www.vim.org/ Vim 安装 CentOS：sudo yum install -y vim Ubuntu：sudo apt-get install -y vim Windows GVim 下载：http://www.xiazaiba.com/html/3347.html Vim 配置（CentOS 环境） 编辑配置文件是：sudo vim /etc/vimrc Vim 基础快捷键 注意 严格区分字母大小写 含有 Ctrl 字眼都表示 Ctrl 键盘按钮 特定符号需要配合 Shift 键，比如字母键盘区上面的数字区：!@#%%^&amp;*() 要按出冒号键 : 也是需要 Shift 的 移动 j，下 k，上 h，左 l，右 v，按 v 之后按方向键可以选中你要选中的文字 gg，跳到第 1 行 G，跳到第最后行 16G 或 :16，跳到第 16 行 $，到本行 行尾 0，到本行 行头 w，到下一个单词的 开头 e，到下一个单词的 结尾 Ctrl + u，向文件 首翻 半屏 Ctrl + d，向文件 尾翻 半屏 Ctrl + f，向文件 尾翻 一屏 Ctrl + b，向文件 首翻 一屏 *，匹配光标当前所在的单词，移动光标到 下一个 匹配单词 #，匹配光标当前所在的单词，移动光标到 上一个 匹配单词 ^，到本行第一个单词头 g_，到本行最后一个单词尾巴 %，匹配括号移动，包括 (、{、[ 插入 I，在当前 行首 插入 A，在当前 行尾 插入 i，在当前字符的 左边 插入 a，在当前字符的 右边 插入 o，在当前行 下面 插入一个新行 O，在当前行 上面 插入一个新行 编辑 删除 x，删除 光标后 的 1 个字符 2x，删除 光标后 的 2 个字符 X，删除 光标前 的 1 个字符 2X，删除 光标前 的 2 个字符 dd，删除当前行 cc，删除当前行后进入 insert 模式 dw，删除当前光标下的单词/空格 d$，删除光标至 行尾 所有字符 dG，删除光标至 文件尾 所有字符 3dd，从当前光标开始，删掉 3 行 复制 y，复制光标所选字符 yw，复制光标后单词 yy，复制当前行 4yy，复制当前行及下面 4 行 y$，复制光标位置至 行尾 的内容 y^，复制光标位置至 行首 的内容 粘贴 p，将粘贴板中内容复制到 光标之后 P，将粘贴板中内容复制到 光标之前 其他 ddp，交换当前光标所在行和下一行的位置 u，撤销 :wq，退出并 保存 :q!，退出并 不保存 Ctrl + v，进入 Vim 列编辑 guu，把当前行的字母全部转换成 小写 gUU，把当前行的字母全部转换成 大写 g~~，把当前行的字母是大写的转换成小写，是小写的转换成大写 :saveas /opt/setups/text.txt，另存到 /opt/setups/text.txt 搜索 /YouMeek，从光标开始处向文件尾搜索 YouMeek 字符，按 n 继续向下找，按 N 继续向上找 ?YouMeek，从光标开始处向文件首搜索 YouMeek 字符，按 n 继续向下找，按 N 继续向上找 替换 :%s/YouMeek/Judasn/g，把文件中所有 YouMeek 替换为：Judasn :%s/YouMeek/Judasn/，把文件中所有行中第一个 YouMeek 替换为：Judasn :s/YouMeek/Judasn/，把光标当前行第一个 YouMeek 替换为 Judasn :s/YouMeek/Judasn/g，把光标当前行所有 YouMeek 替换为 Judasn :s#YouMeek/#Judasn/#，除了使用斜杠作为分隔符之外，还可以使用 # 作为分隔符，此时中间出现的 / 不会作为分隔符，该命令表示：把光标当前行第一个 YouMeek/ 替换为 Judasn/ :10,31s/YouMeek/Judasng，把第 10 行到 31 行之间所有 YouMeek 替换为 Judasn Vim 的特殊复制、黏贴 Vim 提供了 12 个剪贴板，分别是：0,1,2,3,4,5,6,7,8,9,a,&quot;，默认采用的是 &quot;，也就是双引号，可能你初读感觉很奇怪。你可以用 Vim 编辑某个文件，然后输入：:reg。你可以看到如下内容： 复制到某个剪切板的命令：&quot;7y，表示使用 7 号剪切板。 黏贴某个剪切板内容：&quot;7p，表示使用 7 号剪切板内容进行黏贴 Vim 配置 我个人本地不使用 Vim 的，基本上都是在操作服务器的时候使用，所以这里推荐这个配置文件 vim-for-server 在假设你已经备份好你的 Vim 配置文件后，使用该配置文件：curl https://raw.githubusercontent.com/wklken/vim-for-server/master/vimrc &gt; ~/.vimrc 效果如下： 资料 vim几个小技巧（批量替换，列编辑） 最佳vim技巧 简明 Vim 练级攻略 vim 批量查找替换]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Zsh入门]]></title>
      <url>%2F2017%2F11%2F22%2FZsh%2F</url>
      <content type="text"><![CDATA[Zsh 入门本文前提 CentOS 6.7 64 bit root 用户 Zsh 介绍 Zsh 兼容 Bash，据传说 99% 的 Bash 操作 和 Zsh 是相同的 Zsh 官网：http://www.zsh.org/ 先看下你的 CentOS 支持哪些 shell：cat /etc/shells，正常结果应该是这样的： /bin/sh /bin/bash /sbin/nologin /bin/dash /bin/tcsh /bin/csh 默认 CentOS / Ubuntu / Mac 系统用的是 Bash，倒也不是说 Bash 不好，而是说我们有更好的选择。 Zsh 安装 CentOS 安装：sudo yum install -y zsh Ubuntu 安装：sudo apt-get install -y zsh 在检查下系统的 shell：cat /etc/shells，你会发现多了一个：/bin/zsh 使用 Zsh 扩展集合：oh-my-zsh oh-my-zsh 帮我们整理了一些常用的 Zsh 扩展功能和主题：https://github.com/robbyrussell/oh-my-zsh 我们无需自己去捣搞 Zsh，直接用 oh-my-zsh 就足够了，如果你想继续深造的话那再去弄。 先安装 git：sudo yum install -y git 安装 oh-my-zsh：wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O - | sh 整个过程效果如下图： 在以 root 用户为前提下，oh-my-zsh 的安装目录：/root/.oh-my-zsh 在以 root 用户为前提下，Zsh 的配置文件位置：/root/.zshrc 为 root 用户设置 zsh 为系统默认 shell：chsh -s /bin/zsh root 如果你要重新恢复到 bash：chsh -s /bin/bash root 现在你关掉终端或是重新连上 shell，现在开头是一个箭头了，如下图： Zsh 配置插件 启用 oh-my-zsh 中自带的插件。 oh-my-zsh 的插件列表介绍（太长了，用源码不精准地统计下有 149 个）：https://github.com/robbyrussell/oh-my-zsh/wiki/Plugins 我们看下安装 oh-my-zsh 的时候自带有多少个插件：ls -l /root/.oh-my-zsh/plugins |grep &quot;^d&quot;|wc -l，我这边得到的结果是：211 编辑配置文件：vim /root/.zshrc，找到下图的地方，怎么安装，原作者注释写得很清楚了，别装太多了，默认 git 是安装的。 插件推荐： wd 简单地讲就是给指定目录映射一个全局的名字，以后方便直接跳转到这个目录，比如： 编辑配置文件，添加上 wd 的名字：vim /root/.zshrc 我常去目录：/opt/setups，每次进入该目录下都需要这样：cd /opt/setups 现在用 wd 给他映射一个快捷方式：cd /opt/setups ; wd add setups 以后我在任何目录下只要运行：wd setups 就自动跑到 /opt/setups 目录下了 插件官网：https://github.com/mfaerevaag/wd autojump 这个插件会记录你常去的那些目录，然后做一下权重记录，你可以用这个命令看到你的习惯：j --stat，如果这个里面有你的记录，那你就只要敲最后一个文件夹名字即可进入，比如我个人习惯的 program：j program，就可以直接到：/usr/program 插件官网：https://github.com/wting/autojump 官网插件下载地址：https://github.com/wting/autojump/downloads 插件下载：wget https://github.com/downloads/wting/autojump/autojump_v21.1.2.tar.gz 解压：tar zxvf autojump_v21.1.2.tar.gz 进入解压后目录并安装：cd autojump_v21.1.2/ ; ./install.sh 再执行下这个：source /etc/profile.d/autojump.sh 编辑配置文件，添加上 autojump 的名字：vim /root/.zshrc 主题 很多人喜欢捣搞这个 ╮(￣▽￣)╭ 捣搞主题和插件思路一样 oh-my-zsh 的主题列表介绍（还是太长了）：https://github.com/robbyrussell/oh-my-zsh/wiki/Themes 我们看下安装 oh-my-zsh 的时候，自带有多少个：ls -l /root/.oh-my-zsh/themes |grep &quot;^-&quot;|wc -l，我这边得到的结果是：140 我个人品味地推荐的是（排名有先后）： ys agnoster avit blinks 编辑配置文件：vim /root/.zshrc，找到下图的地方，怎么安装，原作者注释写得很清楚了，如果你没特别的喜欢那就选择随机吧。 配置好新主题需要重新连接 shell 才能看到效果 一些人性化功能 呃，这个其实可以不用讲的，你自己用的时候你自己会发现的，各种便捷，特别是用 Tab 多的人一定会有各种惊喜的。 差异 我们现在增加系统变量在：/etc/profile 后，输入命令：source /etc/profile 之后，重启服务器发现刚刚的系统变量现在没效果。 解决办法：vim ~/.zshrc，在该配置文件里面增加一行：source /etc/profile，然后刷新 zsh 的配置：source ~/.zshrc。 资料 http://macshuo.com/?p=676 https://aaaaaashu.gitbooks.io/mac-dev-setup/content/iTerm/zsh.html http://hackerxu.com/2014/11/19/ZSH.html https://blog.phpgao.com/oh-my-zsh.html http://www.bkjia.com/Linuxjc/1033947.html http://swiftcafe.io/2015/10/31/cafe-time-omz/ http://swiftcafe.io/2015/12/04/omz-plugin/ http://www.hackbase.com/article-206940-1.html http://hahack.com/wiki/shell-zsh.html http://blog.jobbole.com/86820/ http://uecss.com/zsh-brew-autojump-plugins-shell-for-mac.html http://www.cnblogs.com/westfly/p/3283525.html 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[黑客入侵检查]]></title>
      <url>%2F2017%2F11%2F22%2FWas-Hacked%2F</url>
      <content type="text"><![CDATA[黑客入侵检查 思路 扫描木马工具：clamAV 官网：http://pkgs.repoforge.org/clamav/ CentOS 安装：yum install -y clamav* 启动 clamAV 服务：service clamd restart 更新病毒库：freshclam 扫描方法： 扫描 /etc 目录，并把扫描结果放在 /root 目录下：clamscan -r /etc --max-dir-recursion=5 -l /root/etcclamav.log 扫描 /bin 目录，并把扫描结果放在 /root 目录下：clamscan -r /bin --max-dir-recursion=5 -l /root/binclamav.log 扫描 /usr 目录，并把扫描结果放在 /root 目录下：clamscan -r /usr --max-dir-recursion=5 -l /root/usrclamav.log 如果日志有类似内容，表示有木马病毒： /usr/bin/.sshd: Linux.Trojan.Agent FOUND /usr/sbin/ss: Linux.Trojan.Agent FOUND /usr/sbin/lsof: Linux.Trojan.Agent FOUND 看下当前有多少登录者：who 看下最近有哪些登录者：last 查看最近尝试登录的账号信息：grep &quot;sshd&quot; /var/log/secure 很多这种信息就表示有人在不断地尝试用 root 登录：Failed password for root from 222.186.56.168 port 4080 ssh2 查看最近登录成功的账号信息：grep &quot;Accepted&quot; /var/log/secure，可以看到：pop3, ssh, telnet, ftp 类型 看下查看系统资源占用有无异常：top 看下所有进程：ps aux 查看当前系统登录者有哪些，及其登录记录：last | more 把最近执行的所有命令输出到一个文件，然后下载下来细细研究：history &gt;&gt; /opt/test.txt 查看当前系统所有用户有哪些：cat /etc/passwd |awk -F \: &#39;{print $1}&#39; 更多详细可以用：cat /etc/passwd 查看开放的端口，比如常用的80,22,8009，后面的箭头表示端口对应占用的程序：netstat -lnp 检查某个端口的具体信息：lsof -i :18954 检查启动项：chkconfig 检查定时器：cat /etc/crontab 检查其他系统重要文件： cat /etc/rc.local cd /etc/init.d;ll 检查文件： find / -uid 0 –perm -4000 –print find / -size +10000k –print find / -name &quot;…&quot; –print find / -name &quot;.. &quot; –print find / -name &quot;. &quot; –print find / -name &quot; &quot; –print 下载 iftop 分析流量，查看是否被黑客当做肉鸡使用 安装 iftop 官网：http://www.ex-parrot.com/~pdw/iftop/ 使用文章：https://linux.cn/article-1843-1.html 没有安装第三方源的情况： 安装依赖包：yum install -y flex byacc libpcap ncurses ncurses-devel libpcap-devel 下载源码包：wget http://www.ex-parrot.com/pdw/iftop/download/iftop-0.17.tar.gz 解压：tar zxf iftop-0.17.tar.gz 进入解压目录：cd iftop-0.17/ 编译：./configure 安装：make &amp;&amp; make install 有第三方源的情况（eg：EPEL）： yum install -y iftop 运行：iftop 显示端口与 IP 信息：iftop -nP 中间部分：外部连接列表，即记录了哪些ip正在和本机的网络连接 右边部分：实时参数分别是该访问 ip 连接到本机 2 秒，10 秒和 40 秒的平均流量 =&gt; 代表发送数据，&lt;= 代表接收数据 底部会显示一些全局的统计数据，peek 是指峰值情况，cumm 是从 iftop 运行至今的累计情况，而 rates 表示最近 2 秒、10 秒、40 秒内总共接收或者发送的平均网络流量。 TX:（发送流量） cumm: 143MB peak: 10.5Mb rates: 1.03Mb 1.54Mb 2.10Mb RX:（接收流量） 12.7GB 228Mb 189Mb 191Mb 183Mb TOTAL:（总的流量） 12.9GB 229Mb 190Mb 193Mb 185MbW 禁用 root 账号登录：vim /etc/ssh/sshd_config 把 PermitRootLogin 属性 yes 改为 no 如果安全度要更高，可以考虑禁用口令登录，采用私钥/公钥方式：vim /etc/ssh/sshd_config 设置属性：PasswordAuthentication 为 no 如果还要限制指定 IP 登录，可以考虑编辑：hosts.allow 和 hosts.deny 两个文件 资料 http://www.jianshu.com/p/97b9dc47b88c http://monklof.com/post/10/ http://yafeilee.me/blogs/54be6e876c69341430050000 http://coolnull.com/4174.html http://www.oicqzone.com/pc/2014110420118.html 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title></title>
      <url>%2F2017%2F11%2F22%2Fconfig%2F</url>
      <content type="text"><![CDATA[{"name":"Java 程序员眼中的 Linux","introduction":"笔者从 Java 开发角度，全方位讲解各种环境搭建及常用工具详解，是一部适合程序员的百科全书。"}]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS 网络设置]]></title>
      <url>%2F2017%2F11%2F22%2Fcentos-settings%2FCentOS-Network-Settings%2F</url>
      <content type="text"><![CDATA[CentOS 网络设置 由于前面虚拟机中安装 CentOS 使用的是桥接模式，为了让虚拟机中的系统能上网，我们需要进行网络设置。 选择上图箭头所示 如上图标注 3 所示：选择 手动 模式 如上图标注 4 所示：填写自己局域网内的子网掩码、默认网关，以及你要分配的内网 IP 地址。这三个参数你可以参考你当前使用的主机信息，在 Windows 系统上使用：cmd --- ipconfig，查看你当前连接的网卡信息。如果你是无线网卡则读取对应的无线网卡信息，如果你是本地连接，则读取对应的本地连接信息。 如上图标注 5 所示：填写你当前地区合适的 DNS 地址，我这边地区使用 360 测试出来的结果显示 114 的适合我，所以我这里填写该值 命令行下设置网络 编辑网卡信息： 备份：cp /etc/sysconfig/network-scripts/ifcfg-eth0 /etc/sysconfig/network-scripts/ifcfg-eth0-20160205Back 把备份文件移动到其他目录：mv /etc/sysconfig/network-scripts/ifcfg-eth0-20160205Back /opt/myBack 编辑网卡文件：vim /etc/sysconfig/network-scripts/ifcfg-eth0 把网卡中信息改为下面对应内容：DEVICE=eth0 (系统默认值) TYPE=Ethernet (系统默认值) UUID=a2c17f0c-a224-43d5-a203-48af1f0d9113 (系统默认值) ONBOOT=yes (系统默认值是 no,我改为 yes) NM_CONTROLLED=yes (系统默认值) BOOTPROTO=none (系统默认值是 dhcp,我改为 none,代表手动) USERCTL=no (自己补充的) IPV6INIT=no (自己补充的) NETMASK=255.255.255.0 (自己补充的) IPADDR=192.168.0.110 (自己补充的) GATEWAY=192.168.0.1 (自己补充的) DNS1=114.114.114.114 (自己补充的) PREFIX=24 (使用图形界面设置后生成的) DEFROUTE=yes (使用图形界面设置后生成的) IPV4_FAILURE_FATAL=yes (使用图形界面设置后生成的) NAME=&quot;System eth0&quot; (使用图形界面设置后生成的) HWADDR=00:0C:29:A9:37:D4 (使用图形界面设置后生成的) LAST_CONNECT=1454626679 (使用图形界面设置后生成的) 重启网络配置：service network restart 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS 源设置]]></title>
      <url>%2F2017%2F11%2F22%2Fcentos-settings%2FCentOS-Extra-Packages%2F</url>
      <content type="text"><![CDATA[CentOS 源设置 国内常用源配置方法（该源和官方源是一样的，只是因为服务器在国内会起到加速作用而已）： 163 源：http://mirrors.163.com/.help/centos.html 阿里源：http://mirrors.aliyun.com/help/centos sohu：http://mirrors.sohu.com/help/centos.html 替换过程（这里以 163 源为例，系统 CentOS 6.7）： 备份官网源：sudo mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.20151219.backup cd /etc/yum.repos.d/ 下载对应版本 repo 文件, 放入 /etc/yum.repos.d/ 下载源文件： CentOS7：sudo wget http://mirrors.163.com/.help/CentOS7-Base-163.repo CentOS6：sudo wget http://mirrors.163.com/.help/CentOS6-Base-163.repo CentOS5：sudo wget http://mirrors.163.com/.help/CentOS5-Base-163.repo sudo mv CentOS6-Base-163.repo CentOS-Base.repo 导入key：rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6 sudo yum clean all sudo yum makecache sudo yum update -y 加入第三方源主要是为了 yum 下载到官方没有提供的软件，在其他社区、第三方源里面有很多的软件包，有些软件是很好用的。CentOS 可以加入多个源，所以就存在一个源的优先级问题了，设置优先级的可以使用 yum-plugin-priorities 工具。一般我是建议官方的优先级是最高的，然后才是第三方的。 安装 yum-plugin-priorities： CentOS 4 或 CentOS 6：sudo yum install -y yum-plugin-priorities CentOS 5：sudo yum install -y yum-priorities 安装完 yum-plugin-priorities 插件后，默认是开启的，如果要关闭可以这样设置： sudo vim /etc/yum/pluginconf.d/priorities.conf 把 enabled=1 改为 enabled=0 即可 设置默认源的优先级： 一般默认的源配置里面 [base], [updates], [extras]，[centosplus] 的 priority=1， [contrib] 的 priority=2，其他第三的软件源为：priority=N （推荐 N &gt; 10，N 可以为1到99的正整数，数值越小越优先） sudo vim /etc/yum.repos.d/CentOS-Base.repo 配置内容如下图 安装 EPEL 源： 官网中文材料：https://fedoraproject.org/wiki/EPEL/zh-cn 安装命令：sudo yum install -y epel-release 导入 KEY：rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 设置 EPEL 源的级别：vim /etc/yum.repos.d/epel.repo，追加：priority=11 卸载 EPEL 源 如果你暂时不想使用 EPEL 源的话，把 epel.repo 里的 enabled=1 改成 enabled=0 即可，如果你完全不需要了，那就直接卸载掉 sudo rpm -e epel-release 安装 RepoForge 源：（旧的名字为 rpmforge） 官网下载 RPM包：http://repoforge.org/use/ 我是 CentOS 6.7 64 位，所以下载 EL 6 x86_64，下载 RMP 安装文件大小：12.3 KB 下载命令：wget http://pkgs.repoforge.org/rpmforge-release/rpmforge-release-0.5.3-1.el6.rf.x86_64.rpm（我这边 wget 不下来，需要开 VPN，所以你最好有这个心理准备） 安装 RPM 文件：sudo rpm -ivh rpmforge-release-0.5.3-1.el6.rf.x86_64.rpm 导入 KEY：sudo rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-rpmforge-dag 设置 RepoForge 源的级别：vim /etc/yum.repos.d/rpmforge.repo，设置如下图 更新包信息： sudo yum clean all sudo yum makecache sudo yum update -y 测试： 命令：sudo yum check-update 看到显示的结果中包括 rpmforge 和 epel 的列表表示成功。 sudo yum install -y htop（htop 官方源是没有的，所以如果能下载下来就表示已经使用了第三方源） 资料： https://wiki.centos.org/zh/PackageManagement/Yum/Priorities http://www.cnblogs.com/Security-Darren/p/3947952.html http://freeloda.blog.51cto.com/2033581/1260824 http://www.centoscn.com/CentOS/config/2014/0920/3793.html http://www.cnblogs.com/mchina/archive/2013/01/04/2842275.html http://www.ha97.com/2626.html 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[GitLab 安装和配置]]></title>
      <url>%2F2017%2F11%2F22%2FGitLab-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[GitLab 安装和配置 GitLab 介绍 官网下载：https://www.gitlab.cc/downloads 官网安装说明：https://doc.gitlab.cc/ce/install/requirements.html 开源版本和企业版本对比：https://www.gitlab.cc/features/#enterprise GitLab 安装（CentOS 6） 安装并开放 HTTP 和 SSH、邮件相关服务和端口 命令：sudo yum install -y curl openssh-server openssh-clients postfix cronie 命令：sudo service postfix start 命令：sudo chkconfig postfix on 命令：sudo lokkit -s http -s ssh 添加 GitLab 仓库，并安装到服务器上（8.8.4 安装包有：261M）： curl -sS http://packages.gitlab.cc/install/gitlab-ce/script.rpm.sh | sudo bash sudo yum install -y gitlab-ce 启动 GitLab：sudo gitlab-ctl reconfigure，使用这个命令会输出一堆的日志出来，整个启动过程需要耗时 20 秒左右 GitLab 配置 用浏览器访问服务器 IP，比如我的是：http://192.168.1.113，就可以直接看到 GitLab 配置初始化界面，让你先重置管理员密码，因为密码不能太简单，所以我改为：http://192.168.1.113，这样比较好记又复杂 重新访问：http://192.168.1.113，输入账号密码：root、http://192.168.1.113 访问管理员控制台，添加用户：http://192.168.1.113/admin/users 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[花生壳]]></title>
      <url>%2F2017%2F11%2F22%2FHsk-Install%2F</url>
      <content type="text"><![CDATA[花生壳 安装 CentOS 下过程 官网：http://hsk.oray.com/ 官网下载：http://hsk.oray.com/download/#type=linux 官网安装说明：http://service.oray.com/question/1890.html 软件包下载：wget http://download.oray.com/peanuthull/linux/phddns-2.0.6.el6.x86_64.rpm 安装：sudo yum localinstall -y phddns-2.0.6.el6.x86_64.rpm 配置： 安装完毕后，在终端下运行：phddns 第一步：：Enter server address(press ENTER use phddns60.oray.net)，这是提示您输入花生壳服务器的域名，如果网站上没有更新域名的公告说明，这一步直接回车即可，会使用默认的 phddns60.oray.net 域名。 第二步：Enter your Oray account:这是提示您输入在花生壳官网注册的用户名，请根据实际情况输入。 第三步：Password：这是提示您输入在花生壳官网注册的用户名所对应的密码，请根据实际情况输入。 第四步：Network interface(s): 这是要配置您这台服务器的网络参数，花生壳（公网版）软件会自动检查，并输出您的网络情况。eth0部分可能和上面的不一样，是您的实际网络设置。如果您有两块网卡，eth0 和eth1 ,而您希望用eth1来绑定花生壳，请在这里输入 eth1 ，然后回车。如果您只有一块网卡，或者您希望使用 eth0来绑定花生壳，在这里直接回车即可。 第五步：Log to use(default /var/log/phddns.log):这是提示您输入花生壳（公网版）软件日志的保存位置，请使用绝对路径指定日志文件名。如果直接回车，会使用 /var/log/phddns.log 来保存日志。 第六步： Save to configuration file (/etc/phlinux.conf)?(yes/no/other): 这是提示您输入上述配置的保存文件名。如果输入yes 或直接回车，将会使用/etc/phlinux.conf 来作为配置的保存文件名。如果输入other ，将会提示您自行指定文件名，请使用绝对路径来指定这个配置文件名。如果输入no ,不对上述配置进行保存,下次重新使用花生壳（公网版）时,需要手动指定配置文件或再次通过交互模式进行设置. 第六步执行完毕后，屏幕上会依次出现：defOnStatusChanged ok，DomainsRegistered，UserType，表示安装、配置完成了 启动服务：/usr/bin/phddns -c /etc/phlinux.conf -d 设置开机启动：echo &quot;/usr/bin/phddns -c /etc/phlinux.conf -d&quot; &gt;&gt; /etc/rc.local 查看进程：ps -ef | grep phddns 卸载： rpm -qa|grep phddns sudo rpm -e phddns-2.0.6-1.el6.x86_64 资料 http://service.oray.com/question/1890.html 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[iptables]]></title>
      <url>%2F2017%2F11%2F22%2FIptables%2F</url>
      <content type="text"><![CDATA[Iptables 介绍前提说明iptables 的设置在 CentOS 和 Ubuntu 下有些细节不一样，Ubuntu 这里不讲，文章底下贴的资料有部分关于 Ubuntu 的，有需要的可以自己看。一般大家会用到 iptables 都是服务器，而一般服务器大家普遍是用 CentOS） Iptables 安装 查看是否已安装： CentOS：rpm -qa | grep iptables 安装（一般系统是集成的）： CentOS 6：sudo yum install -y iptables Iptables 服务器配置文件常用参数 常用命令： 查看已有规则列表，并且显示编号：sudo iptables -L -n --line-numbers 要删除 INPUT 里序号为 x 的规则，执行：sudo iptables -D INPUT x 保存配置命令：sudo service iptables save 或者 sudo /etc/rc.d/init.d/iptables save 重启服务命令 ：sudo service iptables restart 查看服务状态： sudo service iptables status 设置开启默认启动： sudo chkconfig --level 345 iptables on 清除所有规则(慎用) sudo iptables -F sudo iptables -X sudo iptables -Z 添加规则：格式 sudo iptables [-AI 链名] [-io 网络接口] [-p 协议] [-s 来源IP/网域] [-d 目标IP/网域] -j [ACCEPT|DROP|REJECT|LOG] 选项与参数： -AI 链名：针对某的链进行规则的 “插入” 或 “累加” -A ：新增加一条规则，该规则增加在原本规则的最后面。例如原本已经有四条规则，使用 -A 就可以加上第五条规则！ -I ：插入一条规则。如果没有指定此规则的顺序，默认是插入变成第一条规则。例如原本有四条规则，使用 -I 则该规则变成第一条，而原本四条变成 2~5 号链 ：有 INPUT, OUTPUT, FORWARD 等，此链名称又与 -io 有关，请看底下。 -io 网络接口：设定封包进出的接口规范 -i ：封包所进入的那个网络接口，例如 eth0, lo 等接口。需与 INPUT 链配合； -o ：封包所传出的那个网络接口，需与 OUTPUT 链配合； -p 协定：设定此规则适用于哪种封包格式。主要的封包格式有： tcp, udp, icmp 及 all 。 -s 来源 IP/网域：设定此规则之封包的来源项目，可指定单纯的 IP 或包括网域，例如：IP：192.168.0.100，网域：192.168.0.0/24, 192.168.0.0/255.255.255.0 均可。若规范为『不许』时，则加上 ! 即可，例如：-s ! 192.168.100.0/24 表示不许 192.168.100.0/24 之封包来源。 -d 目标 IP/网域：同 -s ，只不过这里指的是目标的 IP 或网域。 -j ：后面接动作，主要的动作有接受(ACCEPT)、丢弃(DROP)、拒绝(REJECT)及记录(LOG) Iptables 例子 开放指定端口 sudo iptables -I INPUT -i lo -j ACCEPT #允许本地回环接口(即运行本机访问本机) sudo iptables -I INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT # 允许已建立的或相关连的通行 sudo iptables -I OUTPUT -j ACCEPT #允许所有本机向外的访问 sudo iptables -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT # 允许访问 22 端口 sudo iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT #允许访问 80 端口 sudo iptables -A INPUT -p tcp -m tcp --dport 8080 -j ACCEPT #允许访问 8080 端口 sudo iptables -A INPUT -p tcp -m tcp --dport 21 -j ACCEPT #允许 FTP 服务的 21 端口 sudo iptables -A INPUT -p tcp -m tcp --dport 20 -j ACCEPT #允许 FTP 服务的 20 端口 sudo iptables -I INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT #允许 ping sudo iptables -I INPUT -j REJECT #禁止其他未允许的规则访问（使用该规则前一定要保证 22 端口是开着，不然就连 SSH 都会连不上） sudo iptables -I FORWARD -j REJECT Iptables 资料 https://wsgzao.github.io/post/iptables/ http://www.vpser.net/security/linux-iptables.html 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK 安装]]></title>
      <url>%2F2017%2F11%2F22%2FJDK-Install%2F</url>
      <content type="text"><![CDATA[JDK 安装 CentOS 下过程 JDK 在 CentOS 和 Ubuntu 下安装过程是一样的，所以这里不再讲 Ubuntu 系统下的安装 JDK 1.8 下载 此时（20160205）最新版本：jdk-8u72-linux-x64.tar.gz 官网：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html 百度云下载（64 位）：http://pan.baidu.com/s/1eQZffbW 官网压缩包地址：http://211.138.156.198:82/1Q2W3E4R5T6Y7U8I9O0P1Z2X3C4V5B/download.oracle.com/otn-pub/java/jdk/8u72-b15/jdk-8u72-linux-x64.tar.gz 在命令行模式下下载上面压缩包： cd /opt sudo wget http://211.138.156.198:82/1Q2W3E4R5T6Y7U8I9O0P1Z2X3C4V5B/download.oracle.com/otn-pub/java/jdk/8u72-b15/jdk-8u72-linux-x64.tar.gz 默认 CentOS 有安装 openJDK，建议先卸载掉 检查 JDK 命令：java -version 查询本地 JDK 安装程序情况； rpm -qa|grep java 我查询出来的结果如下： java-1.6.0-openjdk-1.6.0.38-1.13.10.0.el6_7.x86_64 java-1.7.0-openjdk-1.7.0.95-2.6.4.0.el6_7.x86_64 tzdata-java-2015g-2.el6.noarch 卸载上面三个文件（--nodeps 的作用：忽略依赖的检查）： sudo rpm -e --nodeps java-1.6.0-openjdk-1.6.0.38-1.13.10.0.el6_7.x86_64 sudo rpm -e --nodeps java-1.7.0-openjdk-1.7.0.95-2.6.4.0.el6_7.x86_64 sudo rpm -e --nodeps tzdata-java-2015g-2.el6.noarch 也可以一起卸载：sudo rpm -e --nodeps java-1.6.0-openjdk-1.6.0.38-1.13.10.0.el6_7.x86_64 java-1.7.0-openjdk-1.7.0.95-2.6.4.0.el6_7.x86_64 tzdata-java-2015g-2.el6.noarch JDK 1.8 安装 我们以安装 jdk-8u72-linux-x64.tar.gz 为例 我个人习惯 /opt 目录下创建一个目录 setups 用来存放各种软件安装包；在 /usr 目录下创建一个 program 用来存放各种解压后的软件包，下面的讲解也都是基于此习惯 我个人已经使用了第三方源：EPEL、RepoForge，如果你出现 yum install XXXXX 安装不成功的话，很有可能就是你没有相关源，请查看我对源设置的文章 解压安装包：sudo tar -zxvf jdk-8u72-linux-x64.tar.gz 移到解压包到我个人习惯的安装目录下：mv jdk1.8.0_72/ /usr/program/ 配置环境变量： 编辑配置文件：sudo vim /etc/profile 在该文件的最尾巴，添加下面内容：# JDK JAVA_HOME=/usr/program/jdk1.8.0_72 JRE_HOME=$JAVA_HOME/jre PATH=$PATH:$JAVA_HOME/bin CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JAVA_HOME export JRE_HOME export PATH export CLASSPATH 执行命令，刷新该配置（必备操作）：source /etc/profile 检查是否使用了最新的 JDK：java -version 其他 JDK 历史版本下载地址整理（不间断更新）： JDK 8：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html JDK 7：http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html JDK 6：http://www.oracle.com/technetwork/java/javasebusiness/downloads/java-archive-downloads-javase6-419409.html 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title></title>
      <url>%2F2017%2F11%2F22%2Fcentos-settings%2FClear-Tmp-Directory%2F</url>
      <content type="text"><![CDATA[修改定时清理 /tmp 目录下的文件初衷 默认系统是超过 30 天不访问的文件自动清除的，但是有时候硬盘用得紧可以考虑修改周期 设置方法 编辑配置文件：vim /etc/cron.daily/tmpwatch #! /bin/sh flags=-umc /usr/sbin/tmpwatch &quot;$flags&quot; -x /tmp/.X11-unix -x /tmp/.XIM-unix \ -x /tmp/.font-unix -x /tmp/.ICE-unix -x /tmp/.Test-unix \ -X &#39;/tmp/hsperfdata_*&#39; 10d /tmp /usr/sbin/tmpwatch &quot;$flags&quot; 30d /var/tmp for d in /var/{cache/man,catman}/{cat?,X11R6/cat?,local/cat?}; do if [ -d &quot;$d&quot; ]; then /usr/sbin/tmpwatch &quot;$flags&quot; -f 30d &quot;$d&quot; fi done 上面这句话：/usr/sbin/tmpwatch &quot;$flags&quot; -f 30d &quot;$d&quot;，其中 30d 表示 30 天表示要备删除的周期文件，该值最低为 1。 一般数据建议不要放在这个目录下，以免被系统误删]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Jenkins 安装和配置]]></title>
      <url>%2F2017%2F11%2F22%2FJenkins-Install-And-Settings%2F</url>
      <content type="text"><![CDATA[Jenkins 安装和配置 Jenkins 安装 Jenkins 安装 官网：http://jenkins-ci.org/ 官网帮助中心：https://wiki.jenkins-ci.org/display/JENKINS/Use+Jenkins 官网使用 Tomcat 部署方式指导：https://wiki.jenkins-ci.org/display/JENKINS/Tomcat 此时（20160207） Jenkins 最新版本为：1.647 JDK 最低要求是 JDK 7，官网推荐是 JDK 8 我个人习惯 /opt 目录下创建一个目录 setups 用来存放各种软件安装包；在 /usr 目录下创建一个 program 用来存放各种解压后的软件包，下面的讲解也都是基于此习惯 我个人已经使用了第三方源：EPEL、RepoForge，如果你出现 yum install XXXXX 安装不成功的话，很有可能就是你没有相关源，请查看我对源设置的文章 Jenkins 下载：wget http://mirrors.jenkins-ci.org/war/latest/jenkins.war （大小：61 M） 我们假设这个 Tomcat 就是为了 Jenkins 专用的 把下载下来的 jenkins.war 移到 Tomcat 的 webapps 目录下，比如我的是：/usr/program/tomcat8/webapps 把 Jenkins.war 改名为 ROOT.war：mv jenkins.war ROOT.war 删除 Tomcat 下 webapps 目录下多余的一些目录 首次启动 Tomcat，让 Tomcat 解压 war 设置 JENKINS_HOME： 寻找 jenkins home 目录地址：find / -name .jenkins，我这边得到的结果是：/root/.jenkins 对在 Tomcat 文章中讲解的系统变量 CATALINA_OPTS 进行设置： 旧值：CATALINA_OPTS=&quot;-server -Xms528m -Xmx528m -XX:PermSize=256m -XX:MaxPermSize=358m&quot; export CATALINA_OPTS 改为：CATALINA_OPTS=&quot;-server -DJENKINS_HOME=/root/.jenkins -Xms528m -Xmx528m -XX:PermSize=256m -XX:MaxPermSize=358m&quot; export CATALINA_OPTS Jenkins 各个组件配置： 访问：http://192.168.0.110:8080/configure 其他问题 如果访问的时候报这个异常：java.net.UnknownHostException，可以查看这篇文章：http://stackoverflow.com/questions/4969156/java-net-unknownhostexception 资料 http://stackoverflow.com/questions/4969156/java-net-unknownhostexception 参考来源judasn]]></content>
    </entry>

    
    <entry>
      <title></title>
      <url>%2F2017%2F11%2F22%2Fcentos-settings%2FCpu-Info%2F</url>
      <content type="text"><![CDATA[CPU 信息分析初衷 了解服务器的性能，以方便我们如何更好地对程序进行部署 CPU 信息 Demo CPU 型号：Intel® Xeon® Processor E5-2620 v2(15M Cache, 2.10 GHz) 该 CPU 显示的数据中有一项这个要注意：Intel® Hyper-Threading Technology 是 Yes。表示该 CPU 支持超线程 cat /proc/cpuinfo，查看 CPU 总体信息 grep &#39;physical id&#39; /proc/cpuinfo | sort -u | wc -l，查看物理 CPU 个数 结果：2 物理 CPU：物理 CPU 也就是机器外面就能看到的一个个 CPU，每个物理 CPU 还带有单独的风扇 grep &#39;core id&#39; /proc/cpuinfo | sort -u | wc -l，查看每个物理 CPU 的核心数量 结果：6，因为每个物理 CPU 是 6，所有 2 个物理 CPU 的总核心数量应该是：12 核心数：一个核心就是一个物理线程，英特尔有个超线程技术可以把一个物理线程模拟出两个线程来用，充分发挥 CPU 性能，意思是一个核心可以有多个线程。 grep &#39;processor&#39; /proc/cpuinfo | sort -u | wc -l，查看 CPU 总的线程数，一般也叫做：逻辑 CPU 数量 结果：24，正常情况下：CPU 的总核心数量 == CPU 线程数，但是如果该 CPU 支持超线程，那结果是：CPU 的总核心数量 X 2 == CPU 线程数 线程数：线程数是一种逻辑的概念，简单地说，就是模拟出的 CPU 核心数。比如，可以通过一个 CPU 核心数模拟出 2 线程的 CPU，也就是说，这个单核心的 CPU 被模拟成了一个类似双核心 CPU 的功能。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入理解Java虚拟机-学习]]></title>
      <url>%2F2017%2F11%2F17%2Fjvm-tool%2F</url>
      <content type="text"><![CDATA[jvm调优工具jdk的命令行工具 jps：虚拟机进程状况工具（jps -l） jstat：虚拟机统计信息监视工具（jstat -gcutil VMID，stat -gccapacity VMID） （Local Virtual Machine Identifier,LVMID） jinfo：Java配置信息工具 jinfo -flag +PrintGCDetails VMID jinfo -flag +PrintGC VMID jinfo -flag +PrintGCTimeStamps VMID以上就可以在一个正在运行的JVM中动态开启GC日志功能。 jmap：Java内存映像工具 jmap -heap VMID 显示Java堆详细信息，例如使用哪种回收器、参数配置、分代状况等。 jhat：虚拟机堆转储快照分析工具 jstack：Java堆栈跟踪工具 jstack -l VMID jdk的可视化工具jconsoleJDK中自带的java监控和管理控制台，用于对JVM中内存，线程和类等的监控，是一个基于JMX（java management extensions）的GUI性能监测工具。 VisualVMVisualVM（All-in-One Java Troubleshooting Tool）强大的运行监视和故障处理程序，也能够进行性能分析，CPU、内存，在Profiler页签中能看到。1.插件安装 2.主界面 因为VisualVM的插件太多，重点展示下Visual GC： 第三方调优工具 MAT(Memory Analyzer Tool) GC Easy MAT以eclipse插件形式安装,利用visualvm或者是 jmap命令生产堆文件，导入eclipse mat中生成分析报告： 参考在此：深入理解Java虚拟机 第2版jvm调优-工具篇 作者：纯洁的微笑]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java内存模型之happens-before]]></title>
      <url>%2F2017%2F11%2F03%2Fhappens-before%2F</url>
      <content type="text"><![CDATA[Java内存模型之happens-before从JDK 5 开始，JMM就使用happens-before(先行发生原则)的概念来阐述多线程之间的内存可见性。 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。 happens-before原则定义如下： 1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。2. 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。 下面是Java内存模型下一些“天然的“先行发生关系，可以再编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，虚拟机可以对它们随意地进行重排序。 （摘自《深入理解Java虚拟机第12章》）： 程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 锁定规则（Monitor Lock Rule）：一个unlock操作先行发生与后面同一个锁的lock操作。这里必须强调的是同一个锁，而”后面“是指时间上的先后顺序。 volatile变量规则（Volatile Variable Rule）：这是一条比较重要的规则，它标志着volatile保证了线程可见性。通俗点讲就是如果一个线程先去写一个volatile变量，然后一个线程去读这个变量，那么这个写操作一定是happens-before读操作的。 线程启动规则（Thread Start Rule）：Thread 对象的start()方法先行发生与此线程的每一个动作。 线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生与对此线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值等手段检测到线程已经终止执行。 线程中断原则（Thread Interruption Rule）：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到是否有中段发生。 对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生与它的finalize()方法的开始。 传递性（Transitivity）：如果操作A先行发生与操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。 上面八条是原生Java满足Happens-before关系的规则，但是我们可以对他们进行推导出其他满足happens-before的规则： 将一个元素放入一个线程安全的队列的操作Happens-Before从队列中取出这个元素的操作 将一个元素放入一个线程安全容器的操作Happens-Before从容器中取出这个元素的操作 在CountDownLatch上的倒数操作Happens-Before CountDownLatch#await()操作 释放Semaphore许可的操作Happens-Before获得许可操作 Future表示的任务的所有操作Happens-Before Future#get()操作 向Executor提交一个Runnable或Callable的操作Happens-Before任务开始执行操作 参考在此： 深入理解Java虚拟机：JVM高级特性与最佳实践（最新第二版）周志明 著]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java内存模型看并发（一）]]></title>
      <url>%2F2017%2F11%2F01%2FJVM-1%2F</url>
      <content type="text"><![CDATA[Java内存模型所有的Java开发人员可能会遇到这样的困惑？我该为堆内存设置多大空间呢？OutOfMemoryError的异常到底涉及到运行时数据的哪块区域？该怎么解决呢？ 对象和类的数据存储在3个不同的内存区域：堆（heap space）、方法区（method area）、本地区（native area）。 堆内存存放对象以及数组的数据，方法区存放类的信息（包括类名、方法、字段）、静态变量、编译器编译后的代码，本地区包含线程栈、本地方法栈等存放线程 方法区有时被称为持久代（PermGen）。 所有的对象在实例化后的整个运行周期内，都被存放在堆内存中。堆内存又被划分成不同的部分：伊甸区(Eden)，幸存者区域(Survivor Sapce)，老年代（Old Generation Space）。 方法的执行都是伴随着线程的。原始类型的本地变量以及引用都存放在线程栈中。而引用关联的对象比如String，都存在在堆中。 你真的会写单例吗/** * 漫画：什么是单例模式？见：https://mp.weixin.qq.com/s/pAYYcvh4IRvLs5WYgiPe3A * https://blankj.com/2016/04/21/really-use-singleton/ * @ClassName: Singleton.java * @Description: 单例模式实现方式&lt;br&gt; * 1、双重锁检测&lt;br&gt; * 2、静态内部类&lt;br&gt; * 3、饿汉式 * * @author: zhangjk * @date: 2018年3月7日 下午2:05:53 */ public class Singleton { //一、双检查锁（DCL，即 double-checked locking） //描述：这种方式称为双重检查锁(Double-Check Locking)，需要注意的是，如果使用双重检查锁定来实现懒汉式单例类 // private Singleton() {} // private volatile static Singleton instance = null; //单例对象;volatile 修饰符阻止了变量访问前后的指令重排序，保证了指令执行顺序。 // public static Singleton getInstance() { // if (instance == null) { // synchronized (Singleton.class) { // if(instance == null) { // instance = new Singleton(); // } // } // } // return instance; // } // 二、用静态内部类实现单例模式： // 1.从外部无法访问静态内部类LazyHolder，只有当调用Singleton.getInstance方法的时候，才能得到单例对象INSTANCE。 // 2.INSTANCE对象初始化的时机并不是在单例类Singleton被加载的时候，而是在调用getInstance方法，使得静态内部类LazyHolder被加载的时候。 //描述：饿汉式单例类不能实现延迟加载，不管将来用不用始终占据内存；懒汉式单例类线程安全控制繁琐，而且性能受影响。 // private static class LazyHolder { // private static final Singleton INSTANCE = new Singleton(); // } // // private Singleton() {} // public static Singleton getInstance() { // return LazyHolder.INSTANCE; // } //三、饿汉式 //优点：没有加锁，执行效率会提高。 //缺点：类加载时就初始化，浪费内存。 private static Singleton instance = new Singleton(); private Singleton() {} public static Singleton getIntance() { return instance; } } 并发工具类CountDownLatch和CyclicBarrier是jdk concurrent包下非常有用的两个并发工具类，它们提供了一种控制并发流程的手段。 CountDownLatch 允许一个或多个线程等待其他线程完成操作。CyclicBarrier 让一组线程到达一个同步点后再一起继续运行，在其中任意一个线程未达到同步点，其他到达的线程均会被阻塞。 Semaphore（信号量）信号量(Semaphore)，有时被称为信号灯，是在多线程环境下使用的一种设施, 它负责协调各个线程, 以保证它们能够正确、合理的使用公共资源。 一个计数信号量。从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release() 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore 只对可用许可的号码进行计数，并采取相应的行动。拿到信号量的线程可以进入代码，否则就等待。通过acquire()和release()获取和释放访问许可。 /** * 控制并发线程数 */ public class SemaphoreDemo { /** *执行任务类，获取信号量 */ class SemaphoreRunnable implements Runnable{ private Semaphore semaphore; private int user; public SemaphoreRunnable(Semaphore semaphore, int user) { this.semaphore = semaphore; this.user = user; } @Override public void run() { try { //获取信号量许可 semaphore.acquire(); System.out.println(&quot;用户【&quot; + user + &quot;】进入窗口，准备买票...&quot;); Thread.sleep((long)(Math.random()*10000)); System.out.println(&quot;用户【&quot; + user + &quot;】买票完成，即将离开...&quot;); Thread.sleep((long)(Math.random()*10000)); System.out.println(&quot;用户【&quot; + user + &quot;】离开售票窗口...&quot;); //释放信号量许可 semaphore.release(); } catch (InterruptedException e) { e.printStackTrace(); } } } private void execute(){ //定义窗口个数 final Semaphore semaphore = new Semaphore(3); //线程池 ExecutorService threadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) { threadPool.execute(new SemaphoreRunnable(semaphore,i + 1)); } threadPool.shutdown(); } public static void main(String[] args) { SemaphoreDemo semaphoreDemo = new SemaphoreDemo(); semaphoreDemo.execute(); } } CountDownLatch源码注释：A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes.（一个或者多个线程，等待其他多个线程完成某件事情之后才能执行） CountDownLatch声明： CountDownLatch的构造函数接受int型参数作为它的计数器，如果想等待N个点完成，就传入N； 调用CountDownLatch的countDown方法时，N会减1，CountDownLatch的await方法会阻塞主线程直到N减少到0。 网上有个经典例子，在此抄录一下帮助理解记忆。 /** * F1赛车每次进站后，车队技师都需要在尽可能短的时间内对赛车做三个工作：加注燃油、更换轮胎、更换刹车片。 * 当然，这三项工作都是同时进行的。只有当这三项工作完成，赛车才能驶出维修站。 */ public class CountdownlatchDemo { static class Mechanician implements Runnable{ String work; CountDownLatch cDownLatch ; public Mechanician(String work,CountDownLatch cDownLatch) { this.work = work; this.cDownLatch = cDownLatch; } @Override public void run() { try { int random=new Random().nextInt(7); TimeUnit.SECONDS.sleep(random); System.out.println(Thread.currentThread().getName()+&quot;--- &quot;+work+&quot; 完成，此组耗时：&quot;+random+&quot;秒&quot;); } catch (InterruptedException e) { e.printStackTrace(); }finally{ /*当前技师的任务完成,cDownLatch计算器减1 *通常countDown放在finally里中使用*/ cDownLatch.countDown(); } } } public static void main(String[] args) { CountDownLatch cDownLatch=new CountDownLatch(3);//初始计数器值为3，对应3个维修组 /*1、赛车进站*/ System.out.println(&quot;F1赛车进站，时间：&quot;+Calendar.getInstance().get(Calendar.SECOND)); List&lt;Mechanician&gt; mechanician_team=new ArrayList&lt;Mechanician&gt;(); mechanician_team.add(new Mechanician(&quot;加注燃油&quot;, cDownLatch)); mechanician_team.add(new Mechanician(&quot;更换轮胎&quot;, cDownLatch)); mechanician_team.add(new Mechanician(&quot;更换刹车片&quot;, cDownLatch)); for(Mechanician mechanician : mechanician_team){ new Thread(mechanician).start(); } /*3、等待技师完成三项工作。实际就是等待cDownLatch计数器变成0*/ try { cDownLatch.await(); } catch (InterruptedException e) { e.printStackTrace(); } /*4、完成维护，出发*/ System.out.println(&quot;F1赛车维修完毕，出发！时间：&quot;+Calendar.getInstance().get(Calendar.SECOND)); } } Countdownlatch 是一个倒计数器锁。调用CountDownLatch对象的await()方法使线程处于等待状态，调用countDown()方法的线程会将计数器减1，当计数到达0时，所有等待线程（可多个，但通常的应用场景中只有一个等待者）开始继续执行。 CyclicBarrier源码注释：A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point.（多个线程互相等待，直到到达同一个同步点，再继续一起执行） CyclicBarrier(int parties) 默认构造方法，参数表示拦截的线程数量。 CyclicBarrier(int parties, Runnable barrierAction)由于线程之前的调度是由CPU决定的，所以默认的构造方法无法设置线程执行优先级，CyclicBarrier提供一个更高级的构造函数(int parties, Runnable barrierAction)，用于在线程到达同步点时，优先执行线程barrierAction，这样可以更加方便的处理一些复杂的业务场景。 创建CyclicBarrier后，每个线程调用await方法告诉CyclicBarrier自己已经到达同步点，然后当前线程被阻塞。 结语在Java语言内部，java.lang.Runtime对象就是一个使用单例模式的例子。在每一个Java应用程序里面，都有唯一的一个Runtime对象，应用程序可以与其运行环境发生相互作用。 参考在此：深入理解Java虚拟机 第2版（第2章 Java 内存区域与内存溢出异常）JAVA的内存模型及结构你真的会写单例吗J.U.C之并发工具类：CountDownLatch]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[poi实现Excel文件导入、导出]]></title>
      <url>%2F2017%2F10%2F23%2FExcel-poi-how%2F</url>
      <content type="text"><![CDATA[poi 是什么呢Apache POI 简介是用Java编写的免费开源的跨平台的 Java API，Apache POI提供API给Java程式对Microsoft Office（Excel、WORD、PowerPoint、Visio等）格式档案读和写的功能。POI为“Poor Obfuscation Implementation”的首字母缩写，意为“可怜的模糊实现”。 与我而言使用于某项技术，来完成特定业务是最重要的。看下图最终要实现的功能：考查、考试，在对应的中期（期中）考核形式、期末考试形式 相应位置处画 √必修课补考形式 唯一必填。难点在于 期中考试形式、期末考试形式、必修课补考形式（考试形式字典）是动态可增减的。 归纳总结Excel工具类 public static Map&lt;String,String&gt; getExcelHeaderString(String filePath) { // You&#39;d use HSSF if you needed to read or write an Excel file using Java (XLS). // You&#39;d use XSSF if you need to read or write an OOXML Excel file using Java (XLSX). boolean isE2007 = false; //判断是否是excel2007格式 if(filePath.endsWith(&quot;xlsx&quot;)) isE2007 = true; //得到表头字段 Map&lt;String, String&gt; excelHeaderMap = new LinkedHashMap&lt;String, String&gt;(); InputStream input = null; Workbook wb = null; try { //建立输入流 input = new FileInputStream(filePath); //根据文件格式(2003或者2007)来初始化 if(isE2007) wb = new XSSFWorkbook(input); else wb = new HSSFWorkbook(input); Sheet sheet = wb.getSheetAt(0); //获得第一个表单 Row row = sheet.getRow(0); int columnNum = row.getLastCellNum(); for (short i = 0; i &lt; columnNum; i++) { Cell cell = row.getCell(i); String HeaderString = cell.getRichStringCellValue().getString().trim(); excelHeaderMap.put(HeaderString,HeaderString); } } catch (IOException e) { e.printStackTrace(); }finally{ try { if(null != wb){ input.close(); wb.close(); } } catch (IOException e) { } } return excelHeaderMap; } public static List&lt;Map&lt;String,Object&gt;&gt; getBeanList(String filePath) throws IOException{ return getBeanList(filePath, null); } /** * 解析excel 数据，每一行存为一个map， key为每列首行对应的文字 */ public static List&lt;Map&lt;String,Object&gt;&gt; getBeanList(String filePath, Map&lt;String, String&gt; matchingResultMap) throws IOException{ List&lt;Map&lt;String,Object&gt;&gt; beanList = new ArrayList&lt;Map&lt;String,Object&gt;&gt;(); boolean isE2007 = false; //判断是否是excel2007格式 if(filePath.endsWith(&quot;xlsx&quot;)) isE2007 = true; InputStream input = null; Workbook wb = null; try { //建立输入流 input = new FileInputStream(filePath); //根据文件格式(2003或者2007)来初始化 if(isE2007) wb = new XSSFWorkbook(input); else wb = new HSSFWorkbook(input); Sheet sheet = wb.getSheetAt(0); Map&lt;Short, String&gt; excelHeaderMap = new HashMap&lt;Short, String&gt;(); int firstRowNum = sheet.getFirstRowNum(); Row row = sheet.getRow(firstRowNum); int columnNum = row.getLastCellNum(); for (short i = 0; i &lt; columnNum; i++) { Cell cell = row.getCell(i); String HeaderString = cell.getRichStringCellValue().getString().trim(); excelHeaderMap.put(i,HeaderString); } int rowNum = sheet.getPhysicalNumberOfRows();// 获取第0个sheet的行的数量(1...n) for (int i = firstRowNum+1; i &lt; rowNum; i++) { Row xRow = sheet.getRow(i); Map&lt;String,Object&gt; beanMap = new LinkedHashMap&lt;String, Object&gt;(); for(short j=0; j &lt; columnNum; j++ ){ String headerKey = null; if ( matchingResultMap == null || matchingResultMap.get(excelHeaderMap.get(j)) == null){ headerKey = excelHeaderMap.get(j); } else { matchingResultMap.get(excelHeaderMap.get(j)); } String headerValue = null; if(null != xRow.getCell(j)){ headerValue = getCellContent(xRow.getCell(j)).trim(); if (beanMap.get(headerKey) == null){ beanMap.put(headerKey, headerValue); } }else{ beanMap.put(headerKey, &quot;&quot;); } } if(beanMap.containsKey(null)){ beanMap.remove(null); } beanMap.put(&quot;row_num&quot;, i + 1);//excel中的行号 beanList.add(beanMap); } }catch(IOException e){ }finally{ input.close(); wb.close(); } return beanList; } /** * 根据 二维数组（数据）在指定路径下生成文件 * * @param fileFullPathName 绝对文件路径（包含文件名） * @param fieldNames 表头字段数组 * @param data 二维数组（数据）Object[行][列] * @return boolean (标识是否成功生成文件) * @author zhangjinkui */ public static boolean writeFile(String fileFullPathName,String[] fieldNames,Object[][] data) { boolean flag = false; HSSFWorkbook wb = new HSSFWorkbook(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); try { // 创建字体 Font font = wb.createFont(); // 创建列样式 CellStyle cellStyle = wb.createCellStyle(); Sheet sheet = wb.createSheet(); Row row = sheet.createRow(0); int colLength = fieldNames.length; for (int i = 0; i &lt; colLength; i++) { row.setHeightInPoints(25); sheet.setColumnWidth(i, 256*16); ExcelUtils.createCell(row, i, fieldNames[i],createHeadCell(wb)); } int line = 0; for (line = 0; line &lt; data.length; line++) { Row rowtemp = sheet.createRow(line +1); for (int col = 0; col &lt; colLength; col++) { createCell2(rowtemp, col,data[line][col],createCellStyle(font,cellStyle)); } } wb.write(baos); File file = new File(fileFullPathName); FileUtils.writeByteArrayToFile(file, baos.toByteArray()); flag = true; } catch (Exception e) { flag = false; } finally { try { baos.close(); wb.close(); } catch (IOException e) { e.printStackTrace(); } } return flag; } /** * 得到字节流之后，可直接写入客户端，也可写入到指定文件 * * @param sheetName sheet页名称 * @param fieldNames 表头字段数组 * @param data 二维数组（数据）Object[行][列] * @return 返回字节数组 * @throws IOException * @author zhangjinkui */ public static byte[] writeExcel(String sheetName,String[] fieldNames,Object[][] data) throws IOException{ ByteArrayOutputStream baos = new ByteArrayOutputStream(); HSSFWorkbook wb = new HSSFWorkbook(); try { // 创建字体 Font font = wb.createFont(); // 创建列样式 CellStyle cellStyle = wb.createCellStyle(); Sheet sheet = null; if(StringUtils.isBlank(sheetName)){ sheet = wb.createSheet(&quot;&quot;); }else{ sheet = wb.createSheet(sheetName); } Row row = sheet.createRow(0); int colLength = fieldNames.length; for (int i = 0; i &lt; colLength; i++) { row.setHeightInPoints(25); sheet.setColumnWidth(i, 256*16); ExcelUtils.createCell(row, i, fieldNames[i], createHeadCell(wb)); } int line = 0; for (line = 0; line &lt; data.length; line++) { Row rowtemp = sheet.createRow(line +1); for (int col = 0; col &lt; colLength; col++) { createCell2(rowtemp, col,data[line][col],createCellStyle(font,cellStyle)); } } wb.write(baos); } catch (Exception e) { } finally { try { baos.close(); wb.close(); } catch (IOException e) { e.printStackTrace(); } } return baos.toByteArray(); } /** * 合并单元格 行 * @param sheet * @param columnNum 从第几列开始（0-based） * @param rowStart 从第几行开始（0-based） * @param rowspan 跨多少行 */ public static void mergedRegionRow(Sheet sheet, int columnNum, int rowStart, int rowspan){ sheet.addMergedRegion(new CellRangeAddress( rowStart, //first row (0-based) rowStart + rowspan-1, //last row (0-based) columnNum, //first column (0-based) columnNum //last column (0-based) )); } /** * 合并单元格 列 * @param sheet * @param rowNum 第几行 （0-based） * @param colStart 从第几列开始（0-based） * @param colspan 跨多少列 */ public static void mergedRegionColumn(Sheet sheet, int rowNum, int colStart, int colspan){ sheet.addMergedRegion(new CellRangeAddress( rowNum, //first row (0-based) rowNum, //last row (0-based) colStart, //first column (0-based) colStart + colspan - 1 //last column (0-based) )); } /** * 设置生成Cell单元格 * @param row * @param column * @param cellValue * @param cellStyle */ public static void createCell(Row row, Integer column, String cellValue, CellStyle cellStyle) { Cell cell = row.createCell(column); if(StringUtils.isEmpty(cellValue)) cellValue = &quot;&quot;; cell.setCellValue(cellValue); // 统一将单元格格式设置成字符串类型 cell.setCellType(Cell.CELL_TYPE_STRING); cell.setCellStyle(cellStyle); } public static void createCell2(Row row, Integer column, Object cellValue, CellStyle cellStyle) { Cell cell = row.createCell(column); if(StringUtils.isEmpty(String.valueOf(cellValue))) cellValue = &quot;&quot;; try { if (isNumeric(String.valueOf(cellValue))){ double num = Double.valueOf(String.valueOf(cellValue)); cell.setCellValue(num); cell.setCellType(Cell.CELL_TYPE_NUMERIC); } else { cell.setCellValue(String.valueOf(cellValue)); cell.setCellType(Cell.CELL_TYPE_STRING); } }catch(Exception e){ cell.setCellValue(String.valueOf(cellValue)); cell.setCellType(Cell.CELL_TYPE_STRING); } cell.setCellStyle(cellStyle); } private static boolean isNumeric(String value){ if (StringUtils.isBlank(value) ){ return false; } //http://blog.jobbole.com/96052/ //非负浮点数：^\d+(\.\d+)?$ 或 ^[1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0$ // String reg = &quot;^\\d+(\\.\\d+)?$&quot;; String reg = &quot;^(0|([1-9]\\d{0,6}))(\\.\\d+)?$&quot;;//避免长数字出现科学计数法 return Pattern.compile(reg).matcher(value).find(); } /** * 设置生成Cell单元格 * @param row * @param column * @param cellValue */ public static void createCell(Row row, Integer column, String cellValue) { Cell cell = row.createCell(column); if(StringUtils.isEmpty(cellValue)) cellValue = &quot;&quot;; cell.setCellValue(cellValue); // 统一将单元格格式设置成字符串类型 cell.setCellType(Cell.CELL_TYPE_STRING); } /** * 设置生成Cell单元格 * @param row * @param column * @param cellValue */ public static void createCell(Row row, Integer column, Object cellValue) { Cell cell = row.createCell(column); if(StringUtils.isEmpty(String.valueOf(cellValue))) cellValue = &quot;&quot;; cell.setCellValue(String.valueOf(cellValue)); // 统一将单元格格式设置成字符串类型 cell.setCellType(Cell.CELL_TYPE_STRING); } /** * 获得excel列的值，以字符串格式返回 * 避免过大数字 以出现科学计数法形式出现 * @param cell * @return */ public static String getCellContent(Cell cell){ switch (cell.getCellType()) { case Cell.CELL_TYPE_STRING: return String.valueOf(cell.getRichStringCellValue().toString().trim()); case Cell.CELL_TYPE_NUMERIC: if (DateUtil.isCellDateFormatted(cell)) { return String.valueOf(cell.getDateCellValue()); } else { DecimalFormat df = new DecimalFormat(&quot;0&quot;); return df.format(cell.getNumericCellValue()); } case Cell.CELL_TYPE_BOOLEAN: return String.valueOf(cell.getBooleanCellValue()); case Cell.CELL_TYPE_FORMULA: String strCell = null; try { strCell = String.valueOf(cell.getStringCellValue().trim()); } catch (IllegalStateException e) { strCell = String.valueOf(cell.getNumericCellValue()); } return strCell; default: return String.valueOf(cell.getRichStringCellValue().getString().trim()); } } /** * 正文 默认字体样式，setWrapText=true（自动换行） * @return */ public static CellStyle createCellStyle(Font font,CellStyle cellStyle) { // 设置字体颜色 (黑色) font.setColor(HSSFColor.BLACK.index); // 设置字体 font.setFontName(&quot;宋体&quot;); // 设置粗体 font.setBoldweight(HSSFFont.BOLDWEIGHT_NORMAL); // 设置字体大小 font.setFontHeightInPoints((short)12); cellStyle.setWrapText(true); // 设置字体 cellStyle.setFont(font); // 设置对齐 cellStyle.setAlignment(CellStyle.ALIGN_CENTER); // 垂直居中 cellStyle.setVerticalAlignment(CellStyle.VERTICAL_CENTER); cellStyle.setLocked(false); return cellStyle; } /** * 正文 默认字体样式，setWrapText=false（不允许自动换行） * @return */ public static CellStyle createCellStyleWrapTextFalse(Font font,CellStyle cellStyle) { // 设置字体颜色 (黑色) font.setColor(HSSFColor.BLACK.index); // 设置字体 font.setFontName(&quot;宋体&quot;); // 设置粗体 font.setBoldweight(HSSFFont.BOLDWEIGHT_NORMAL); // 设置字体大小 font.setFontHeightInPoints((short)12); cellStyle.setWrapText(false); // 设置字体 cellStyle.setFont(font); // 设置对齐 cellStyle.setAlignment(CellStyle.ALIGN_CENTER); // 垂直居中 cellStyle.setVerticalAlignment(CellStyle.VERTICAL_CENTER); cellStyle.setLocked(false); return cellStyle; } /** * 允许换行 * @param wb * @return */ public static CellStyle createBrCellStyle(HSSFWorkbook wb) { // 创建列样式 CellStyle style = wb.createCellStyle(); // 创建字体 Font font = wb.createFont(); // 设置字体颜色 (黑色) font.setColor(HSSFColor.BLACK.index); // 设置字体 font.setFontName(&quot;宋体&quot;); // 设置粗体 font.setBoldweight(HSSFFont.BOLDWEIGHT_NORMAL); // 设置字体大小 font.setFontHeightInPoints((short)12); // 设置不换行 style.setWrapText(true); // 设置字体 style.setFont(font); // 设置对齐 style.setAlignment(CellStyle.ALIGN_LEFT); // 垂直居中 style.setVerticalAlignment(CellStyle.ALIGN_LEFT); style.setLocked(false); return style; } /** * 表头默认样式：宋体 12号字体，加粗 * @return */ public static CellStyle createHeadCell(HSSFWorkbook wb) { // 创建字体 Font font = wb.createFont(); // 创建列样式 CellStyle cellStyle = wb.createCellStyle(); // 设置字体颜色 (黑色) font.setColor(HSSFColor.BLACK.index); font.setFontName(&quot;宋体&quot;); // 设置粗体 font.setBoldweight(HSSFFont.BOLDWEIGHT_BOLD); // 设置字体大小 font.setFontHeightInPoints((short)12); // 设置不允许自动换行 cellStyle.setWrapText(false); // 设置字体 cellStyle.setFont(font); // 设置对齐 cellStyle.setAlignment(CellStyle.ALIGN_CENTER); cellStyle.setVerticalAlignment(CellStyle.VERTICAL_CENTER); cellStyle.setLocked(false); return cellStyle; } /** * 特殊格式自定义，主要用在表头上 * @return */ public static CellStyle createHSSFCellStyle(HSSFWorkbook wb,short boldweight, short fontheight, short alignment) { // 创建列样式 CellStyle style = wb.createCellStyle(); // 创建字体 Font font = wb.createFont(); // 设置字体颜色 (黑色) font.setColor(HSSFColor.BLACK.index); // 设置字体 font.setFontName(&quot;宋体&quot;); // 设置粗体 font.setBoldweight(boldweight); // 设置字体大小 font.setFontHeightInPoints(fontheight); // 设置不换行 style.setWrapText(false); // 设置字体 style.setFont(font); // 设置对齐 style.setAlignment(alignment); // 垂直居中 style.setVerticalAlignment(CellStyle.VERTICAL_CENTER); style.setLocked(false); return style; } /** * 获取合并单元格的值 * @return */ public static String getMergedRegionValue(Sheet sheet, int row, int column) { int sheetMergeCount = sheet.getNumMergedRegions(); for (int i = 0; i &lt; sheetMergeCount; i++) { CellRangeAddress ca = sheet.getMergedRegion(i); int firstColumn = ca.getFirstColumn(); int lastColumn = ca.getLastColumn(); int firstRow = ca.getFirstRow(); int lastRow = ca.getLastRow(); if (row &gt;= firstRow &amp;&amp; row &lt;= lastRow) { if (column &gt;= firstColumn &amp;&amp; column &lt;= lastColumn) { Row fRow = sheet.getRow(firstRow); Cell fCell = fRow.getCell(firstColumn); return ExcelUtils.getCellContent(fCell); } } } return null; } /** * 得到合并区域 * * @param sheet * @param row * @param column * @return */ public static CellRangeAddress getMergedRegion(Sheet sheet, int row, int column) { int sheetMergeCount = sheet.getNumMergedRegions(); for (int i = 0; i &lt; sheetMergeCount; i++) { CellRangeAddress region = sheet.getMergedRegion(i); int firstColumn = region.getFirstColumn(); int lastColumn = region.getLastColumn(); int firstRow = region.getFirstRow(); int lastRow = region.getLastRow(); if (row &gt;= firstRow &amp;&amp; row &lt;= lastRow) { if (column &gt;= firstColumn &amp;&amp; column &lt;= lastColumn) { return region; } } } return null; } /** * 判断合并了行 * * @param sheet * @param row * @param column * @return */ public static boolean isMergedRow(Sheet sheet, int row, int column) { int sheetMergeCount = sheet.getNumMergedRegions(); for (int i = 0; i &lt; sheetMergeCount; i++) { CellRangeAddress range = sheet.getMergedRegion(i); int firstColumn = range.getFirstColumn(); int lastColumn = range.getLastColumn(); int firstRow = range.getFirstRow(); int lastRow = range.getLastRow(); if (row == firstRow &amp;&amp; row == lastRow) { if (column &gt;= firstColumn &amp;&amp; column &lt;= lastColumn) { return true; } } } return false; } /** * 判断指定的单元格是否是合并单元格 * * @param sheet * 工作表 * @param row * 行下标 * @param column * 列下标 * @return */ public static boolean isMergedRegion(Sheet sheet, int row, int column) { int sheetMergeCount = sheet.getNumMergedRegions(); for (int i = 0; i &lt; sheetMergeCount; i++) { CellRangeAddress range = sheet.getMergedRegion(i); int firstColumn = range.getFirstColumn(); int lastColumn = range.getLastColumn(); int firstRow = range.getFirstRow(); int lastRow = range.getLastRow(); if (row &gt;= firstRow &amp;&amp; row &lt;= lastRow) { if (column &gt;= firstColumn &amp;&amp; column &lt;= lastColumn) { return true; } } } return false; } 页面部分分为三步：1、上传文件2、设置数据更新方式3、提示（比如说Excel中有重复记录，也需要提示出来，让用户修改后重新导入） #结语记录备忘之。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[itext实现录取通知书、成绩单]]></title>
      <url>%2F2017%2F07%2F03%2Fitext-how%2F</url>
      <content type="text"><![CDATA[itext5、jfreechart生成成绩分析图表，并写入成绩单pdf浏览器中展示图表，一般都是用百度的ECharts来展现。但是后台导出成绩单，必须要绕过浏览器才最方便。 在maven中引入itext5、jfreechart、ssj &lt;dependency&gt; &lt;groupId&gt;com.itextpdf&lt;/groupId&gt; &lt;artifactId&gt;itextpdf&lt;/artifactId&gt; &lt;version&gt;5.5.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.itextpdf&lt;/groupId&gt; &lt;artifactId&gt;itext-pdfa&lt;/artifactId&gt; &lt;version&gt;5.5.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.itextpdf&lt;/groupId&gt; &lt;artifactId&gt;itext-xtra&lt;/artifactId&gt; &lt;version&gt;5.5.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.itextpdf.tool&lt;/groupId&gt; &lt;artifactId&gt;xmlworker&lt;/artifactId&gt; &lt;version&gt;5.5.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.itextpdf&lt;/groupId&gt; &lt;artifactId&gt;itext-asian&lt;/artifactId&gt; &lt;version&gt;5.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-math3&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jfree&lt;/groupId&gt; &lt;artifactId&gt;jfreechart&lt;/artifactId&gt; &lt;version&gt;1.0.14&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.lowagie&lt;/groupId&gt; &lt;artifactId&gt;itext&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ca.umontreal.iro.simul&lt;/groupId&gt; &lt;artifactId&gt;ssj&lt;/artifactId&gt; &lt;version&gt;3.2.1&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;jfree&lt;/groupId&gt; &lt;artifactId&gt;jfreechart&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; 示例如图： 中位数、标准差、峰度、偏度等使用 org.apache.commons.math3.analysis.function.*直接函数调用，很方便。 结语菜头叔每篇公号文章都有个 禅定时刻，很是喜欢。在此有样学样吧。 一个酒鬼的自述“一个人活得拧巴是值得理解的，甚至是值得赞美的，这证明他内心还有冲突，并不甘于和人生妥协。但是，通过酒来发泄显得太过脆弱而虚伪，且对不起那瓶好酒。酒带给人们的应该是被压抑的快乐，而不是被压抑的痛苦。” 不是酒鬼，不咋饮酒，但是挺喜欢这句话。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mac上使用Homebrew进行MySQL卸载、安装，解决乱码]]></title>
      <url>%2F2017%2F06%2F22%2FMySQL-how%2F</url>
      <content type="text"><![CDATA[Mac上使用Homebrew进行MySQL卸载、安装，解决乱码Mac上使用Homebrew进行MySQL卸载系统环境 Mac 10.12Homebrew 1.2.3MySQL 5.6.36_1homebrew 卸载 $ brew remove mysql@5.6 $ brew cleanup $ launchctl unload -w ~/Library/LaunchAgents/homebrew.mxcl.mysql@5.6.plist 删除文件 $ sudo rm -f /etc/my.cnf $ sudo rm -rf /usr/local/var/mysql $ sudo rm ~/Library/LaunchAgents/homebrew.mxcl.mysql@5.6.plist Mac上使用Homebrew安装MySQL$ brew install mysql@5.6 让 MySQL 开机自行启动$ ln -sfv /usr/local/opt/mysql@5.6/*.plist ~/Library/LaunchAgents $ sudo find /usr/local/Cellar/mysql@5.6/5.6.36_1/ -name &quot;homebrew.mxcl.mysql@5.6.plist&quot; -exec cp {} ~/Library/LaunchAgents/ \; $ launchctl load -w ~/Library/LaunchAgents/homebrew.mxcl.mysql@5.6.plist 指定MySQL数据存放路径$ mysql_install_db --verbose --user=`whoami` --basedir=&quot;/usr/local/Cellar/mysql@5.6/5.6.36_1&quot; --datadir=/usr/local/var/mysql --tmpdir=/tmp $ cd . ; /usr/local/Cellar/mysql@5.6/5.6.36_1/bin/mysqld_safe &amp; 配置MySQL修改 /etc/my.cnf，没有就从MySQL安装目录拷贝一个模板过来。# For advice on how to change settings please see # http://dev.mysql.com/doc/refman/5.6/en/server-configuration-defaults.html [mysqld] port=3306 datadir=/usr/local/var/mysql # Remove leading # and set to the amount of RAM for the most important data # cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%. # innodb_buffer_pool_size = 128M # Remove leading # to turn on a very important data integrity option: logging # changes to the binary log between backups. # log_bin # These are commonly set, remove the # and set as required. # basedir = ..... # datadir = ..... # port = ..... # server_id = ..... # socket = ..... # Remove leading # to set options mainly useful for reporting servers. 将mysql加入系统环境变量执行vim ~/.bash_profile在该文件中添加如下语句，完成后，按esc，然后输入wq保存。export PATH=/usr/local/opt/mysql@5.6/bin:$PATH最后在命令行输入source ~/.bash_profile ok ,可以启动MySQL了。$ mysql.server start权限配置参见官网：https://dev.mysql.com/doc/refman/5.7/en/resetting-permissions.html 设置密码默认是没有密码的，进去mysql后，执行语句： mysql&gt; set password for &#39;root&#39;@&#39;localhost&#39;=password(&#39;root&#39;); Query OK, 0 rows affected (0.01 sec) 接下来使用密码登录MySQL： $ mysql -uroot -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 395 Server version: 5.6.36 Homebrew Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement. mysql&gt; show variables like &#39;character%&#39;; +--------------------------+------------------------------------------------------------+ | Variable_name | Value | +--------------------------+------------------------------------------------------------+ | character_set_client | utf8 | | character_set_connection | utf8 | | character_set_database | utf8 | | character_set_filesystem | binary | | character_set_results | utf8 | | character_set_server | utf8 | | character_set_system | utf8 | | character_sets_dir | /usr/local/Cellar/mysql@5.6/5.6.36_1/share/mysql/charsets/ | +--------------------------+------------------------------------------------------------+ 8 rows in set (0.04 sec) 看到utf8，编码就不会出问题了。 结语之所以写这篇，原因是从Windows转到Mac环境搞开发，碰到了乱码问题，各种配置都试了也没解决。卸载重装妥妥的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker初探]]></title>
      <url>%2F2017%2F06%2F16%2Fdocker-how-1%2F</url>
      <content type="text"><![CDATA[初始容器与Dockerhttps://docs.docker.com/engine/docker-overview/ 什么是DockerDocker开源项目背景Docker是基于Go语言实现的开源容器项目，诞生于2013年年初，最初发起者是dotCloud公司。Docker自开源后受到广泛的关注和讨论，目前已有多个相关项目（包括Docker三剑客、Kubernetes等），逐渐形成了围绕Docker容器的生态体系。由于Docker在业界造成的影响力实在太大，dotCloud公司后来也直接改名为Docker Inc，并专注于Docker相关技术和产品的开发。 对于Docker，目前的定义是一个开源的容器引擎，可以方便地对容器（关于容器，将在第2章详细介绍）进行管理。其对镜像的打包封装，以及引入的Docker Registry对镜像的统一管理，构建了方便快捷的“Build，Ship and Run”流程，它可以统一整个开发、测试和部署的环境和流程，极大地减少运维成本。 Docker在开发和运维中的优势对开发和运维（DevOps）人员来说，可能最梦寐以求的效果就是一次创建或配置，之后可以在任意地方、任意时间让应用正常运行。 1.更快速的交付和部署。使用Docker，开发人员可以使用镜像来快速构建一套标准的开发环境；开发完成之后，测试和运维人员可以直接使用完全相同环境来部署代码。只要开发测试过的代码，就可以确保在生产环境无缝运行。Docker可以快速创建和删除容器，实现快速迭代，大量节约开发、测试、部署的时间。并且，整个过程全程可见，使团队更容易理解应用的创建和工作过程。2.更高效的资源利用。Docker容器的运行不需要额外的虚拟化管理程序（Virtual Machine Manager以及Hypervisor）支持，它是内核级的虚拟化，可以实现更高的性能，同时对资源的额外需求很低。3.更轻松的迁移和扩展。4.更简单的更新管理。使用Dockerfile，只需要小小的配置修改，就可以替代以往大量的更新工作。并且所有修改都以增量的方式被分发和更新，从而实现自动化并且高效的容器管理。 核心概念1.Docker镜像镜像是创建Docker容器的基础。通过版本管理和增量的文件系统，Docker提供了一套十分简单的机制来创建和更新现有的镜像。与容器相对应，如果说容器提供了一个完整的、隔离的运行环境，那么镜像则是这个运行环境的静态体现，是一个还没有运行起来的“运行环境”。Docker镜像通常是通过Dockerfile来创建的，Dockerfile提供了镜像内容的定制，同时也体现了层级关系的建立。 ps:镜像自身是只读的。容器从镜像启动的时候，会在镜像的最上层创建一个可写层。2.Docker容器在功能上，Docker通过Libcontainer实现对容器生命周期的管理、信息的设置和查询，以及监控和通信等功能。而容器也是对镜像的完美诠释，容器以镜像为基础，同时又为镜像提供了一个标准的和隔离的执行环境。在概念上，容器则很好地诠释了Docker集装箱的理念，集装箱可以存放任何货物，可以通过邮轮将货物运输到世界各地。运输集装箱的邮轮和装载卸载集装箱的码头都不用关心集装箱里的货物，这是一种标准的集装和运输方式。类似的，Docker的容器就是“软件界的集装箱”，它可以安装任意的软件和库文件，做任意的运行环境配置。 3.Docker仓库是Docker集中存放镜像文件的场所。 Install Docker for Machttps://docs.docker.com/docker-for-mac/install/ ~ docker version Client: Version: 17.03.1-ce API version: 1.27 Go version: go1.7.5 Git commit: c6d412e Built: Tue Mar 28 00:40:02 2017 OS/Arch: darwin/amd64 Server: Version: 17.03.1-ce API version: 1.27 (minimum version 1.12) Go version: go1.7.5 Git commit: c6d412e Built: Fri Mar 24 00:00:50 2017 OS/Arch: linux/amd64 Experimental: true 我们看到Client和Server均有输出，则说明Docker for Mac已经正常启动。 CentOS环境下安装DockerOS requirementsTo install Docker, you need the 64-bit version of CentOS 7.我是在Mac上安装的VirtualBox，然后装上CentOS 7镜像。 对于CentOS 7系统，CentOS-Extras源中已内置Docker yum安装[root@centos-docker yum.repos.d]# sudo tee /etc/yum.repos.d/docker.repo &lt;&lt;-&#39;EOF&#39; &gt; [dockerrepo] &gt; name=Docker Repository &gt; baseurl=https://yum.dockerproject.org/repo/main/centos/$releasever/ &gt; enabled=1 &gt; gpgcheck=1 &gt; gpgkey=https://yum.dockerproject.org/gpg &gt; EOF 之后更新yum软件源缓存，并安装docker-engine 即可。 $ sudo yum install -y yum-utils $ sudo yum update $ sudo yum makecache fast $ sudo yum install docker-engine 这是最新的版本。要想随意指定要安装的版本，如下命令，官网上如下。1.List the available versions: $ yum list docker-engine.x86_64 –showduplicates |sort -r 2.Install a specific version by adding the version after docker-engine, separated by a hyphen (-):$ sudo yum install docker-engine-version 脚本安装1.更新系统包到最新。$ yum -y update 2.执行Docker安装脚本 $ curl -fsSL https://get.docker.com/ | sh 获取镜像Docker Hub 镜像站点 安装／升级你的Docker客户端您可以通过阿里云的镜像仓库下载：mirrors.aliyun.com/help/docker-engine 或执行以下命令： curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh - 如何使用Docker加速器针对Docker客户端版本大于1.10的用户 您可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器： sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-‘EOF’{ “registry-mirrors”: [“https://wgqgbfsb.mirror.aliyuncs.com“]}EOFsudo systemctl daemon-reloadsudo systemctl restart docker 镜像是运行容器的前提，官方的Docker Hub网站已经提供了数十万个镜像供大家开放下载。可以使用docker pull命令直接从Docker Hub镜像源来下载镜像。该命令的格式为docker pull NAME[：TAG]。其中，NAME是镜像仓库的名称（用来区分镜像），TAG是镜像的标签（往往用来表示版本信息）。通常情况下，描述一个镜像需要包括“名称+标签”信息。 现在想要获得centos的Docker镜像，1.docker search –no-trunc centos2.docker pull docker.io/jdeathe/centos-ssh 查看镜像信息1.使用images命令列出镜像2.使用tag命令添加镜像标签3.使用inspect命令查看详细信息4.使用history命令查看镜像历史(docker history –no-trunc centos-ssh) 搜寻镜像使用docker search命令可以搜索远端仓库中共享的镜像，默认搜索官方仓库中的镜像。用法为docker search TERM，支持的参数主要包括：·–automated=true|false：仅显示自动创建的镜像，默认为否；·–no-trunc=true|false：输出信息不截断显示，默认为否；·–filter=stars=X：指定仅显示评价为指定星级以上的镜像，默认为0，即输出所有镜像。例如： $ docker search --filter=stars=3 ubuntu $ docker search -f stars=25 centos 删除镜像使用标签删除镜像使用docker rmi命令可以删除镜像，命令格式为docker rmi IMAGE[IMAGE…]，其中IMAGE可以为标签或ID。 创建镜像创建镜像的方法主要有三种：基于已有镜像的容器创建、基于本地模板导入、基于Dockerfile创建。本节将重点介绍前两种方法。最后一种基于Dockerfile创建的方法将在后续章节专门予以详细介绍。 基于已有镜像的容器创建该方法主要是使用docker commit命令。命令格式为docker commit[OPTIONS]CONTAINER[REPOSITORY[：TAG]]，主要选项包括：·-a，–author=””：作者信息；·-c，–change=[]：提交的时候执行Dockerfile指令，包括CMD|ENTRYPOINT|ENV|EXPOSE|LABEL|ONBUILD|USER|VOLUME|WORKDIR等；·-m，–message=””：提交消息；·-p，–pause=true：提交时暂停容器运行。 基于本地模板导入要直接导入一个镜像，可以使用OpenVZ提供的模板来创建，或者用其他已导出的镜像模板来创建。OPENVZ模板的下载地址为http://openvz.org/Download/templates/precreated 存出和载入镜像1.存出镜像 [root@centos-docker docker]# docker save -o centos_7.tar.gz daocloud.io/centos:7 [root@centos-docker docker]# ls centos_7.tar.gz certs.d daemon.json key.json 2.载入镜像 [root@centos-docker docker]# docker load --input centos_7.tar.gz Loaded image: daocloud.io/centos:7 或者$ docker load &lt; centos_7.tar.gz这将导入镜像及其相关的元数据信息（包括标签等）。 创建&amp;启动一个容器：$ docker run -d -p 10022:22 -v /dfile/:/dfile/ -h &quot;centos-d&quot; --name centos-d centos-ssh /usr/sbin/sshd -D $ mount -t vboxsf docker_files /docker [root@centos-d /]# netstat -tunlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1/sshd tcp6 0 0 :::22 :::* LISTEN 1/sshd 其中10022是宿主主机的端口，22是容器的SSH服务监听端口：-p 10022:22使用HostPort：ContainerPort格式将本地的10022端口映射到容器的22端口。 在宿主主机或其他主机上，可以通过SSH访问10022端口来登录容器。 使用docker inspect来查看容器的基础信息。参见：https://docs.docker.com/engine/reference/commandline/inspect/ -v /dfile(主机):/dfile(容器):ro上面的命令加载主机的/dfile目录到容器的/dfile目录。ps：本地目录的路径必须是绝对路径，如果目录不存在，Docker会自动创建。 Docker挂载数据卷的默认权限是读写（rw），用户也可以通过ro指定为只读。 mount -t vboxsf the_share_name /a_folder_nameps:VirtualBox与Mac共享文件夹为：docker_filesps: $ docker ps -a查看容器。 [root@centos-docker docker]# docker start centos-d centos-d [root@centos-docker docker]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0ffb8ab3f777 centos-ssh &quot;/usr/sbin/sshd -D&quot; 11 weeks ago Up 12 seconds 0.0.0.0:10022-&gt;22/tcp centos-d $ docker-enter centos-d 进入容器。可以按Ctrl+d或输入exit命令来退出容器，通过exit命令或Ctrl+d来退出终端时，所创建的容器立刻终止，处于stopped状态。 利用ssh进入到docker中的centos里然后 我们试着从宿主机直接进入到docker中的centos里： ~ ssh root@192.168.99.100 -p 10022 root@192.168.99.100&#39;s password: Last login: Thu Jun 29 09:03:57 2017 from 192.168.99.1 [root@centos-d ~]# 避免了先进入虚拟机系统，然后再进入docker中的centos里： ~ ssh root@192.168.99.100 -p 22 root@192.168.99.100&#39;s password: Last login: Thu Jun 29 17:11:29 2017 from 192.168.99.1 [root@centos-docker ~]# docker-enter centos-d Last login: Thu Jun 29 09:21:21 UTC 2017 from 192.168.99.1 on pts/0 [root@centos-d ~]# create命令与容器运行模式相关的选项-d, –detach=true|false (是否在后台运行容器，默认为否)-P, –publish-all=true|false (通过NAT机制将容器标记暴露的端口自动映射到本地主机的临时端口)-p, –publish=[] (指定如何映射到本地主机端口)–rm=true|false （容器退出后是否自动删除，不能跟-d同时使用）-i, –interactive=true|false (保持标准输入打开，默认为false)-t, –tty=true|false (是否分配一个伪终端，默认是false)–expose=[] (指定容器会暴露出来的端口或端口范围)–group-add=[] (运行容器的用户组)-v|–volume[=[[HOST-DIR:]CONTAINER-DIR[:OPTIONS]]] (挂载主机上的文件卷到容器内)-w, –workdir=”” (容器内的默认工作目录) create命令与容器环境和配置相关的选项–add-host=[] (在容器内添加一个主机名到IP地址的映射关系（通过/etc/hosts文件）)-h, –hostname=”” (指定容器内的主机名)–name=”” (指定容器的别名) create命令与容器资源限制和安全保护相关的选项–privileged=true|false (是否给容器以高权限，这意味着容器内应用将不受权限下限制，一般不推荐)–read-only=true|false (是否让容器内的文件系统只读) 启动容器说明当利用docker run来创建并启动容器时，Docker在后台运行的标准操作包括： ·检查本地是否存在指定的镜像，不存在就从公有仓库下载；·利用镜像创建一个容器，并启动该容器；·分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层；·从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中；·从网桥的地址池配置一个IP地址给容器；·执行用户指定的应用程序；·执行完毕后容器被自动终止。 终止容器可以使用docker stop来终止一个运行中的容器。该命令的格式为docker stop[-t|–time[=10]][CONTAINER…]。首先向容器发送SIGTERM信号，等待一段超时时间（默认为10秒）后，再发送SIGKILL信号来终止容器。 进入容器在使用-d参数时，容器启动后会进入后台，用户无法看到容器中的信息，也无法进行操作。这个时候如果需要进入容器进行操作，有多种方法，包括使用官方的attach或exec命令，以及第三方的nsenter工具等。下面分别介绍一下。 attach命令attach是Docker自带的命令，命令格式为： 支持三个主要选项：·–detach-keys[=[]]：指定退出attach模式的快捷键序列，默认是CTRL-p CTRL-q；·–no-stdin=true|false：是否关闭标准输入，默认是保持打开；·–sig-proxy=true|false：是否代理收到的系统信号给应用进程，默认为true。ps:当多个窗口同时用attach命令连到同一个容器的时候，所有窗口都会同步显示。不常用。 exec命令Docker从1.3.0版本起提供了一个更加方便的exec命令，可以在容器内直接执行任意命令。比较重要的参数有：·-i，–interactive=true|false：打开标准输入接受用户输入命令，默认为false；·–privileged=true|false：是否给执行命令以高权限，默认为false；·-t，–tty=true|false：分配伪终端，默认为false；·-u，–user=””：执行命令的用户名或ID。例如进入到刚创建的容器中，并启动一个bash： [root@centos-docker docker]# docker exec -it centos-d /bin/bash [root@centos-d /]# pwd / 可以看到，一个bash终端打开了，在不影响容器内其他应用的前提下，用户可以很容易与容器进行交互。注意通过指定-it参数来保持标准输入打开，并且分配一个伪终端。通过exec命令对容器执行操作是最为推荐的方式。 nsenter工具在util-linux软件包版本2.23+中包含nsenter工具。 [root@centos-docker docker]# docker start centos-d centos-d [root@centos-docker docker]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0ffb8ab3f777 centos-ssh &quot;/usr/sbin/sshd -D&quot; 11 weeks ago Up 6 seconds 0.0.0.0:10022-&gt;22/tcp centos-d [root@centos-docker docker]# PID=$(docker inspect --format &quot;{{ .State.Pid }}&quot; centos-d) [root@centos-docker docker]# nsenter --target $PID --mount --uts --ipc --net --pid [root@centos-d /]# ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 06:04 ? 00:00:00 /usr/sbin/sshd -D root 5 0 0 06:07 ? 00:00:00 -bash root 19 5 0 06:09 ? 00:00:00 ps -ef 删除容器可以使用docker rm命令来删除处于终止或退出状态的容器，命令格式为docker rm[-f|–force][-l|–link][-v|–volumes]CONTAINER[CONTAINER…]。主要支持的选项包括：·-f，–force=false：是否强行终止并删除一个运行中的容器；·-l，–link=false：删除容器的连接，但保留容器；·-v，–volumes=false：删除容器挂载的数据卷。 导入和导出容器某些时候，需要将容器从一个系统迁移到另外一个系统，此时可以使用Docker的导入和导出功能。这也是Docker自身提供的一个重要特性。 导出容器导出容器是指导出一个已经创建的容器到一个文件，不管此时这个容器是否处于运行状态，可以使用docker export命令，该命令的格式为docker export[-o|–output[=””]]CONTAINER。其中，可以通过-o选项来指定导出的tar文件名，也可以直接通过重定向来实现。ps:实现容器的迁移 [root@centos-docker docker]# docker export -o test_centos-d.tar.gz centos-d [root@centos-docker docker]# ls a.txt b.txt c.txt epel-release-7-9.noarch.rpm test_centos-d.tar.gz [root@centos-docker docker]# docker export centos-d &gt;test2_centos-d.tar.gz [root@centos-docker docker]# ls a.txt b.txt c.txt epel-release-7-9.noarch.rpm test2_centos-d.tar.gz test_centos-d.tar.gz 实际上，既可以使用docker load命令来导入镜像存储文件到本地镜像库，也可以使用docker import命令来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也更大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。 参考在此：Docker技术入门与实践Docker进阶与实战 作者：华为Docker实践小组]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Systemd 入门教程：命令篇]]></title>
      <url>%2F2017%2F05%2F25%2Fsystemd%2F</url>
      <content type="text"><![CDATA[Systemd 入门教程：命令篇Systemd 是 Linux 系统工具，用来启动守护进程，已成为大多数发行版的标准配置。 本文介绍它的基本用法，分为上下两篇。今天介绍它的主要命令，下一篇介绍如何用于实战。 一、由来历史上，Linux 的启动一直采用init进程。 下面的命令用来启动服务。 [root@localhost /]# service httpd start Redirecting to /bin/systemctl start httpd.service ps:Centos7已经不支持了喔！ 这种方法有两个缺点。 一是启动时间长。init进程是串行启动，只有前一个进程启动完，才会启动下一个进程。 二是启动脚本复杂。init进程只是执行启动脚本，不管其他事情。脚本需要自己处理各种情况，这往往使得脚本变得很长。 二、Systemd 概述Systemd 就是为了解决这些问题而诞生的。它的设计目标是，为系统的启动和管理提供一套完整的解决方案。 根据 Linux 惯例，字母d是守护进程（daemon）的缩写。 Systemd 这个名字的含义，就是它要守护整个系统。 （上图为 Systemd 作者 Lennart Poettering） 使用了 Systemd，就不需要再用init了。Systemd 取代了initd，成为系统的第一个进程（PID 等于 1），其他进程都是它的子进程。 $ systemctl --version 上面的命令查看 Systemd 的版本。 Systemd 的优点是功能强大，使用方便，缺点是系统庞大，非常复杂。事实上，现在还有很多人反对使用 Systemd，理由就是它过于复杂，与操作系统的其他部分强耦合，违反“keep simple, keep stupid”的Unix 哲学。 （上图为 Systemd 架构图） 三、系统管理Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。 3.1 systemctlsystemctl是 Systemd 的主命令，用于管理系统。 # 重启系统 $ sudo systemctl reboot # 关闭系统，切断电源 $ sudo systemctl poweroff # CPU停止工作 $ sudo systemctl halt # 暂停系统 $ sudo systemctl suspend # 让系统进入冬眠状态 $ sudo systemctl hibernate # 让系统进入交互式休眠状态 $ sudo systemctl hybrid-sleep # 启动进入救援状态（单用户状态） $ sudo systemctl rescue 3.2 systemd-analyzesystemd-analyze命令用于查看启动耗时。 # 查看启动耗时 $ systemd-analyze # 查看每个服务的启动耗时 $ systemd-analyze blame # 显示瀑布状的启动过程流 $ systemd-analyze critical-chain # 显示指定服务的启动流(eg:sshd.service) $ systemd-analyze critical-chain sshd.service 3.3 hostnamectlhostnamectl命令用于查看当前主机的信息。 # 显示当前主机的信息 $ hostnamectl # 设置主机名。 $ sudo hostnamectl set-hostname CentOS-Docker 3.4 localectllocalectl命令用于查看本地化设置。 # 查看本地化设置 $ localectl # 设置本地化参数。 $ sudo localectl set-locale LANG=zh_CN.UTF-8 $ sudo localectl set-keymap cn 3.5 timedatectltimedatectl命令用于查看当前时区设置。 # 查看当前时区设置 $ timedatectl # 显示所有可用的时区 $ timedatectl list-timezones # 设置当前时区 $ sudo timedatectl set-timezone America/New_York 3.6 loginctlloginctl命令用于查看当前登录的用户。 # 列出当前session $ loginctl list-sessions # 列出当前登录用户 $ loginctl list-users # 列出显示指定用户的信息 $ loginctl show-user root 四、Unit4.1 含义Systemd 可以管理所有系统资源。不同的资源统称为 Unit（单位）。 Unit 一共分成12种。 Service unit：系统服务 Target unit：多个 Unit 构成的一个组 Device Unit：硬件设备 Mount Unit：文件系统的挂载点 Automount Unit：自动挂载点 Path Unit：文件或路径 Scope Unit：不是由 Systemd 启动的外部进程 Slice Unit：进程组 Snapshot Unit：Systemd 快照，可以切回某个快照 Socket Unit：进程间通信的 socket Swap Unit：swap 文件 Timer Unit：定时器 systemctl list-units命令可以查看当前系统的所有 Unit 。 # 列出正在运行的 Unit $ systemctl list-units # 列出所有Unit，包括没有找到配置文件的或者启动失败的 $ systemctl list-units --all # 列出所有没有运行的 Unit $ systemctl list-units --all --state=inactive # 列出所有加载失败的 Unit $ systemctl list-units --failed # 列出所有正在运行的、类型为 service 的 Unit $ systemctl list-units --type=service 4.2 Unit 的状态systemctl status命令用于查看系统状态和单个 Unit 的状态。 # 显示系统状态 $ systemctl status # 显示单个 Unit 的状态 $ sysystemctl status httpd.service # 显示远程主机的某个 Unit 的状态 $ systemctl -H root@rhel7.example.com status httpd.service 除了status命令，systemctl还提供了三个查询状态的简单方法，主要供脚本内部的判断语句使用。 # 显示某个 Unit 是否正在运行 $ systemctl is-active httpd.service # 显示某个 Unit 是否处于启动失败状态 $ systemctl is-failed httpd.service # 显示某个 Unit 服务是否建立了启动链接 $ systemctl is-enabled httpd.service 4.3 Unit 管理对于用户来说，最常用的是下面这些命令，用于启动和停止 Unit（主要是 service）。 # 立即启动一个服务 $ sudo systemctl start httpd.service # 立即停止一个服务 $ sudo systemctl stop httpd.service # 重启一个服务 $ sudo systemctl restart httpd.service # 杀死一个服务的所有子进程 $ sudo systemctl kill httpd.service # 重新加载一个服务的配置文件 $ sudo systemctl reload httpd.service # 重载所有修改过的配置文件 $ sudo systemctl daemon-reload # 显示某个 Unit 的所有底层参数 $ systemctl show httpd.service # 显示某个 Unit 的指定属性的值 $ systemctl show -p CPUShares httpd.service 4.4 依赖关系Unit 之间存在依赖关系：A 依赖于 B，就意味着 Systemd 在启动 A 的时候，同时会去启动 B。 systemctl list-dependencies命令列出一个 Unit 的所有依赖。 $ systemctl list-dependencies nginx.service 上面命令的输出结果之中，有些依赖是 Target 类型（详见下文），默认不会展开显示。如果要展开 Target，就需要使用--all参数。 $ systemctl list-dependencies --all nginx.service 五、Unit 的配置文件5.1 概述每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit 。 Systemd 默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/，真正的配置文件存放在这个目录。 systemctl enable命令用于在上面两个目录之间，建立符号链接关系。 $ sudo systemctl enable sshd.service # 等同于 $ sudo ln -s &#39;/usr/lib/systemd/system/sshd.service&#39; &#39;/etc/systemd/system/multi-user.target.wants/sshd.service&#39; 如果配置文件里面设置了开机启动，systemctl enable命令相当于激活开机启动。 与之对应的，systemctl disable命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动。 $ sudo systemctl disable sshd.service 配置文件的后缀名，就是该 Unit 的种类，比如sshd.socket。如果省略，Systemd 默认后缀名为.service，所以sshd会被理解成sshd.service。 5.2 配置文件的状态systemctl list-unit-files命令用于列出所有配置文件。 # 列出所有配置文件 $ systemctl list-unit-files # 列出指定类型的配置文件 $ systemctl list-unit-files --type=service 这个命令会输出一个列表。 $ systemctl list-unit-files UNIT FILE STATE chronyd.service enabled clamd@.service static sshd.service disabled 这个列表显示每个配置文件的状态，一共有四种。 enabled：已建立启动链接 disabled：没建立启动链接 static：该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖 masked：该配置文件被禁止建立启动链接 注意，从配置文件的状态无法看出，该 Unit 是否正在运行。这必须执行前面提到的systemctl status命令。 $ systemctl status httpd.service 一旦修改配置文件，就要让 Systemd 重新加载配置文件，然后重新启动，否则修改不会生效。 $ sudo systemctl daemon-reload $ sudo systemctl restart httpd.service 5.3 配置文件的格式配置文件就是普通的文本文件，可以用文本编辑器打开。 systemctl cat命令可以查看配置文件的内容。注意，配置文件的区块名和字段名，都是大小写敏感的。 每个区块内部是一些等号连接的键值对。 [Section] Directive1=value Directive2=value . . . 注意，键值对的等号两侧不能有空格。 5.4 配置文件的区块[Unit]区块通常是配置文件的第一个区块，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系。它的主要字段如下。 Description：简短描述 Documentation：文档地址 Requires：当前 Unit 依赖的其他 Unit，如果它们没有运行，当前 Unit 会启动失败 Wants：与当前 Unit 配合的其他 Unit，如果它们没有运行，当前 Unit 不会启动失败 BindsTo：与Requires类似，它指定的 Unit 如果退出，会导致当前 Unit 停止运行 Before：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之后启动 After：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之前启动 Conflicts：这里指定的 Unit 不能与当前 Unit 同时运行 Condition...：当前 Unit 运行必须满足的条件，否则不会运行 Assert...：当前 Unit 运行必须满足的条件，否则会报启动失败 [Install]通常是配置文件的最后一个区块，用来定义如何启动，以及是否开机启动。它的主要字段如下。 WantedBy：它的值是一个或多个 Target，当前 Unit 激活时（enable）符号链接会放入/etc/systemd/system目录下面以 Target 名 + .wants后缀构成的子目录中 RequiredBy：它的值是一个或多个 Target，当前 Unit 激活时，符号链接会放入/etc/systemd/system目录下面以 Target 名 + .required后缀构成的子目录中 Alias：当前 Unit 可用于启动的别名 Also：当前 Unit 激活（enable）时，会被同时激活的其他 Unit [Service]区块用来 Service 的配置，只有 Service 类型的 Unit 才有这个区块。它的主要字段如下。 Type：定义启动时的进程行为。它有以下几种值。 simple：默认值，执行ExecStart指定的命令，启动主进程 forking：以 fork 方式从父进程创建子进程，创建后父进程会立即退出 oneshot：一次性进程，Systemd 会等当前服务退出，再继续往下执行 dbus：当前服务通过D-Bus启动 notify：当前服务启动完毕，会通知Systemd，再继续往下执行 idle：若有其他任务执行完毕，当前服务才会运行 ExecStart：启动当前服务的命令 ExecStartPre：启动当前服务之前执行的命令 ExecStartPost：启动当前服务之后执行的命令 ExecReload：重启当前服务时执行的命令 ExecStop：停止当前服务时执行的命令 ExecStopPost：停止当其服务之后执行的命令 RestartSec：自动重启当前服务间隔的秒数 Restart：定义何种情况 Systemd 会自动重启当前服务，可能的值包括always（总是重启）、on-success、on-failure、on-abnormal、on-abort、on-watchdog TimeoutSec：定义 Systemd 停止当前服务之前等待的秒数 Environment：指定环境变量 Unit 配置文件的完整字段清单，请参考官方文档。 六、Target简单说，Target 就是一个 Unit 组，包含许多相关的 Unit 。启动某个 Target 的时候，Systemd 就会启动里面所有的 Unit。从这个意义上说，Target 这个概念类似于“状态点”，启动某个 Target 就好比启动到某种状态。 传统的init启动模式里面，有 RunLevel 的概念，跟 Target 的作用很类似。不同的是，RunLevel 是互斥的，不可能多个 RunLevel 同时启动，但是多个 Target 可以同时启动。 # 查看当前系统的所有 Target $ systemctl list-unit-files --type=target # 查看一个 Target 包含的所有 Unit $ systemctl list-dependencies multi-user.target # 查看启动时的默认 Target $ systemctl get-default # 设置启动时的默认 Target $ sudo systemctl set-default multi-user.target # 切换 Target 时，默认不关闭前一个 Target 启动的进程， # systemctl isolate 命令改变这种行为， # 关闭前一个 Target 里面所有不属于后一个 Target 的进程 $ sudo systemctl isolate multi-user.target Target 与 传统 RunLevel 的对应关系如下。 Traditional runlevel New target name Symbolically linked to... Runlevel 0 | runlevel0.target -&gt; poweroff.target Runlevel 1 | runlevel1.target -&gt; rescue.target Runlevel 2 | runlevel2.target -&gt; multi-user.target Runlevel 3 | runlevel3.target -&gt; multi-user.target Runlevel 4 | runlevel4.target -&gt; multi-user.target Runlevel 5 | runlevel5.target -&gt; graphical.target Runlevel 6 | runlevel6.target -&gt; reboot.target 它与init进程的主要差别如下。 （1）默认的 RunLevel（在/etc/inittab文件设置）现在被默认的 Target 取代，位置是/etc/systemd/system/default.target，通常符号链接到graphical.target（图形界面）或者multi-user.target（多用户命令行）。 （2）启动脚本的位置，以前是/etc/init.d目录，符号链接到不同的 RunLevel 目录 （比如/etc/rc3.d、/etc/rc5.d等），现在则存放在/lib/systemd/system和/etc/systemd/system目录。 （3）配置文件的位置，以前init进程的配置文件是/etc/inittab，各种服务的配置文件存放在/etc/sysconfig目录。现在的配置文件主要存放在/lib/systemd目录，在/etc/systemd目录里面的修改可以覆盖原始设置。 七、日志管理Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件是/etc/systemd/journald.conf。 journalctl功能强大，用法非常多。 # 查看所有日志（默认情况下 ，只保存本次启动的日志） $ sudo journalctl # 查看内核日志（不显示应用日志） $ sudo journalctl -k # 查看系统本次启动的日志 $ sudo journalctl -b $ sudo journalctl -b -0 # 查看上一次启动的日志（需更改设置） $ sudo journalctl -b -1 # 查看指定时间的日志 $ sudo journalctl --since=&quot;2012-10-30 18:17:16&quot; $ sudo journalctl --since &quot;20 min ago&quot; $ sudo journalctl --since yesterday $ sudo journalctl --since 09:00 --until &quot;1 hour ago&quot; # 显示尾部的最新10行日志 $ sudo journalctl -n # 显示尾部指定行数的日志 $ sudo journalctl -n 20 # 实时滚动显示最新日志 $ sudo journalctl -f # 查看指定服务的日志 $ sudo journalctl /usr/lib/systemd/systemd # 查看指定进程的日志 $ sudo journalctl _PID=1 # 查看某个路径的脚本的日志 $ sudo journalctl /usr/bin/bash # 查看指定用户的日志 $ sudo journalctl _UID=33 --since today # 查看某个 Unit 的日志 $ sudo journalctl -u nginx.service $ sudo journalctl -u nginx.service --since today # 实时滚动显示某个 Unit 的最新日志 $ sudo journalctl -u nginx.service -f # 合并显示多个 Unit 的日志 $ journalctl -u nginx.service -u php-fpm.service --since today # 查看指定优先级（及其以上级别）的日志，共有8级 # 0: emerg # 1: alert # 2: crit # 3: err # 4: warning # 5: notice # 6: info # 7: debug $ sudo journalctl -p err -b # 日志默认分页输出，--no-pager 改为正常的标准输出 $ sudo journalctl --no-pager # 以 JSON 格式（单行）输出 $ sudo journalctl -b -u nginx.service -o json # 以 JSON 格式（多行）输出，可读性更好 $ sudo journalctl -b -u nginx.service -o json-pretty # 显示日志占据的硬盘空间 $ sudo journalctl --disk-usage # 指定日志文件占据的最大空间 $ sudo journalctl --vacuum-size=1G # 指定日志文件保存多久 $ sudo journalctl --vacuum-time=1years 八、结语转载于http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html 引申阅读： LINUX PID 1 和 SYSTEMD]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Git 学习笔记 - 基本操作]]></title>
      <url>%2F2017%2F05%2F11%2Fgit-how%2F</url>
      <content type="text"><![CDATA[#Git 闲话 1、最近阅读《数学之美》、《浪潮之巅》惊叹于大神的眼界、文化功底，所以就在得到专栏上订阅了吴军博士的硅谷来信。总之，就是膜拜了。想了解一个人，就先了解一个的思想对不对，所谓见贤与之思齐就是这样了。2、接下来说一说我心目中的另一位大神 林纳斯•托瓦兹，编程界公认的啊。“我不是个有远见的人，我是一名工程师，”托瓦兹说，“我非常乐意跟梦想家在一起，他们行走四方，仰望苍穹……但我是低头看路的那种人，我只想填好眼前这个坑，不让自己掉进去。“只干了两件事啊，毫不夸张的说：惊天地泣鬼神。第一件是开发出Linux内核，驱动了因特网，第二件是开发出Git，一种源代码管理系统，被全世界开发者广泛使用。再接下来，Git 就是我们的主题了，记录以备忘。 Git安装与配置安装Mac 上brew安装算是最便捷的了 ~ brew install git ~ brew --version Homebrew 1.1.13 Homebrew/homebrew-core (git revision ea163; last commit 2017-04-20) ~ git --version git version 2.11.0 配置可以通过 git config –list –global 命令来查看： ~ git config --list --global user.email=1250114609@qq.com user.name=千古不见一人闲 color.ui=auto alias.st=status alias.lg=log --color --graph --pretty=format:&#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#39; --abbrev-commit 可以看到有两个alias出现，这里使用了别名。 配置别名 这个功能在shell中是很常用的。我们可以做一些别名来取代比较复杂的指令。比如上面就是使用了以下两个配置 ~ git config --global alias.st status ~ git config --global alias.lg &quot;log --color --graph --pretty=format:&#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#39; --abbrev-commit&quot; 身份认证当本地git仓库与git远程仓库通信的时候，需要进行SSH身份认证。打开根目录下的.ssh目录： ~/.ssh la . .. config github_rsa github_rsa.pub id_rsa id_rsa.pub known_hosts 如果没有id_rsa和id_rsa.pub这两个文件，就通过如下的命令生成： ssh-keygen -t rsa -C “youremail@example.com”id_rsa和id_rsa.pub这两个文件，就是SSH Key的秘钥对，id_rsa是私钥，id_rsa.pub是公钥，用在github上表明身份。在GitHub上的SSH keys中添加刚刚生成的key。(id_rsa.pub) 创建Git仓库创建一个目录，并cd到目录下，通过调用git init来将现有目录初始化为git仓库，或者直接在git init后面跟上目录名，同样也可以创建一个新的仓库。 git clone 直接clone一个远程仓库也是可以的。 提交修改~/Documents/workspace git_springboot ~/Documents/workspace/git_springboot(master ✔) la . .. .git ~/Documents/workspace/git_springboot(master ✔) touch README.md ~/Documents/workspace/git_springboot(master ✗) vim README.md ~/Documents/workspace/git_springboot(master ✗) git add README.md ~/Documents/workspace/git_springboot(master ✗) git commit -m &quot;add README.md&quot; [master be9081a] add README.md 1 file changed, 1 insertion(+) create mode 100644 README.md ~/Documents/workspace/git_springboot(master ✔) 查看修改修改README.md文件，git st查看修改 ~/Documents/workspace/git_springboot(master ✗) git st On branch master Your branch is ahead of &#39;origin/master&#39; by 1 commit. (use &quot;git push&quot; to publish your local commits) Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: README.md no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) Git 比较不同版本文件差异的常用命令格式： git diff 查看尚未暂存的文件更新了哪些部分 git diff filename 查看尚未暂存的某个文件更新了哪些 git diff –cached 查看已经暂存起来的文件和上次提交的版本之间的差异 git diff –cached filename 查看已经暂存起来的某个文件和上次提交的版本之间的差异 使用git diff README.md 命令看一下修改的具体内容 diff –git a/README.md b/README.mdindex e8281cd..f1729fb 100644— a/README.md+++ b/README.md@@ -1 +1 @@-this’s ok.+this’s ok,modify. add和commit之后，我们都使用status来查看下状态，可以发现，在commit之后，git提示我们，工作区是干净的。 ~/Documents/workspace/git_springboot(master ✗) git st On branch master Your branch is ahead of &#39;origin/master&#39; by 1 commit. (use &quot;git push&quot; to publish your local commits) Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: README.md no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) ~/Documents/workspace/git_springboot(master ✗) git add README.md ~/Documents/workspace/git_springboot(master ✗) git commit -m &quot;modify README.md&quot; [master a77107b] modify README.md 1 file changed, 1 insertion(+), 1 deletion(-) ~/Documents/workspace/git_springboot(master ✔) git st On branch master Your branch is ahead of &#39;origin/master&#39; by 2 commits. (use &quot;git push&quot; to publish your local commits) nothing to commit, working tree clean 版本记录使用git lg 命令来查看也可以使用gitk命令来查看图形化的log记录 工作区与暂存区Git通常是工作在三个区域上： 工作区暂存区历史区其中工作区就是我们平时工作、修改代码的区域；而历史区，用来保存各个版本；而暂存区，则是Git的核心所在。Git官网图解Git 版本回退回退版本是必不可少的操作啊 我们来考虑以下常见的几种情况： 文件已经修改，但是还没有git add 文件已经add到暂存区，又作了修改 文件的修改已经add到了暂存区 分别执行以下操作： ➜git checkout – README.md修改被删除，完全还原到上次commit的状态，也就是服务器版本(1.)最后的修改被删除，还原到上次add的状态，也就是修改前的暂存区状态(2.)➜git reset HEAD README.md(3.) ~/Documents/workspace/git_springboot(master ✗) git st On branch master Your branch is ahead of &#39;origin/master&#39; by 2 commits. (use &quot;git push&quot; to publish your local commits) Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: README.md ~/Documents/workspace/git_springboot(master ✗) git reset HEAD README.md Unstaged changes after reset: M README.md ~/Documents/workspace/git_springboot(master ✗) git st On branch master Your branch is ahead of &#39;origin/master&#39; by 2 commits. (use &quot;git push&quot; to publish your local commits) Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: README.md no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 通过git reset HEAD README.md，我们就把暂存区的文件清除了。这样，在本地就是add前的状态，通过checkout操作，就可以进行修改回退了。在Git中，用HEAD表示当前版本，上一个版本就是HEAD^，上上一个版本就是HEAD^^。（git reset –hard HEAD）要回退到哪个版本，也可以写commit id。 前进版本如果我们回退到了旧的版本，但是却后悔了想回到后面某个新的版本,git reflog 查看操作历史。找到 commit id。版本号没必要写全，前7位就可以了，Git会自动去找。 文件暂存这里的暂存不是前面说的暂存区，而是只一次备份与恢复操作。git stash指令来将当前修改暂存，这样就可以切换到其他分支或者就在当前干净的分支上checkout了。比如你checkout了一个issue分支，修改了bug，使用git merge合并到了master分支，删除issue分支，切换到dev分支，想继续之前的新功能开发。这时候，就需要恢复现场了： git stash list指令来查看当前暂存的内容记录。然后，通过git stash apply或者git stash pop来进行恢复，它们的区别是，前者不会删除记录（当然你可以使用git stash drop来删除），而后者会。 远程仓库&amp;同步协作 Git关联远程仓库 Git学习资料*Git学习资料]]></content>
    </entry>

    
  
  
</search>
